# This collector config file is designed for use within an ECS task.
# The collector should run in a sidecar container within an ECS task.
config_sources:
  env:
    defaults:
      METRICS_TO_EXCLUDE: []

extensions:
  headers_setter:
    headers:
      - action: upsert
        key: X-SF-TOKEN
        from_context: X-SF-TOKEN
        default_value: "${SPLUNK_ACCESS_TOKEN}"
  health_check:
    endpoint: 0.0.0.0:13133
  http_forwarder:
    ingress:
      endpoint: 0.0.0.0:6060
    egress:
      endpoint: "https://api.${SPLUNK_REALM}.signalfx.com"
  zpages:
    endpoint: 0.0.0.0:55679

receivers:
  # The fluentforward receiver can be used to forward logs from the Docker fluentd logging driver.
  fluentforward:
    endpoint: 0.0.0.0:8006
  hostmetrics:
    collection_interval: 10s
    scrapers:
      cpu:
      disk:
      filesystem:
      memory:
      network:
      # System load average metrics https://en.wikipedia.org/wiki/Load_(computing)
      load:
      # Paging/Swap space utilization and I/O metrics
      paging:
      # Aggregated system process count metrics
      processes:
      # System processes metrics, disabled by default
      # process:
  jaeger:
    protocols:
      grpc:
        endpoint: 0.0.0.0:14250
      thrift_http:
        endpoint: 0.0.0.0:14268
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
        # Uncomment below config to preserve incoming access token and use it instead of the token value set in exporter config
        # include_metadata: true
      http:
        endpoint: 0.0.0.0:4318
        # Uncomment below config to preserve incoming access token and use it instead of the token value set in exporter config
        # include_metadata: true
  # This section is used to collect the OpenTelemetry Collector metrics
  # Even if just a Splunk APM customer, these metrics are included
  prometheus/internal:
    config:
      scrape_configs:
        - job_name: 'otel-collector'
          scrape_interval: 10s
          static_configs:
            - targets: ['0.0.0.0:8888']
          metric_relabel_configs:
            - source_labels: [ __name__ ]
              regex: 'promhttp_metric_handler_errors.*'
              action: drop
            - source_labels: [ __name__ ]
              regex: 'otelcol_processor_batch_.*'
              action: drop
  signalfx:
    endpoint: 0.0.0.0:9943
    # Whether to preserve incoming access token and use instead of exporter token
    # default = false
    #access_token_passthrough: true
  zipkin:
    endpoint: 0.0.0.0:9411

processors:
  batch:
    metadata_keys:
      - X-SF-Token
  # Enabling the memory_limiter is strongly recommended for every pipeline.
  # Configuration is based on the amount of memory allocated to the collector.
  # For more information about memory limiter, see
  # https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/memorylimiter/README.md
  memory_limiter:
    check_interval: 2s
    limit_mib: ${SPLUNK_MEMORY_LIMIT_MIB}
  # detect if the collector is running on a cloud system
  # important for creating unique cloud provider dimensions
  resourcedetection:
    detectors: [ecs]
    override: false
  # Same as above but overrides resource attributes set by receivers
  resourcedetection/internal:
    detectors: [ecs]
    override: true
  # Defines the filter processor with example settings
  # Full configuration here: https://github.com/open-telemetry/opentelemetry-collector/tree/main/processor/filterprocessor
  filter:
    metrics:
      exclude:
        match_type: regexp
        metric_names: ${env:METRICS_TO_EXCLUDE}
#  # Optional: The following processor can be used to add a default "deployment.environment" attribute to the logs and
#  # traces when it's not populated by instrumentation libraries.
#  # If enabled, make sure to enable this processor in the pipeline below.
#  resource/add_environment:
#    attributes:
#      - action: insert
#        value: staging/production/...
#        key: deployment.environment

exporters:
  # Traces
  otlphttp:
    traces_endpoint: "${SPLUNK_INGEST_URL}/v2/trace/otlp"
    headers:
      "X-SF-Token": "${SPLUNK_ACCESS_TOKEN}"
    auth:
      authenticator: headers_setter
  # Metrics + Events
  signalfx:
    access_token: "${SPLUNK_ACCESS_TOKEN}"
    realm: "${SPLUNK_REALM}"
    correlation:
  # Logs
  splunk_hec:
    token: "${SPLUNK_HEC_TOKEN}"
    endpoint: "${SPLUNK_HEC_URL}"
    source: "otel"
    sourcetype: "otel"
    profiling_data_enabled: false
  # Profiling
  splunk_hec/profiling:
    token: "${SPLUNK_ACCESS_TOKEN}"
    endpoint: "${SPLUNK_INGEST_URL}/v1/log"
    log_data_enabled: false

service:
  extensions: [headers_setter, health_check, http_forwarder, zpages]
  pipelines:
    traces:
      receivers: [jaeger, otlp, zipkin]
      processors:
        - memory_limiter
        - batch
        - resourcedetection
        #- resource/add_environment
      exporters: [otlphttp, signalfx]
    metrics:
      receivers: [hostmetrics, otlp, signalfx]
      processors: [memory_limiter, batch, filter, resourcedetection]
      exporters: [signalfx]
    metrics/internal:
      receivers: [prometheus/internal]
      processors: [memory_limiter, batch, filter, resourcedetection/internal]
      exporters: [signalfx]
    logs:
      receivers: [otlp, fluentforward]
      processors:
        - memory_limiter
        - batch
        - resourcedetection
        #- resource/add_environment
      exporters: [splunk_hec, splunk_hec/profiling]
