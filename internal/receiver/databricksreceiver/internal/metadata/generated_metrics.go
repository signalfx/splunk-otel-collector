// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
)

// AttributeTaskType specifies the a value task.type attribute.
type AttributeTaskType int

const (
	_ AttributeTaskType = iota
	AttributeTaskTypeNotebookTask
	AttributeTaskTypeSparkJarTask
	AttributeTaskTypeSparkPythonTask
	AttributeTaskTypePipelineTask
	AttributeTaskTypePythonWheelTask
	AttributeTaskTypeSparkSubmitTask
)

// String returns the string representation of the AttributeTaskType.
func (av AttributeTaskType) String() string {
	switch av {
	case AttributeTaskTypeNotebookTask:
		return "NotebookTask"
	case AttributeTaskTypeSparkJarTask:
		return "SparkJarTask"
	case AttributeTaskTypeSparkPythonTask:
		return "SparkPythonTask"
	case AttributeTaskTypePipelineTask:
		return "PipelineTask"
	case AttributeTaskTypePythonWheelTask:
		return "PythonWheelTask"
	case AttributeTaskTypeSparkSubmitTask:
		return "SparkSubmitTask"
	}
	return ""
}

// MapAttributeTaskType is a helper map of string to AttributeTaskType attribute value.
var MapAttributeTaskType = map[string]AttributeTaskType{
	"NotebookTask":    AttributeTaskTypeNotebookTask,
	"SparkJarTask":    AttributeTaskTypeSparkJarTask,
	"SparkPythonTask": AttributeTaskTypeSparkPythonTask,
	"PipelineTask":    AttributeTaskTypePipelineTask,
	"PythonWheelTask": AttributeTaskTypePythonWheelTask,
	"SparkSubmitTask": AttributeTaskTypeSparkSubmitTask,
}

type metricDatabricksJobsActiveTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.jobs.active.total metric with initial data.
func (m *metricDatabricksJobsActiveTotal) init() {
	m.data.SetName("databricks.jobs.active.total")
	m.data.SetDescription("A snapshot of the number of active jobs taken at each scrape")
	m.data.SetUnit("{jobs}")
	m.data.SetEmptyGauge()
}

func (m *metricDatabricksJobsActiveTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksJobsActiveTotal) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksJobsActiveTotal) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksJobsActiveTotal(cfg MetricConfig) metricDatabricksJobsActiveTotal {
	m := metricDatabricksJobsActiveTotal{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksJobsRunDuration struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.jobs.run.duration metric with initial data.
func (m *metricDatabricksJobsRunDuration) init() {
	m.data.SetName("databricks.jobs.run.duration")
	m.data.SetDescription("The execution duration in milliseconds per completed job")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksJobsRunDuration) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, jobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("job.id", jobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksJobsRunDuration) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksJobsRunDuration) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksJobsRunDuration(cfg MetricConfig) metricDatabricksJobsRunDuration {
	m := metricDatabricksJobsRunDuration{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksJobsScheduleStatus struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.jobs.schedule.status metric with initial data.
func (m *metricDatabricksJobsScheduleStatus) init() {
	m.data.SetName("databricks.jobs.schedule.status")
	m.data.SetDescription("A snapshot of the pause/run status per job taken at each scrape")
	m.data.SetUnit("{status}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksJobsScheduleStatus) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, jobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("job.id", jobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksJobsScheduleStatus) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksJobsScheduleStatus) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksJobsScheduleStatus(cfg MetricConfig) metricDatabricksJobsScheduleStatus {
	m := metricDatabricksJobsScheduleStatus{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksJobsTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.jobs.total metric with initial data.
func (m *metricDatabricksJobsTotal) init() {
	m.data.SetName("databricks.jobs.total")
	m.data.SetDescription("A snapshot of the total number of jobs registered in the Databricks instance taken at each scrape")
	m.data.SetUnit("{jobs}")
	m.data.SetEmptyGauge()
}

func (m *metricDatabricksJobsTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksJobsTotal) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksJobsTotal) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksJobsTotal(cfg MetricConfig) metricDatabricksJobsTotal {
	m := metricDatabricksJobsTotal{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkBlockManagerMemoryDiskSpaceUsed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.block_manager.memory.disk_space.used metric with initial data.
func (m *metricDatabricksSparkBlockManagerMemoryDiskSpaceUsed) init() {
	m.data.SetName("databricks.spark.block_manager.memory.disk_space.used")
	m.data.SetDescription("n/a")
	m.data.SetUnit("mb")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkBlockManagerMemoryDiskSpaceUsed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkBlockManagerMemoryDiskSpaceUsed) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkBlockManagerMemoryDiskSpaceUsed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkBlockManagerMemoryDiskSpaceUsed(cfg MetricConfig) metricDatabricksSparkBlockManagerMemoryDiskSpaceUsed {
	m := metricDatabricksSparkBlockManagerMemoryDiskSpaceUsed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkBlockManagerMemoryMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.block_manager.memory.max metric with initial data.
func (m *metricDatabricksSparkBlockManagerMemoryMax) init() {
	m.data.SetName("databricks.spark.block_manager.memory.max")
	m.data.SetDescription("n/a")
	m.data.SetUnit("mb")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkBlockManagerMemoryMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkBlockManagerMemoryMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkBlockManagerMemoryMax) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkBlockManagerMemoryMax(cfg MetricConfig) metricDatabricksSparkBlockManagerMemoryMax {
	m := metricDatabricksSparkBlockManagerMemoryMax{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkBlockManagerMemoryOffHeapMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.block_manager.memory.off_heap.max metric with initial data.
func (m *metricDatabricksSparkBlockManagerMemoryOffHeapMax) init() {
	m.data.SetName("databricks.spark.block_manager.memory.off_heap.max")
	m.data.SetDescription("n/a")
	m.data.SetUnit("mb")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkBlockManagerMemoryOffHeapMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkBlockManagerMemoryOffHeapMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkBlockManagerMemoryOffHeapMax) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkBlockManagerMemoryOffHeapMax(cfg MetricConfig) metricDatabricksSparkBlockManagerMemoryOffHeapMax {
	m := metricDatabricksSparkBlockManagerMemoryOffHeapMax{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkBlockManagerMemoryOffHeapUsed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.block_manager.memory.off_heap.used metric with initial data.
func (m *metricDatabricksSparkBlockManagerMemoryOffHeapUsed) init() {
	m.data.SetName("databricks.spark.block_manager.memory.off_heap.used")
	m.data.SetDescription("n/a")
	m.data.SetUnit("mb")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkBlockManagerMemoryOffHeapUsed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkBlockManagerMemoryOffHeapUsed) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkBlockManagerMemoryOffHeapUsed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkBlockManagerMemoryOffHeapUsed(cfg MetricConfig) metricDatabricksSparkBlockManagerMemoryOffHeapUsed {
	m := metricDatabricksSparkBlockManagerMemoryOffHeapUsed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkBlockManagerMemoryOnHeapMax struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.block_manager.memory.on_heap.max metric with initial data.
func (m *metricDatabricksSparkBlockManagerMemoryOnHeapMax) init() {
	m.data.SetName("databricks.spark.block_manager.memory.on_heap.max")
	m.data.SetDescription("n/a")
	m.data.SetUnit("mb")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkBlockManagerMemoryOnHeapMax) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkBlockManagerMemoryOnHeapMax) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkBlockManagerMemoryOnHeapMax) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkBlockManagerMemoryOnHeapMax(cfg MetricConfig) metricDatabricksSparkBlockManagerMemoryOnHeapMax {
	m := metricDatabricksSparkBlockManagerMemoryOnHeapMax{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkBlockManagerMemoryOnHeapUsed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.block_manager.memory.on_heap.used metric with initial data.
func (m *metricDatabricksSparkBlockManagerMemoryOnHeapUsed) init() {
	m.data.SetName("databricks.spark.block_manager.memory.on_heap.used")
	m.data.SetDescription("n/a")
	m.data.SetUnit("mb")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkBlockManagerMemoryOnHeapUsed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkBlockManagerMemoryOnHeapUsed) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkBlockManagerMemoryOnHeapUsed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkBlockManagerMemoryOnHeapUsed(cfg MetricConfig) metricDatabricksSparkBlockManagerMemoryOnHeapUsed {
	m := metricDatabricksSparkBlockManagerMemoryOnHeapUsed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkBlockManagerMemoryRemaining struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.block_manager.memory.remaining metric with initial data.
func (m *metricDatabricksSparkBlockManagerMemoryRemaining) init() {
	m.data.SetName("databricks.spark.block_manager.memory.remaining")
	m.data.SetDescription("n/a")
	m.data.SetUnit("mb")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkBlockManagerMemoryRemaining) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkBlockManagerMemoryRemaining) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkBlockManagerMemoryRemaining) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkBlockManagerMemoryRemaining(cfg MetricConfig) metricDatabricksSparkBlockManagerMemoryRemaining {
	m := metricDatabricksSparkBlockManagerMemoryRemaining{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkBlockManagerMemoryRemainingOffHeap struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.block_manager.memory.remaining.off_heap metric with initial data.
func (m *metricDatabricksSparkBlockManagerMemoryRemainingOffHeap) init() {
	m.data.SetName("databricks.spark.block_manager.memory.remaining.off_heap")
	m.data.SetDescription("n/a")
	m.data.SetUnit("mb")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkBlockManagerMemoryRemainingOffHeap) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkBlockManagerMemoryRemainingOffHeap) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkBlockManagerMemoryRemainingOffHeap) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkBlockManagerMemoryRemainingOffHeap(cfg MetricConfig) metricDatabricksSparkBlockManagerMemoryRemainingOffHeap {
	m := metricDatabricksSparkBlockManagerMemoryRemainingOffHeap{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkBlockManagerMemoryRemainingOnHeap struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.block_manager.memory.remaining.on_heap metric with initial data.
func (m *metricDatabricksSparkBlockManagerMemoryRemainingOnHeap) init() {
	m.data.SetName("databricks.spark.block_manager.memory.remaining.on_heap")
	m.data.SetDescription("n/a")
	m.data.SetUnit("mb")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkBlockManagerMemoryRemainingOnHeap) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkBlockManagerMemoryRemainingOnHeap) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkBlockManagerMemoryRemainingOnHeap) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkBlockManagerMemoryRemainingOnHeap(cfg MetricConfig) metricDatabricksSparkBlockManagerMemoryRemainingOnHeap {
	m := metricDatabricksSparkBlockManagerMemoryRemainingOnHeap{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkBlockManagerMemoryUsed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.block_manager.memory.used metric with initial data.
func (m *metricDatabricksSparkBlockManagerMemoryUsed) init() {
	m.data.SetName("databricks.spark.block_manager.memory.used")
	m.data.SetDescription("n/a")
	m.data.SetUnit("mb")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkBlockManagerMemoryUsed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkBlockManagerMemoryUsed) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkBlockManagerMemoryUsed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkBlockManagerMemoryUsed(cfg MetricConfig) metricDatabricksSparkBlockManagerMemoryUsed {
	m := metricDatabricksSparkBlockManagerMemoryUsed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkCodeGeneratorCompilationTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.code_generator.compilation.time metric with initial data.
func (m *metricDatabricksSparkCodeGeneratorCompilationTime) init() {
	m.data.SetName("databricks.spark.code_generator.compilation.time")
	m.data.SetDescription("This value comes from the 'mean' field in a histogram returned by the /metrics/json/ endpoint.")
	m.data.SetUnit("ns")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkCodeGeneratorCompilationTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkCodeGeneratorCompilationTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkCodeGeneratorCompilationTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkCodeGeneratorCompilationTime(cfg MetricConfig) metricDatabricksSparkCodeGeneratorCompilationTime {
	m := metricDatabricksSparkCodeGeneratorCompilationTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkCodeGeneratorGeneratedClassSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.code_generator.generated_class_size metric with initial data.
func (m *metricDatabricksSparkCodeGeneratorGeneratedClassSize) init() {
	m.data.SetName("databricks.spark.code_generator.generated_class_size")
	m.data.SetDescription("This value comes from the 'mean' field in a histogram returned by the /metrics/json/ endpoint.")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkCodeGeneratorGeneratedClassSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkCodeGeneratorGeneratedClassSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkCodeGeneratorGeneratedClassSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkCodeGeneratorGeneratedClassSize(cfg MetricConfig) metricDatabricksSparkCodeGeneratorGeneratedClassSize {
	m := metricDatabricksSparkCodeGeneratorGeneratedClassSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkCodeGeneratorGeneratedMethodSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.code_generator.generated_method_size metric with initial data.
func (m *metricDatabricksSparkCodeGeneratorGeneratedMethodSize) init() {
	m.data.SetName("databricks.spark.code_generator.generated_method_size")
	m.data.SetDescription("This value comes from the 'mean' field in a histogram returned by the /metrics/json/ endpoint.")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkCodeGeneratorGeneratedMethodSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkCodeGeneratorGeneratedMethodSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkCodeGeneratorGeneratedMethodSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkCodeGeneratorGeneratedMethodSize(cfg MetricConfig) metricDatabricksSparkCodeGeneratorGeneratedMethodSize {
	m := metricDatabricksSparkCodeGeneratorGeneratedMethodSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkCodeGeneratorSourcecodeSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.code_generator.sourcecode_size metric with initial data.
func (m *metricDatabricksSparkCodeGeneratorSourcecodeSize) init() {
	m.data.SetName("databricks.spark.code_generator.sourcecode_size")
	m.data.SetDescription("This value comes from the 'mean' field in a histogram returned by the /metrics/json/ endpoint.")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkCodeGeneratorSourcecodeSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkCodeGeneratorSourcecodeSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkCodeGeneratorSourcecodeSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkCodeGeneratorSourcecodeSize(cfg MetricConfig) metricDatabricksSparkCodeGeneratorSourcecodeSize {
	m := metricDatabricksSparkCodeGeneratorSourcecodeSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDagSchedulerJobsActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.dag_scheduler.jobs.active metric with initial data.
func (m *metricDatabricksSparkDagSchedulerJobsActive) init() {
	m.data.SetName("databricks.spark.dag_scheduler.jobs.active")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{jobs}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDagSchedulerJobsActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDagSchedulerJobsActive) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDagSchedulerJobsActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDagSchedulerJobsActive(cfg MetricConfig) metricDatabricksSparkDagSchedulerJobsActive {
	m := metricDatabricksSparkDagSchedulerJobsActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDagSchedulerJobsAll struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.dag_scheduler.jobs.all metric with initial data.
func (m *metricDatabricksSparkDagSchedulerJobsAll) init() {
	m.data.SetName("databricks.spark.dag_scheduler.jobs.all")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{jobs}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDagSchedulerJobsAll) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDagSchedulerJobsAll) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDagSchedulerJobsAll) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDagSchedulerJobsAll(cfg MetricConfig) metricDatabricksSparkDagSchedulerJobsAll {
	m := metricDatabricksSparkDagSchedulerJobsAll{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDagSchedulerStagesFailed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.dag_scheduler.stages.failed metric with initial data.
func (m *metricDatabricksSparkDagSchedulerStagesFailed) init() {
	m.data.SetName("databricks.spark.dag_scheduler.stages.failed")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{stages}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDagSchedulerStagesFailed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDagSchedulerStagesFailed) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDagSchedulerStagesFailed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDagSchedulerStagesFailed(cfg MetricConfig) metricDatabricksSparkDagSchedulerStagesFailed {
	m := metricDatabricksSparkDagSchedulerStagesFailed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDagSchedulerStagesRunning struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.dag_scheduler.stages.running metric with initial data.
func (m *metricDatabricksSparkDagSchedulerStagesRunning) init() {
	m.data.SetName("databricks.spark.dag_scheduler.stages.running")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{stages}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDagSchedulerStagesRunning) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDagSchedulerStagesRunning) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDagSchedulerStagesRunning) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDagSchedulerStagesRunning(cfg MetricConfig) metricDatabricksSparkDagSchedulerStagesRunning {
	m := metricDatabricksSparkDagSchedulerStagesRunning{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDagSchedulerStagesWaiting struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.dag_scheduler.stages.waiting metric with initial data.
func (m *metricDatabricksSparkDagSchedulerStagesWaiting) init() {
	m.data.SetName("databricks.spark.dag_scheduler.stages.waiting")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{stages}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDagSchedulerStagesWaiting) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDagSchedulerStagesWaiting) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDagSchedulerStagesWaiting) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDagSchedulerStagesWaiting(cfg MetricConfig) metricDatabricksSparkDagSchedulerStagesWaiting {
	m := metricDatabricksSparkDagSchedulerStagesWaiting{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksDirectoryCommitAutoVacuumCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.directory_commit.auto_vacuum.count metric with initial data.
func (m *metricDatabricksSparkDatabricksDirectoryCommitAutoVacuumCount) init() {
	m.data.SetName("databricks.spark.databricks.directory_commit.auto_vacuum.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{auto-vacuums}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksDirectoryCommitAutoVacuumCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksDirectoryCommitAutoVacuumCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksDirectoryCommitAutoVacuumCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksDirectoryCommitAutoVacuumCount(cfg MetricConfig) metricDatabricksSparkDatabricksDirectoryCommitAutoVacuumCount {
	m := metricDatabricksSparkDatabricksDirectoryCommitAutoVacuumCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksDirectoryCommitDeletedFilesFiltered struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.directory_commit.deleted_files_filtered metric with initial data.
func (m *metricDatabricksSparkDatabricksDirectoryCommitDeletedFilesFiltered) init() {
	m.data.SetName("databricks.spark.databricks.directory_commit.deleted_files_filtered")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{files}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksDirectoryCommitDeletedFilesFiltered) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksDirectoryCommitDeletedFilesFiltered) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksDirectoryCommitDeletedFilesFiltered) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksDirectoryCommitDeletedFilesFiltered(cfg MetricConfig) metricDatabricksSparkDatabricksDirectoryCommitDeletedFilesFiltered {
	m := metricDatabricksSparkDatabricksDirectoryCommitDeletedFilesFiltered{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksDirectoryCommitFilterListingCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.directory_commit.filter_listing.count metric with initial data.
func (m *metricDatabricksSparkDatabricksDirectoryCommitFilterListingCount) init() {
	m.data.SetName("databricks.spark.databricks.directory_commit.filter_listing.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{filters}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksDirectoryCommitFilterListingCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksDirectoryCommitFilterListingCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksDirectoryCommitFilterListingCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksDirectoryCommitFilterListingCount(cfg MetricConfig) metricDatabricksSparkDatabricksDirectoryCommitFilterListingCount {
	m := metricDatabricksSparkDatabricksDirectoryCommitFilterListingCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksDirectoryCommitJobCommitCompleted struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.directory_commit.job_commit_completed metric with initial data.
func (m *metricDatabricksSparkDatabricksDirectoryCommitJobCommitCompleted) init() {
	m.data.SetName("databricks.spark.databricks.directory_commit.job_commit_completed")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{commits}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksDirectoryCommitJobCommitCompleted) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksDirectoryCommitJobCommitCompleted) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksDirectoryCommitJobCommitCompleted) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksDirectoryCommitJobCommitCompleted(cfg MetricConfig) metricDatabricksSparkDatabricksDirectoryCommitJobCommitCompleted {
	m := metricDatabricksSparkDatabricksDirectoryCommitJobCommitCompleted{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksDirectoryCommitMarkerReadErrors struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.directory_commit.marker_read.errors metric with initial data.
func (m *metricDatabricksSparkDatabricksDirectoryCommitMarkerReadErrors) init() {
	m.data.SetName("databricks.spark.databricks.directory_commit.marker_read.errors")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{errors}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksDirectoryCommitMarkerReadErrors) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksDirectoryCommitMarkerReadErrors) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksDirectoryCommitMarkerReadErrors) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksDirectoryCommitMarkerReadErrors(cfg MetricConfig) metricDatabricksSparkDatabricksDirectoryCommitMarkerReadErrors {
	m := metricDatabricksSparkDatabricksDirectoryCommitMarkerReadErrors{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.directory_commit.marker_refresh.count metric with initial data.
func (m *metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshCount) init() {
	m.data.SetName("databricks.spark.databricks.directory_commit.marker_refresh.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{refreshes}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshCount(cfg MetricConfig) metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshCount {
	m := metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrors struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.directory_commit.marker_refresh.errors metric with initial data.
func (m *metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrors) init() {
	m.data.SetName("databricks.spark.databricks.directory_commit.marker_refresh.errors")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{errors}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrors) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrors) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrors) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrors(cfg MetricConfig) metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrors {
	m := metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrors{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksDirectoryCommitMarkersRead struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.directory_commit.markers.read metric with initial data.
func (m *metricDatabricksSparkDatabricksDirectoryCommitMarkersRead) init() {
	m.data.SetName("databricks.spark.databricks.directory_commit.markers.read")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{markers}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksDirectoryCommitMarkersRead) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksDirectoryCommitMarkersRead) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksDirectoryCommitMarkersRead) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksDirectoryCommitMarkersRead(cfg MetricConfig) metricDatabricksSparkDatabricksDirectoryCommitMarkersRead {
	m := metricDatabricksSparkDatabricksDirectoryCommitMarkersRead{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksDirectoryCommitRepeatedListCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.directory_commit.repeated_list.count metric with initial data.
func (m *metricDatabricksSparkDatabricksDirectoryCommitRepeatedListCount) init() {
	m.data.SetName("databricks.spark.databricks.directory_commit.repeated_list.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{lists}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksDirectoryCommitRepeatedListCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksDirectoryCommitRepeatedListCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksDirectoryCommitRepeatedListCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksDirectoryCommitRepeatedListCount(cfg MetricConfig) metricDatabricksSparkDatabricksDirectoryCommitRepeatedListCount {
	m := metricDatabricksSparkDatabricksDirectoryCommitRepeatedListCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksDirectoryCommitUncommittedFilesFiltered struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.directory_commit.uncommitted_files.filtered metric with initial data.
func (m *metricDatabricksSparkDatabricksDirectoryCommitUncommittedFilesFiltered) init() {
	m.data.SetName("databricks.spark.databricks.directory_commit.uncommitted_files.filtered")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{files}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksDirectoryCommitUncommittedFilesFiltered) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksDirectoryCommitUncommittedFilesFiltered) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksDirectoryCommitUncommittedFilesFiltered) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksDirectoryCommitUncommittedFilesFiltered(cfg MetricConfig) metricDatabricksSparkDatabricksDirectoryCommitUncommittedFilesFiltered {
	m := metricDatabricksSparkDatabricksDirectoryCommitUncommittedFilesFiltered{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksDirectoryCommitUntrackedFilesFound struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.directory_commit.untracked_files.found metric with initial data.
func (m *metricDatabricksSparkDatabricksDirectoryCommitUntrackedFilesFound) init() {
	m.data.SetName("databricks.spark.databricks.directory_commit.untracked_files.found")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{files}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksDirectoryCommitUntrackedFilesFound) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksDirectoryCommitUntrackedFilesFound) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksDirectoryCommitUntrackedFilesFound) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksDirectoryCommitUntrackedFilesFound(cfg MetricConfig) metricDatabricksSparkDatabricksDirectoryCommitUntrackedFilesFound {
	m := metricDatabricksSparkDatabricksDirectoryCommitUntrackedFilesFound{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksDirectoryCommitVacuumCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.directory_commit.vacuum.count metric with initial data.
func (m *metricDatabricksSparkDatabricksDirectoryCommitVacuumCount) init() {
	m.data.SetName("databricks.spark.databricks.directory_commit.vacuum.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{vaccums}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksDirectoryCommitVacuumCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksDirectoryCommitVacuumCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksDirectoryCommitVacuumCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksDirectoryCommitVacuumCount(cfg MetricConfig) metricDatabricksSparkDatabricksDirectoryCommitVacuumCount {
	m := metricDatabricksSparkDatabricksDirectoryCommitVacuumCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksDirectoryCommitVacuumErrors struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.directory_commit.vacuum.errors metric with initial data.
func (m *metricDatabricksSparkDatabricksDirectoryCommitVacuumErrors) init() {
	m.data.SetName("databricks.spark.databricks.directory_commit.vacuum.errors")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{errors}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksDirectoryCommitVacuumErrors) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksDirectoryCommitVacuumErrors) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksDirectoryCommitVacuumErrors) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksDirectoryCommitVacuumErrors(cfg MetricConfig) metricDatabricksSparkDatabricksDirectoryCommitVacuumErrors {
	m := metricDatabricksSparkDatabricksDirectoryCommitVacuumErrors{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksPreemptionChecksCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.preemption.checks.count metric with initial data.
func (m *metricDatabricksSparkDatabricksPreemptionChecksCount) init() {
	m.data.SetName("databricks.spark.databricks.preemption.checks.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{checks}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksPreemptionChecksCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksPreemptionChecksCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksPreemptionChecksCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksPreemptionChecksCount(cfg MetricConfig) metricDatabricksSparkDatabricksPreemptionChecksCount {
	m := metricDatabricksSparkDatabricksPreemptionChecksCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksPreemptionPoolsAutoexpiredCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.preemption.pools_autoexpired.count metric with initial data.
func (m *metricDatabricksSparkDatabricksPreemptionPoolsAutoexpiredCount) init() {
	m.data.SetName("databricks.spark.databricks.preemption.pools_autoexpired.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{pools}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksPreemptionPoolsAutoexpiredCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksPreemptionPoolsAutoexpiredCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksPreemptionPoolsAutoexpiredCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksPreemptionPoolsAutoexpiredCount(cfg MetricConfig) metricDatabricksSparkDatabricksPreemptionPoolsAutoexpiredCount {
	m := metricDatabricksSparkDatabricksPreemptionPoolsAutoexpiredCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksPreemptionPoolstarvationTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.preemption.poolstarvation.time metric with initial data.
func (m *metricDatabricksSparkDatabricksPreemptionPoolstarvationTime) init() {
	m.data.SetName("databricks.spark.databricks.preemption.poolstarvation.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksPreemptionPoolstarvationTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksPreemptionPoolstarvationTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksPreemptionPoolstarvationTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksPreemptionPoolstarvationTime(cfg MetricConfig) metricDatabricksSparkDatabricksPreemptionPoolstarvationTime {
	m := metricDatabricksSparkDatabricksPreemptionPoolstarvationTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksPreemptionSchedulerOverheadTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.preemption.scheduler_overhead.time metric with initial data.
func (m *metricDatabricksSparkDatabricksPreemptionSchedulerOverheadTime) init() {
	m.data.SetName("databricks.spark.databricks.preemption.scheduler_overhead.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksPreemptionSchedulerOverheadTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksPreemptionSchedulerOverheadTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksPreemptionSchedulerOverheadTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksPreemptionSchedulerOverheadTime(cfg MetricConfig) metricDatabricksSparkDatabricksPreemptionSchedulerOverheadTime {
	m := metricDatabricksSparkDatabricksPreemptionSchedulerOverheadTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksPreemptionTaskWastedTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.preemption.task_wasted.time metric with initial data.
func (m *metricDatabricksSparkDatabricksPreemptionTaskWastedTime) init() {
	m.data.SetName("databricks.spark.databricks.preemption.task_wasted.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksPreemptionTaskWastedTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksPreemptionTaskWastedTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksPreemptionTaskWastedTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksPreemptionTaskWastedTime(cfg MetricConfig) metricDatabricksSparkDatabricksPreemptionTaskWastedTime {
	m := metricDatabricksSparkDatabricksPreemptionTaskWastedTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksPreemptionTasksPreemptedCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.preemption.tasks_preempted.count metric with initial data.
func (m *metricDatabricksSparkDatabricksPreemptionTasksPreemptedCount) init() {
	m.data.SetName("databricks.spark.databricks.preemption.tasks_preempted.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{tasks}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksPreemptionTasksPreemptedCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksPreemptionTasksPreemptedCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksPreemptionTasksPreemptedCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksPreemptionTasksPreemptedCount(cfg MetricConfig) metricDatabricksSparkDatabricksPreemptionTasksPreemptedCount {
	m := metricDatabricksSparkDatabricksPreemptionTasksPreemptedCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksTaskSchedulingLanesActivePools struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.task_scheduling_lanes.active_pools metric with initial data.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesActivePools) init() {
	m.data.SetName("databricks.spark.databricks.task_scheduling_lanes.active_pools")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{pools}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesActivePools) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesActivePools) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesActivePools) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksTaskSchedulingLanesActivePools(cfg MetricConfig) metricDatabricksSparkDatabricksTaskSchedulingLanesActivePools {
	m := metricDatabricksSparkDatabricksTaskSchedulingLanesActivePools{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePools struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.task_scheduling_lanes.bypass_lane_active_pools metric with initial data.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePools) init() {
	m.data.SetName("databricks.spark.databricks.task_scheduling_lanes.bypass_lane_active_pools")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{pools}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePools) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePools) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePools) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePools(cfg MetricConfig) metricDatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePools {
	m := metricDatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePools{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePools struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.task_scheduling_lanes.fast_lane_active_pools metric with initial data.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePools) init() {
	m.data.SetName("databricks.spark.databricks.task_scheduling_lanes.fast_lane_active_pools")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{pools}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePools) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePools) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePools) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePools(cfg MetricConfig) metricDatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePools {
	m := metricDatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePools{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.task_scheduling_lanes.finished_queries_total_task.time metric with initial data.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTime) init() {
	m.data.SetName("databricks.spark.databricks.task_scheduling_lanes.finished_queries_total_task.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTime(cfg MetricConfig) metricDatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTime {
	m := metricDatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPools struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.task_scheduling_lanes.lane_cleanup.marked_pools metric with initial data.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPools) init() {
	m.data.SetName("databricks.spark.databricks.task_scheduling_lanes.lane_cleanup.marked_pools")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{pools}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPools) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPools) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPools) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPools(cfg MetricConfig) metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPools {
	m := metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPools{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleaned struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.task_scheduling_lanes.lane_cleanup.two_phase_pools_cleaned metric with initial data.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleaned) init() {
	m.data.SetName("databricks.spark.databricks.task_scheduling_lanes.lane_cleanup.two_phase_pools_cleaned")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{pools}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleaned) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleaned) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleaned) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleaned(cfg MetricConfig) metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleaned {
	m := metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleaned{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleaned struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.task_scheduling_lanes.lane_cleanup.zombie_pools_cleaned metric with initial data.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleaned) init() {
	m.data.SetName("databricks.spark.databricks.task_scheduling_lanes.lane_cleanup.zombie_pools_cleaned")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{pools}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleaned) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleaned) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleaned) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleaned(cfg MetricConfig) metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleaned {
	m := metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleaned{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.task_scheduling_lanes.preemption.slot_transfer_successful_preemption_iterations.count metric with initial data.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCount) init() {
	m.data.SetName("databricks.spark.databricks.task_scheduling_lanes.preemption.slot_transfer_successful_preemption_iterations.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{slots}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCount(cfg MetricConfig) metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCount {
	m := metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.task_scheduling_lanes.preemption.slot_transfer_tasks_preempted.count metric with initial data.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCount) init() {
	m.data.SetName("databricks.spark.databricks.task_scheduling_lanes.preemption.slot_transfer_tasks_preempted.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{slots}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCount(cfg MetricConfig) metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCount {
	m := metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.task_scheduling_lanes.preemption.slot_transfer_wasted_task.time metric with initial data.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTime) init() {
	m.data.SetName("databricks.spark.databricks.task_scheduling_lanes.preemption.slot_transfer_wasted_task.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTime(cfg MetricConfig) metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTime {
	m := metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.task_scheduling_lanes.slot_reservation.gradual_decrease.count metric with initial data.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCount) init() {
	m.data.SetName("databricks.spark.databricks.task_scheduling_lanes.slot_reservation.gradual_decrease.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{slot reservations}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCount(cfg MetricConfig) metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCount {
	m := metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.task_scheduling_lanes.slot_reservation.quick_drop.count metric with initial data.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCount) init() {
	m.data.SetName("databricks.spark.databricks.task_scheduling_lanes.slot_reservation.quick_drop.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{slot reservations}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCount(cfg MetricConfig) metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCount {
	m := metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.task_scheduling_lanes.slot_reservation.quick_jump.count metric with initial data.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCount) init() {
	m.data.SetName("databricks.spark.databricks.task_scheduling_lanes.slot_reservation.quick_jump.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{slot reservations}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCount(cfg MetricConfig) metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCount {
	m := metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReserved struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.task_scheduling_lanes.slot_reservation.slots_reserved metric with initial data.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReserved) init() {
	m.data.SetName("databricks.spark.databricks.task_scheduling_lanes.slot_reservation.slots_reserved")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{slot reservations}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReserved) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReserved) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReserved) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReserved(cfg MetricConfig) metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReserved {
	m := metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReserved{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePools struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.task_scheduling_lanes.slow_lane_active_pools metric with initial data.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePools) init() {
	m.data.SetName("databricks.spark.databricks.task_scheduling_lanes.slow_lane_active_pools")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{pools}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePools) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePools) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePools) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePools(cfg MetricConfig) metricDatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePools {
	m := metricDatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePools{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinished struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.databricks.task_scheduling_lanes.totalquerygroupsfinished metric with initial data.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinished) init() {
	m.data.SetName("databricks.spark.databricks.task_scheduling_lanes.totalquerygroupsfinished")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{query groups}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinished) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinished) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinished) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinished(cfg MetricConfig) metricDatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinished {
	m := metricDatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinished{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorDiskUsed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor.disk_used metric with initial data.
func (m *metricDatabricksSparkExecutorDiskUsed) init() {
	m.data.SetName("databricks.spark.executor.disk_used")
	m.data.SetDescription("n/a")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorDiskUsed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkExecutorIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("spark.executor.id", sparkExecutorIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorDiskUsed) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorDiskUsed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorDiskUsed(cfg MetricConfig) metricDatabricksSparkExecutorDiskUsed {
	m := metricDatabricksSparkExecutorDiskUsed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMaxMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor.max_memory metric with initial data.
func (m *metricDatabricksSparkExecutorMaxMemory) init() {
	m.data.SetName("databricks.spark.executor.max_memory")
	m.data.SetDescription("n/a")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMaxMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkExecutorIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("spark.executor.id", sparkExecutorIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMaxMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMaxMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMaxMemory(cfg MetricConfig) metricDatabricksSparkExecutorMaxMemory {
	m := metricDatabricksSparkExecutorMaxMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMemoryUsed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor.memory_used metric with initial data.
func (m *metricDatabricksSparkExecutorMemoryUsed) init() {
	m.data.SetName("databricks.spark.executor.memory_used")
	m.data.SetDescription("n/a")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMemoryUsed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkExecutorIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("spark.executor.id", sparkExecutorIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMemoryUsed) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMemoryUsed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMemoryUsed(cfg MetricConfig) metricDatabricksSparkExecutorMemoryUsed {
	m := metricDatabricksSparkExecutorMemoryUsed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorTotalInputBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor.total_input_bytes metric with initial data.
func (m *metricDatabricksSparkExecutorTotalInputBytes) init() {
	m.data.SetName("databricks.spark.executor.total_input_bytes")
	m.data.SetDescription("n/a")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorTotalInputBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkExecutorIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("spark.executor.id", sparkExecutorIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorTotalInputBytes) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorTotalInputBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorTotalInputBytes(cfg MetricConfig) metricDatabricksSparkExecutorTotalInputBytes {
	m := metricDatabricksSparkExecutorTotalInputBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorTotalShuffleRead struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor.total_shuffle_read metric with initial data.
func (m *metricDatabricksSparkExecutorTotalShuffleRead) init() {
	m.data.SetName("databricks.spark.executor.total_shuffle_read")
	m.data.SetDescription("n/a")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorTotalShuffleRead) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkExecutorIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("spark.executor.id", sparkExecutorIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorTotalShuffleRead) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorTotalShuffleRead) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorTotalShuffleRead(cfg MetricConfig) metricDatabricksSparkExecutorTotalShuffleRead {
	m := metricDatabricksSparkExecutorTotalShuffleRead{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorTotalShuffleWrite struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor.total_shuffle_write metric with initial data.
func (m *metricDatabricksSparkExecutorTotalShuffleWrite) init() {
	m.data.SetName("databricks.spark.executor.total_shuffle_write")
	m.data.SetDescription("n/a")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorTotalShuffleWrite) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkExecutorIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("spark.executor.id", sparkExecutorIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorTotalShuffleWrite) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorTotalShuffleWrite) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorTotalShuffleWrite(cfg MetricConfig) metricDatabricksSparkExecutorTotalShuffleWrite {
	m := metricDatabricksSparkExecutorTotalShuffleWrite{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsDirectPoolMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.direct_pool.memory metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsDirectPoolMemory) init() {
	m.data.SetName("databricks.spark.executor_metrics.direct_pool.memory")
	m.data.SetDescription("Peak memory that the JVM is using for direct buffer pool")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsDirectPoolMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsDirectPoolMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsDirectPoolMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsDirectPoolMemory(cfg MetricConfig) metricDatabricksSparkExecutorMetricsDirectPoolMemory {
	m := metricDatabricksSparkExecutorMetricsDirectPoolMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsJvmHeapMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.jvm.heap.memory metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsJvmHeapMemory) init() {
	m.data.SetName("databricks.spark.executor_metrics.jvm.heap.memory")
	m.data.SetDescription("Peak memory usage of the heap that is used for object allocation. See https://spark.apache.org/docs/latest/monitoring.html")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsJvmHeapMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsJvmHeapMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsJvmHeapMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsJvmHeapMemory(cfg MetricConfig) metricDatabricksSparkExecutorMetricsJvmHeapMemory {
	m := metricDatabricksSparkExecutorMetricsJvmHeapMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsJvmOffHeapMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.jvm.off_heap.memory metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsJvmOffHeapMemory) init() {
	m.data.SetName("databricks.spark.executor_metrics.jvm.off_heap.memory")
	m.data.SetDescription("Peak memory usage of non-heap memory that is used by the Java virtual machine. See https://spark.apache.org/docs/latest/monitoring.html")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsJvmOffHeapMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsJvmOffHeapMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsJvmOffHeapMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsJvmOffHeapMemory(cfg MetricConfig) metricDatabricksSparkExecutorMetricsJvmOffHeapMemory {
	m := metricDatabricksSparkExecutorMetricsJvmOffHeapMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsMajorGcCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.major_gc.count metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsMajorGcCount) init() {
	m.data.SetName("databricks.spark.executor_metrics.major_gc.count")
	m.data.SetDescription("Total major GC count. For example, the garbage collector is one of MarkSweepCompact, PS MarkSweep, ConcurrentMarkSweep, G1 Old Generation and so on.")
	m.data.SetUnit("{gc_operations}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsMajorGcCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsMajorGcCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsMajorGcCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsMajorGcCount(cfg MetricConfig) metricDatabricksSparkExecutorMetricsMajorGcCount {
	m := metricDatabricksSparkExecutorMetricsMajorGcCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsMajorGcTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.major_gc.time metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsMajorGcTime) init() {
	m.data.SetName("databricks.spark.executor_metrics.major_gc.time")
	m.data.SetDescription("Elapsed total major GC time.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsMajorGcTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsMajorGcTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsMajorGcTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsMajorGcTime(cfg MetricConfig) metricDatabricksSparkExecutorMetricsMajorGcTime {
	m := metricDatabricksSparkExecutorMetricsMajorGcTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsMappedPoolMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.mapped_pool.memory metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsMappedPoolMemory) init() {
	m.data.SetName("databricks.spark.executor_metrics.mapped_pool.memory")
	m.data.SetDescription("Peak memory that the JVM is using for mapped buffer pool")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsMappedPoolMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsMappedPoolMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsMappedPoolMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsMappedPoolMemory(cfg MetricConfig) metricDatabricksSparkExecutorMetricsMappedPoolMemory {
	m := metricDatabricksSparkExecutorMetricsMappedPoolMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsMinorGcCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.minor_gc.count metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsMinorGcCount) init() {
	m.data.SetName("databricks.spark.executor_metrics.minor_gc.count")
	m.data.SetDescription("Total minor GC count. For example, the garbage collector is one of Copy, PS Scavenge, ParNew, G1 Young Generation and so on.")
	m.data.SetUnit("{gc}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsMinorGcCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsMinorGcCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsMinorGcCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsMinorGcCount(cfg MetricConfig) metricDatabricksSparkExecutorMetricsMinorGcCount {
	m := metricDatabricksSparkExecutorMetricsMinorGcCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsMinorGcTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.minor_gc.time metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsMinorGcTime) init() {
	m.data.SetName("databricks.spark.executor_metrics.minor_gc.time")
	m.data.SetDescription("Elapsed total minor GC time.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsMinorGcTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsMinorGcTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsMinorGcTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsMinorGcTime(cfg MetricConfig) metricDatabricksSparkExecutorMetricsMinorGcTime {
	m := metricDatabricksSparkExecutorMetricsMinorGcTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsOffHeapExecutionMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.off_heap.execution.memory metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsOffHeapExecutionMemory) init() {
	m.data.SetName("databricks.spark.executor_metrics.off_heap.execution.memory")
	m.data.SetDescription("Peak off heap execution memory in use, in bytes.")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsOffHeapExecutionMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsOffHeapExecutionMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsOffHeapExecutionMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsOffHeapExecutionMemory(cfg MetricConfig) metricDatabricksSparkExecutorMetricsOffHeapExecutionMemory {
	m := metricDatabricksSparkExecutorMetricsOffHeapExecutionMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsOffHeapStorageMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.off_heap.storage.memory metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsOffHeapStorageMemory) init() {
	m.data.SetName("databricks.spark.executor_metrics.off_heap.storage.memory")
	m.data.SetDescription("Peak off heap storage memory in use, in bytes.")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsOffHeapStorageMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsOffHeapStorageMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsOffHeapStorageMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsOffHeapStorageMemory(cfg MetricConfig) metricDatabricksSparkExecutorMetricsOffHeapStorageMemory {
	m := metricDatabricksSparkExecutorMetricsOffHeapStorageMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsOffHeapUnifiedMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.off_heap.unified.memory metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsOffHeapUnifiedMemory) init() {
	m.data.SetName("databricks.spark.executor_metrics.off_heap.unified.memory")
	m.data.SetDescription("Peak off heap memory (execution and storage).")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsOffHeapUnifiedMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsOffHeapUnifiedMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsOffHeapUnifiedMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsOffHeapUnifiedMemory(cfg MetricConfig) metricDatabricksSparkExecutorMetricsOffHeapUnifiedMemory {
	m := metricDatabricksSparkExecutorMetricsOffHeapUnifiedMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsOnHeapExecutionMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.on_heap.execution.memory metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsOnHeapExecutionMemory) init() {
	m.data.SetName("databricks.spark.executor_metrics.on_heap.execution.memory")
	m.data.SetDescription("Peak on heap memory (execution and storage).")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsOnHeapExecutionMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsOnHeapExecutionMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsOnHeapExecutionMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsOnHeapExecutionMemory(cfg MetricConfig) metricDatabricksSparkExecutorMetricsOnHeapExecutionMemory {
	m := metricDatabricksSparkExecutorMetricsOnHeapExecutionMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsOnHeapStorageMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.on_heap.storage.memory metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsOnHeapStorageMemory) init() {
	m.data.SetName("databricks.spark.executor_metrics.on_heap.storage.memory")
	m.data.SetDescription("Peak on heap storage memory in use, in bytes.")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsOnHeapStorageMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsOnHeapStorageMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsOnHeapStorageMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsOnHeapStorageMemory(cfg MetricConfig) metricDatabricksSparkExecutorMetricsOnHeapStorageMemory {
	m := metricDatabricksSparkExecutorMetricsOnHeapStorageMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsOnHeapUnifiedMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.on_heap.unified.memory metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsOnHeapUnifiedMemory) init() {
	m.data.SetName("databricks.spark.executor_metrics.on_heap.unified.memory")
	m.data.SetDescription("Peak on heap memory (execution and storage).")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsOnHeapUnifiedMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsOnHeapUnifiedMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsOnHeapUnifiedMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsOnHeapUnifiedMemory(cfg MetricConfig) metricDatabricksSparkExecutorMetricsOnHeapUnifiedMemory {
	m := metricDatabricksSparkExecutorMetricsOnHeapUnifiedMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsProcessTreeJvmRssMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.process_tree.jvm_rss.memory metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsProcessTreeJvmRssMemory) init() {
	m.data.SetName("databricks.spark.executor_metrics.process_tree.jvm_rss.memory")
	m.data.SetDescription("Resident Set Size: number of pages the process has in real memory. This is just the pages which count toward text, data, or stack space. This does not include pages which have not been demand-loaded in, or which are swapped out. Enabled if spark.executor.processTreeMetrics.enabled is true.")
	m.data.SetUnit("{pages}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsProcessTreeJvmRssMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsProcessTreeJvmRssMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsProcessTreeJvmRssMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsProcessTreeJvmRssMemory(cfg MetricConfig) metricDatabricksSparkExecutorMetricsProcessTreeJvmRssMemory {
	m := metricDatabricksSparkExecutorMetricsProcessTreeJvmRssMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsProcessTreeJvmVMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.process_tree.jvm_v.memory metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsProcessTreeJvmVMemory) init() {
	m.data.SetName("databricks.spark.executor_metrics.process_tree.jvm_v.memory")
	m.data.SetDescription("Virtual memory size in bytes. Enabled if spark.executor.processTreeMetrics.enabled is true.")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsProcessTreeJvmVMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsProcessTreeJvmVMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsProcessTreeJvmVMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsProcessTreeJvmVMemory(cfg MetricConfig) metricDatabricksSparkExecutorMetricsProcessTreeJvmVMemory {
	m := metricDatabricksSparkExecutorMetricsProcessTreeJvmVMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsProcessTreeOtherRssMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.process_tree.other_rss.memory metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsProcessTreeOtherRssMemory) init() {
	m.data.SetName("databricks.spark.executor_metrics.process_tree.other_rss.memory")
	m.data.SetDescription("Resident Set Size for other kind of process. Enabled if spark.executor.processTreeMetrics.enabled is true.")
	m.data.SetUnit("{pages}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsProcessTreeOtherRssMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsProcessTreeOtherRssMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsProcessTreeOtherRssMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsProcessTreeOtherRssMemory(cfg MetricConfig) metricDatabricksSparkExecutorMetricsProcessTreeOtherRssMemory {
	m := metricDatabricksSparkExecutorMetricsProcessTreeOtherRssMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsProcessTreeOtherVMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.process_tree.other_v.memory metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsProcessTreeOtherVMemory) init() {
	m.data.SetName("databricks.spark.executor_metrics.process_tree.other_v.memory")
	m.data.SetDescription("Virtual memory size for other kind of process in bytes. Enabled if spark.executor.processTreeMetrics.enabled is true.")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsProcessTreeOtherVMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsProcessTreeOtherVMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsProcessTreeOtherVMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsProcessTreeOtherVMemory(cfg MetricConfig) metricDatabricksSparkExecutorMetricsProcessTreeOtherVMemory {
	m := metricDatabricksSparkExecutorMetricsProcessTreeOtherVMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsProcessTreePythonRssMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.process_tree.python_rss.memory metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsProcessTreePythonRssMemory) init() {
	m.data.SetName("databricks.spark.executor_metrics.process_tree.python_rss.memory")
	m.data.SetDescription("Resident Set Size for Python. Enabled if spark.executor.processTreeMetrics.enabled is true.")
	m.data.SetUnit("{pages}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsProcessTreePythonRssMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsProcessTreePythonRssMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsProcessTreePythonRssMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsProcessTreePythonRssMemory(cfg MetricConfig) metricDatabricksSparkExecutorMetricsProcessTreePythonRssMemory {
	m := metricDatabricksSparkExecutorMetricsProcessTreePythonRssMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkExecutorMetricsProcessTreePythonVMemory struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.executor_metrics.process_tree.python_v.memory metric with initial data.
func (m *metricDatabricksSparkExecutorMetricsProcessTreePythonVMemory) init() {
	m.data.SetName("databricks.spark.executor_metrics.process_tree.python_v.memory")
	m.data.SetDescription("Virtual memory size for Python in bytes. Enabled if spark.executor.processTreeMetrics.enabled is true.")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkExecutorMetricsProcessTreePythonVMemory) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkExecutorMetricsProcessTreePythonVMemory) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkExecutorMetricsProcessTreePythonVMemory) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkExecutorMetricsProcessTreePythonVMemory(cfg MetricConfig) metricDatabricksSparkExecutorMetricsProcessTreePythonVMemory {
	m := metricDatabricksSparkExecutorMetricsProcessTreePythonVMemory{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkHiveExternalCatalogFileCacheHits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.hive_external_catalog.file_cache.hits metric with initial data.
func (m *metricDatabricksSparkHiveExternalCatalogFileCacheHits) init() {
	m.data.SetName("databricks.spark.hive_external_catalog.file_cache.hits")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{hits}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkHiveExternalCatalogFileCacheHits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkHiveExternalCatalogFileCacheHits) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkHiveExternalCatalogFileCacheHits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkHiveExternalCatalogFileCacheHits(cfg MetricConfig) metricDatabricksSparkHiveExternalCatalogFileCacheHits {
	m := metricDatabricksSparkHiveExternalCatalogFileCacheHits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkHiveExternalCatalogFilesDiscovered struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.hive_external_catalog.files_discovered metric with initial data.
func (m *metricDatabricksSparkHiveExternalCatalogFilesDiscovered) init() {
	m.data.SetName("databricks.spark.hive_external_catalog.files_discovered")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{files}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkHiveExternalCatalogFilesDiscovered) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkHiveExternalCatalogFilesDiscovered) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkHiveExternalCatalogFilesDiscovered) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkHiveExternalCatalogFilesDiscovered(cfg MetricConfig) metricDatabricksSparkHiveExternalCatalogFilesDiscovered {
	m := metricDatabricksSparkHiveExternalCatalogFilesDiscovered{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkHiveExternalCatalogHiveClientCalls struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.hive_external_catalog.hive_client_calls metric with initial data.
func (m *metricDatabricksSparkHiveExternalCatalogHiveClientCalls) init() {
	m.data.SetName("databricks.spark.hive_external_catalog.hive_client_calls")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{calls}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkHiveExternalCatalogHiveClientCalls) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkHiveExternalCatalogHiveClientCalls) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkHiveExternalCatalogHiveClientCalls) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkHiveExternalCatalogHiveClientCalls(cfg MetricConfig) metricDatabricksSparkHiveExternalCatalogHiveClientCalls {
	m := metricDatabricksSparkHiveExternalCatalogHiveClientCalls{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkHiveExternalCatalogParallelListingJobsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.hive_external_catalog.parallel_listing_jobs.count metric with initial data.
func (m *metricDatabricksSparkHiveExternalCatalogParallelListingJobsCount) init() {
	m.data.SetName("databricks.spark.hive_external_catalog.parallel_listing_jobs.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{jobs}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkHiveExternalCatalogParallelListingJobsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkHiveExternalCatalogParallelListingJobsCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkHiveExternalCatalogParallelListingJobsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkHiveExternalCatalogParallelListingJobsCount(cfg MetricConfig) metricDatabricksSparkHiveExternalCatalogParallelListingJobsCount {
	m := metricDatabricksSparkHiveExternalCatalogParallelListingJobsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkHiveExternalCatalogPartitionsFetched struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.hive_external_catalog.partitions_fetched metric with initial data.
func (m *metricDatabricksSparkHiveExternalCatalogPartitionsFetched) init() {
	m.data.SetName("databricks.spark.hive_external_catalog.partitions_fetched")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{partitions}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkHiveExternalCatalogPartitionsFetched) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkHiveExternalCatalogPartitionsFetched) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkHiveExternalCatalogPartitionsFetched) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkHiveExternalCatalogPartitionsFetched(cfg MetricConfig) metricDatabricksSparkHiveExternalCatalogPartitionsFetched {
	m := metricDatabricksSparkHiveExternalCatalogPartitionsFetched{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkJobNumActiveStages struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.job.num_active_stages metric with initial data.
func (m *metricDatabricksSparkJobNumActiveStages) init() {
	m.data.SetName("databricks.spark.job.num_active_stages")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{stages}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkJobNumActiveStages) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutInt("spark.job.id", sparkJobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkJobNumActiveStages) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkJobNumActiveStages) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkJobNumActiveStages(cfg MetricConfig) metricDatabricksSparkJobNumActiveStages {
	m := metricDatabricksSparkJobNumActiveStages{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkJobNumActiveTasks struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.job.num_active_tasks metric with initial data.
func (m *metricDatabricksSparkJobNumActiveTasks) init() {
	m.data.SetName("databricks.spark.job.num_active_tasks")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{tasks}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkJobNumActiveTasks) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutInt("spark.job.id", sparkJobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkJobNumActiveTasks) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkJobNumActiveTasks) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkJobNumActiveTasks(cfg MetricConfig) metricDatabricksSparkJobNumActiveTasks {
	m := metricDatabricksSparkJobNumActiveTasks{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkJobNumCompletedStages struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.job.num_completed_stages metric with initial data.
func (m *metricDatabricksSparkJobNumCompletedStages) init() {
	m.data.SetName("databricks.spark.job.num_completed_stages")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{stages}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkJobNumCompletedStages) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutInt("spark.job.id", sparkJobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkJobNumCompletedStages) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkJobNumCompletedStages) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkJobNumCompletedStages(cfg MetricConfig) metricDatabricksSparkJobNumCompletedStages {
	m := metricDatabricksSparkJobNumCompletedStages{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkJobNumCompletedTasks struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.job.num_completed_tasks metric with initial data.
func (m *metricDatabricksSparkJobNumCompletedTasks) init() {
	m.data.SetName("databricks.spark.job.num_completed_tasks")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{tasks}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkJobNumCompletedTasks) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutInt("spark.job.id", sparkJobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkJobNumCompletedTasks) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkJobNumCompletedTasks) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkJobNumCompletedTasks(cfg MetricConfig) metricDatabricksSparkJobNumCompletedTasks {
	m := metricDatabricksSparkJobNumCompletedTasks{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkJobNumFailedStages struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.job.num_failed_stages metric with initial data.
func (m *metricDatabricksSparkJobNumFailedStages) init() {
	m.data.SetName("databricks.spark.job.num_failed_stages")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{stages}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkJobNumFailedStages) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutInt("spark.job.id", sparkJobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkJobNumFailedStages) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkJobNumFailedStages) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkJobNumFailedStages(cfg MetricConfig) metricDatabricksSparkJobNumFailedStages {
	m := metricDatabricksSparkJobNumFailedStages{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkJobNumFailedTasks struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.job.num_failed_tasks metric with initial data.
func (m *metricDatabricksSparkJobNumFailedTasks) init() {
	m.data.SetName("databricks.spark.job.num_failed_tasks")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{tasks}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkJobNumFailedTasks) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutInt("spark.job.id", sparkJobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkJobNumFailedTasks) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkJobNumFailedTasks) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkJobNumFailedTasks(cfg MetricConfig) metricDatabricksSparkJobNumFailedTasks {
	m := metricDatabricksSparkJobNumFailedTasks{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkJobNumSkippedStages struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.job.num_skipped_stages metric with initial data.
func (m *metricDatabricksSparkJobNumSkippedStages) init() {
	m.data.SetName("databricks.spark.job.num_skipped_stages")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{stages}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkJobNumSkippedStages) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutInt("spark.job.id", sparkJobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkJobNumSkippedStages) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkJobNumSkippedStages) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkJobNumSkippedStages(cfg MetricConfig) metricDatabricksSparkJobNumSkippedStages {
	m := metricDatabricksSparkJobNumSkippedStages{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkJobNumSkippedTasks struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.job.num_skipped_tasks metric with initial data.
func (m *metricDatabricksSparkJobNumSkippedTasks) init() {
	m.data.SetName("databricks.spark.job.num_skipped_tasks")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{tasks}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkJobNumSkippedTasks) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutInt("spark.job.id", sparkJobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkJobNumSkippedTasks) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkJobNumSkippedTasks) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkJobNumSkippedTasks(cfg MetricConfig) metricDatabricksSparkJobNumSkippedTasks {
	m := metricDatabricksSparkJobNumSkippedTasks{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkJobNumTasks struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.job.num_tasks metric with initial data.
func (m *metricDatabricksSparkJobNumTasks) init() {
	m.data.SetName("databricks.spark.job.num_tasks")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{tasks}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkJobNumTasks) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutInt("spark.job.id", sparkJobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkJobNumTasks) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkJobNumTasks) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkJobNumTasks(cfg MetricConfig) metricDatabricksSparkJobNumTasks {
	m := metricDatabricksSparkJobNumTasks{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkJvmCPUTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.jvm.cpu.time metric with initial data.
func (m *metricDatabricksSparkJvmCPUTime) init() {
	m.data.SetName("databricks.spark.jvm.cpu.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ns")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkJvmCPUTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkJvmCPUTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkJvmCPUTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkJvmCPUTime(cfg MetricConfig) metricDatabricksSparkJvmCPUTime {
	m := metricDatabricksSparkJvmCPUTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkLiveListenerBusEventsPostedCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.live_listener_bus.events_posted.count metric with initial data.
func (m *metricDatabricksSparkLiveListenerBusEventsPostedCount) init() {
	m.data.SetName("databricks.spark.live_listener_bus.events_posted.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{events}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkLiveListenerBusEventsPostedCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkLiveListenerBusEventsPostedCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkLiveListenerBusEventsPostedCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkLiveListenerBusEventsPostedCount(cfg MetricConfig) metricDatabricksSparkLiveListenerBusEventsPostedCount {
	m := metricDatabricksSparkLiveListenerBusEventsPostedCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.live_listener_bus.queue.app_status.dropped_events.count metric with initial data.
func (m *metricDatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCount) init() {
	m.data.SetName("databricks.spark.live_listener_bus.queue.app_status.dropped_events.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{events}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCount(cfg MetricConfig) metricDatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCount {
	m := metricDatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkLiveListenerBusQueueAppstatusSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.live_listener_bus.queue.appstatus.size metric with initial data.
func (m *metricDatabricksSparkLiveListenerBusQueueAppstatusSize) init() {
	m.data.SetName("databricks.spark.live_listener_bus.queue.appstatus.size")
	m.data.SetDescription("n/a")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkLiveListenerBusQueueAppstatusSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkLiveListenerBusQueueAppstatusSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkLiveListenerBusQueueAppstatusSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkLiveListenerBusQueueAppstatusSize(cfg MetricConfig) metricDatabricksSparkLiveListenerBusQueueAppstatusSize {
	m := metricDatabricksSparkLiveListenerBusQueueAppstatusSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.live_listener_bus.queue.executor_management.dropped_events.count metric with initial data.
func (m *metricDatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCount) init() {
	m.data.SetName("databricks.spark.live_listener_bus.queue.executor_management.dropped_events.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{events}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCount(cfg MetricConfig) metricDatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCount {
	m := metricDatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkLiveListenerBusQueueExecutormanagementSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.live_listener_bus.queue.executormanagement.size metric with initial data.
func (m *metricDatabricksSparkLiveListenerBusQueueExecutormanagementSize) init() {
	m.data.SetName("databricks.spark.live_listener_bus.queue.executormanagement.size")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{executor}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkLiveListenerBusQueueExecutormanagementSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkLiveListenerBusQueueExecutormanagementSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkLiveListenerBusQueueExecutormanagementSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkLiveListenerBusQueueExecutormanagementSize(cfg MetricConfig) metricDatabricksSparkLiveListenerBusQueueExecutormanagementSize {
	m := metricDatabricksSparkLiveListenerBusQueueExecutormanagementSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkLiveListenerBusQueueSharedDroppedEventsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.live_listener_bus.queue.shared.dropped_events.count metric with initial data.
func (m *metricDatabricksSparkLiveListenerBusQueueSharedDroppedEventsCount) init() {
	m.data.SetName("databricks.spark.live_listener_bus.queue.shared.dropped_events.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{events}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkLiveListenerBusQueueSharedDroppedEventsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkLiveListenerBusQueueSharedDroppedEventsCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkLiveListenerBusQueueSharedDroppedEventsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkLiveListenerBusQueueSharedDroppedEventsCount(cfg MetricConfig) metricDatabricksSparkLiveListenerBusQueueSharedDroppedEventsCount {
	m := metricDatabricksSparkLiveListenerBusQueueSharedDroppedEventsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkLiveListenerBusQueueSharedSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.live_listener_bus.queue.shared.size metric with initial data.
func (m *metricDatabricksSparkLiveListenerBusQueueSharedSize) init() {
	m.data.SetName("databricks.spark.live_listener_bus.queue.shared.size")
	m.data.SetDescription("n/a")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkLiveListenerBusQueueSharedSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkLiveListenerBusQueueSharedSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkLiveListenerBusQueueSharedSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkLiveListenerBusQueueSharedSize(cfg MetricConfig) metricDatabricksSparkLiveListenerBusQueueSharedSize {
	m := metricDatabricksSparkLiveListenerBusQueueSharedSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.live_listener_bus.queue.streams.dropped_events.count metric with initial data.
func (m *metricDatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCount) init() {
	m.data.SetName("databricks.spark.live_listener_bus.queue.streams.dropped_events.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{events}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCount(cfg MetricConfig) metricDatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCount {
	m := metricDatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkLiveListenerBusQueueStreamsSize struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.live_listener_bus.queue.streams.size metric with initial data.
func (m *metricDatabricksSparkLiveListenerBusQueueStreamsSize) init() {
	m.data.SetName("databricks.spark.live_listener_bus.queue.streams.size")
	m.data.SetDescription("n/a")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkLiveListenerBusQueueStreamsSize) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkLiveListenerBusQueueStreamsSize) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkLiveListenerBusQueueStreamsSize) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkLiveListenerBusQueueStreamsSize(cfg MetricConfig) metricDatabricksSparkLiveListenerBusQueueStreamsSize {
	m := metricDatabricksSparkLiveListenerBusQueueStreamsSize{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkSparkSQLOperationManagerHiveOperationsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.spark_sql_operation_manager.hive_operations.count metric with initial data.
func (m *metricDatabricksSparkSparkSQLOperationManagerHiveOperationsCount) init() {
	m.data.SetName("databricks.spark.spark_sql_operation_manager.hive_operations.count")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{operations}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkSparkSQLOperationManagerHiveOperationsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutStr("pipeline.id", pipelineIDAttributeValue)
	dp.Attributes().PutStr("pipeline.name", pipelineNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkSparkSQLOperationManagerHiveOperationsCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkSparkSQLOperationManagerHiveOperationsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkSparkSQLOperationManagerHiveOperationsCount(cfg MetricConfig) metricDatabricksSparkSparkSQLOperationManagerHiveOperationsCount {
	m := metricDatabricksSparkSparkSQLOperationManagerHiveOperationsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkStageDiskBytesSpilled struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.stage.disk_bytes_spilled metric with initial data.
func (m *metricDatabricksSparkStageDiskBytesSpilled) init() {
	m.data.SetName("databricks.spark.stage.disk_bytes_spilled")
	m.data.SetDescription("n/a")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkStageDiskBytesSpilled) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutInt("spark.job.id", sparkJobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkStageDiskBytesSpilled) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkStageDiskBytesSpilled) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkStageDiskBytesSpilled(cfg MetricConfig) metricDatabricksSparkStageDiskBytesSpilled {
	m := metricDatabricksSparkStageDiskBytesSpilled{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkStageExecutorRunTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.stage.executor_run_time metric with initial data.
func (m *metricDatabricksSparkStageExecutorRunTime) init() {
	m.data.SetName("databricks.spark.stage.executor_run_time")
	m.data.SetDescription("Elapsed time the executor spent running this task. This includes time fetching shuffle data. See https://spark.apache.org/docs/latest/monitoring.html#executor-metrics")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkStageExecutorRunTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutInt("spark.job.id", sparkJobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkStageExecutorRunTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkStageExecutorRunTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkStageExecutorRunTime(cfg MetricConfig) metricDatabricksSparkStageExecutorRunTime {
	m := metricDatabricksSparkStageExecutorRunTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkStageInputBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.stage.input_bytes metric with initial data.
func (m *metricDatabricksSparkStageInputBytes) init() {
	m.data.SetName("databricks.spark.stage.input_bytes")
	m.data.SetDescription("n/a")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkStageInputBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutInt("spark.job.id", sparkJobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkStageInputBytes) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkStageInputBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkStageInputBytes(cfg MetricConfig) metricDatabricksSparkStageInputBytes {
	m := metricDatabricksSparkStageInputBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkStageInputRecords struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.stage.input_records metric with initial data.
func (m *metricDatabricksSparkStageInputRecords) init() {
	m.data.SetName("databricks.spark.stage.input_records")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{records}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkStageInputRecords) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutInt("spark.job.id", sparkJobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkStageInputRecords) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkStageInputRecords) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkStageInputRecords(cfg MetricConfig) metricDatabricksSparkStageInputRecords {
	m := metricDatabricksSparkStageInputRecords{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkStageMemoryBytesSpilled struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.stage.memory_bytes_spilled metric with initial data.
func (m *metricDatabricksSparkStageMemoryBytesSpilled) init() {
	m.data.SetName("databricks.spark.stage.memory_bytes_spilled")
	m.data.SetDescription("n/a")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkStageMemoryBytesSpilled) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutInt("spark.job.id", sparkJobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkStageMemoryBytesSpilled) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkStageMemoryBytesSpilled) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkStageMemoryBytesSpilled(cfg MetricConfig) metricDatabricksSparkStageMemoryBytesSpilled {
	m := metricDatabricksSparkStageMemoryBytesSpilled{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkStageOutputBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.stage.output_bytes metric with initial data.
func (m *metricDatabricksSparkStageOutputBytes) init() {
	m.data.SetName("databricks.spark.stage.output_bytes")
	m.data.SetDescription("n/a")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkStageOutputBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutInt("spark.job.id", sparkJobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkStageOutputBytes) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkStageOutputBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkStageOutputBytes(cfg MetricConfig) metricDatabricksSparkStageOutputBytes {
	m := metricDatabricksSparkStageOutputBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkStageOutputRecords struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.stage.output_records metric with initial data.
func (m *metricDatabricksSparkStageOutputRecords) init() {
	m.data.SetName("databricks.spark.stage.output_records")
	m.data.SetDescription("n/a")
	m.data.SetUnit("{records}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkStageOutputRecords) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
	dp.Attributes().PutInt("spark.job.id", sparkJobIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkStageOutputRecords) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkStageOutputRecords) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkStageOutputRecords(cfg MetricConfig) metricDatabricksSparkStageOutputRecords {
	m := metricDatabricksSparkStageOutputRecords{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerDagSchedulerMessageProcessingTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.dag_scheduler.message_processing.time metric with initial data.
func (m *metricDatabricksSparkTimerDagSchedulerMessageProcessingTime) init() {
	m.data.SetName("databricks.spark.timer.dag_scheduler.message_processing.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerDagSchedulerMessageProcessingTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerDagSchedulerMessageProcessingTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerDagSchedulerMessageProcessingTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerDagSchedulerMessageProcessingTime(cfg MetricConfig) metricDatabricksSparkTimerDagSchedulerMessageProcessingTime {
	m := metricDatabricksSparkTimerDagSchedulerMessageProcessingTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.execution.streaming.query_listener_bus.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.execution.streaming.query_listener_bus.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.execution.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.execution.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.execution.ui.sql_app_status_listener.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.execution.ui.sql_app_status_listener.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.hive.thriftserver.ui.hive_thrift_server2listener.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.hive.thriftserver.ui.hive_thrift_server2listener.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.spark_session.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.spark_session.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.util.execution_listener_bus.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.util.execution_listener_bus.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.status.app_status_listener.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.status.app_status_listener.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.util.profiler_env.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.util.profiler_env.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.databricks.backend.daemon.driver.data_plane_event_listener.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.databricks.backend.daemon.driver.data_plane_event_listener.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.databricks.backend.daemon.driver.dbc_event_logging_listener.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.databricks.backend.daemon.driver.dbc_event_logging_listener.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.databricks.photon.photon_cleanup_listener.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.databricks.photon.photon_cleanup_listener.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.databricks.spark.util.executor_time_logging_listener.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.databricks.spark.util.executor_time_logging_listener.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.databricks.spark.util.usage_logging_listener.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.databricks.spark.util.usage_logging_listener.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.databricks.sql.advice.advisor_listener.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.databricks.sql.advice.advisor_listener.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.databricks.sql.debugger.query_watchdog_listener.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.databricks.sql.debugger.query_watchdog_listener.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.databricks.sql.execution.ui.io_cache_listener.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.databricks.sql.execution.ui.io_cache_listener.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.listener_processing.databricks.sql.io.caching.repeated_reads_estimator.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.listener_processing.databricks.sql.io.caching.repeated_reads_estimator.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTime {
	m := metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.queue.app_status.listener_processing.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.queue.app_status.listener_processing.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTime {
	m := metricDatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.queue.executor_management.listener_processing.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.queue.executor_management.listener_processing.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTime {
	m := metricDatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.queue.shared.listener_processing.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.queue.shared.listener_processing.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTime {
	m := metricDatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.spark.timer.live_listener_bus.queue.streams.listener_processing.time metric with initial data.
func (m *metricDatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTime) init() {
	m.data.SetName("databricks.spark.timer.live_listener_bus.queue.streams.listener_processing.time")
	m.data.SetDescription("n/a")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("cluster.id", clusterIDAttributeValue)
	dp.Attributes().PutStr("spark.app.id", sparkAppIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTime(cfg MetricConfig) metricDatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTime {
	m := metricDatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksTasksRunDuration struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.tasks.run.duration metric with initial data.
func (m *metricDatabricksTasksRunDuration) init() {
	m.data.SetName("databricks.tasks.run.duration")
	m.data.SetDescription("The execution duration in milliseconds per completed task")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksTasksRunDuration) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, jobIDAttributeValue int64, taskIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("job.id", jobIDAttributeValue)
	dp.Attributes().PutStr("task.id", taskIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksTasksRunDuration) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksTasksRunDuration) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksTasksRunDuration(cfg MetricConfig) metricDatabricksTasksRunDuration {
	m := metricDatabricksTasksRunDuration{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricDatabricksTasksScheduleStatus struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills databricks.tasks.schedule.status metric with initial data.
func (m *metricDatabricksTasksScheduleStatus) init() {
	m.data.SetName("databricks.tasks.schedule.status")
	m.data.SetDescription("A snapshot of the pause/run status per task taken at each scrape")
	m.data.SetUnit("{status}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricDatabricksTasksScheduleStatus) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, jobIDAttributeValue int64, taskIDAttributeValue string, taskTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("job.id", jobIDAttributeValue)
	dp.Attributes().PutStr("task.id", taskIDAttributeValue)
	dp.Attributes().PutStr("task.type", taskTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricDatabricksTasksScheduleStatus) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricDatabricksTasksScheduleStatus) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricDatabricksTasksScheduleStatus(cfg MetricConfig) metricDatabricksTasksScheduleStatus {
	m := metricDatabricksTasksScheduleStatus{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	metricsBuffer                                                                                                            pmetric.Metrics
	buildInfo                                                                                                                component.BuildInfo
	metricDatabricksSparkExecutorMetricsMappedPoolMemory                                                                     metricDatabricksSparkExecutorMetricsMappedPoolMemory
	metricDatabricksSparkBlockManagerMemoryOnHeapMax                                                                         metricDatabricksSparkBlockManagerMemoryOnHeapMax
	metricDatabricksJobsScheduleStatus                                                                                       metricDatabricksJobsScheduleStatus
	metricDatabricksTasksScheduleStatus                                                                                      metricDatabricksTasksScheduleStatus
	metricDatabricksJobsTotal                                                                                                metricDatabricksJobsTotal
	metricDatabricksSparkBlockManagerMemoryDiskSpaceUsed                                                                     metricDatabricksSparkBlockManagerMemoryDiskSpaceUsed
	metricDatabricksSparkBlockManagerMemoryMax                                                                               metricDatabricksSparkBlockManagerMemoryMax
	metricDatabricksSparkBlockManagerMemoryOffHeapMax                                                                        metricDatabricksSparkBlockManagerMemoryOffHeapMax
	metricDatabricksSparkBlockManagerMemoryOffHeapUsed                                                                       metricDatabricksSparkBlockManagerMemoryOffHeapUsed
	metricDatabricksSparkExecutorMetricsMinorGcCount                                                                         metricDatabricksSparkExecutorMetricsMinorGcCount
	metricDatabricksSparkBlockManagerMemoryOnHeapUsed                                                                        metricDatabricksSparkBlockManagerMemoryOnHeapUsed
	metricDatabricksSparkBlockManagerMemoryRemaining                                                                         metricDatabricksSparkBlockManagerMemoryRemaining
	metricDatabricksSparkBlockManagerMemoryRemainingOffHeap                                                                  metricDatabricksSparkBlockManagerMemoryRemainingOffHeap
	metricDatabricksSparkBlockManagerMemoryRemainingOnHeap                                                                   metricDatabricksSparkBlockManagerMemoryRemainingOnHeap
	metricDatabricksSparkBlockManagerMemoryUsed                                                                              metricDatabricksSparkBlockManagerMemoryUsed
	metricDatabricksSparkCodeGeneratorCompilationTime                                                                        metricDatabricksSparkCodeGeneratorCompilationTime
	metricDatabricksSparkCodeGeneratorGeneratedClassSize                                                                     metricDatabricksSparkCodeGeneratorGeneratedClassSize
	metricDatabricksSparkCodeGeneratorGeneratedMethodSize                                                                    metricDatabricksSparkCodeGeneratorGeneratedMethodSize
	metricDatabricksSparkCodeGeneratorSourcecodeSize                                                                         metricDatabricksSparkCodeGeneratorSourcecodeSize
	metricDatabricksSparkDagSchedulerJobsActive                                                                              metricDatabricksSparkDagSchedulerJobsActive
	metricDatabricksSparkDagSchedulerJobsAll                                                                                 metricDatabricksSparkDagSchedulerJobsAll
	metricDatabricksSparkDagSchedulerStagesFailed                                                                            metricDatabricksSparkDagSchedulerStagesFailed
	metricDatabricksSparkDagSchedulerStagesRunning                                                                           metricDatabricksSparkDagSchedulerStagesRunning
	metricDatabricksSparkDagSchedulerStagesWaiting                                                                           metricDatabricksSparkDagSchedulerStagesWaiting
	metricDatabricksSparkDatabricksDirectoryCommitAutoVacuumCount                                                            metricDatabricksSparkDatabricksDirectoryCommitAutoVacuumCount
	metricDatabricksSparkDatabricksDirectoryCommitDeletedFilesFiltered                                                       metricDatabricksSparkDatabricksDirectoryCommitDeletedFilesFiltered
	metricDatabricksSparkDatabricksDirectoryCommitFilterListingCount                                                         metricDatabricksSparkDatabricksDirectoryCommitFilterListingCount
	metricDatabricksSparkDatabricksDirectoryCommitJobCommitCompleted                                                         metricDatabricksSparkDatabricksDirectoryCommitJobCommitCompleted
	metricDatabricksSparkDatabricksDirectoryCommitMarkerReadErrors                                                           metricDatabricksSparkDatabricksDirectoryCommitMarkerReadErrors
	metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshCount                                                         metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshCount
	metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrors                                                        metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrors
	metricDatabricksSparkDatabricksDirectoryCommitMarkersRead                                                                metricDatabricksSparkDatabricksDirectoryCommitMarkersRead
	metricDatabricksSparkDatabricksDirectoryCommitRepeatedListCount                                                          metricDatabricksSparkDatabricksDirectoryCommitRepeatedListCount
	metricDatabricksSparkDatabricksDirectoryCommitUncommittedFilesFiltered                                                   metricDatabricksSparkDatabricksDirectoryCommitUncommittedFilesFiltered
	metricDatabricksSparkDatabricksDirectoryCommitUntrackedFilesFound                                                        metricDatabricksSparkDatabricksDirectoryCommitUntrackedFilesFound
	metricDatabricksSparkDatabricksDirectoryCommitVacuumCount                                                                metricDatabricksSparkDatabricksDirectoryCommitVacuumCount
	metricDatabricksSparkDatabricksDirectoryCommitVacuumErrors                                                               metricDatabricksSparkDatabricksDirectoryCommitVacuumErrors
	metricDatabricksSparkDatabricksPreemptionChecksCount                                                                     metricDatabricksSparkDatabricksPreemptionChecksCount
	metricDatabricksSparkDatabricksPreemptionPoolsAutoexpiredCount                                                           metricDatabricksSparkDatabricksPreemptionPoolsAutoexpiredCount
	metricDatabricksSparkDatabricksPreemptionPoolstarvationTime                                                              metricDatabricksSparkDatabricksPreemptionPoolstarvationTime
	metricDatabricksSparkDatabricksPreemptionSchedulerOverheadTime                                                           metricDatabricksSparkDatabricksPreemptionSchedulerOverheadTime
	metricDatabricksSparkDatabricksPreemptionTaskWastedTime                                                                  metricDatabricksSparkDatabricksPreemptionTaskWastedTime
	metricDatabricksSparkDatabricksPreemptionTasksPreemptedCount                                                             metricDatabricksSparkDatabricksPreemptionTasksPreemptedCount
	metricDatabricksSparkDatabricksTaskSchedulingLanesActivePools                                                            metricDatabricksSparkDatabricksTaskSchedulingLanesActivePools
	metricDatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePools                                                  metricDatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePools
	metricDatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePools                                                    metricDatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePools
	metricDatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTime                                           metricDatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTime
	metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPools                                                 metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPools
	metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleaned                                        metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleaned
	metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleaned                                          metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleaned
	metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCount              metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCount
	metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCount                              metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCount
	metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTime                                   metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTime
	metricDatabricksSparkExecutorMetricsMinorGcTime                                                                          metricDatabricksSparkExecutorMetricsMinorGcTime
	metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCount                                          metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCount
	metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCount                                          metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCount
	metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReserved                                           metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReserved
	metricDatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePools                                                    metricDatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePools
	metricDatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinished                                               metricDatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinished
	metricDatabricksSparkExecutorDiskUsed                                                                                    metricDatabricksSparkExecutorDiskUsed
	metricDatabricksSparkExecutorMaxMemory                                                                                   metricDatabricksSparkExecutorMaxMemory
	metricDatabricksSparkExecutorMemoryUsed                                                                                  metricDatabricksSparkExecutorMemoryUsed
	metricDatabricksSparkExecutorTotalInputBytes                                                                             metricDatabricksSparkExecutorTotalInputBytes
	metricDatabricksSparkExecutorTotalShuffleRead                                                                            metricDatabricksSparkExecutorTotalShuffleRead
	metricDatabricksSparkExecutorTotalShuffleWrite                                                                           metricDatabricksSparkExecutorTotalShuffleWrite
	metricDatabricksSparkExecutorMetricsDirectPoolMemory                                                                     metricDatabricksSparkExecutorMetricsDirectPoolMemory
	metricDatabricksSparkExecutorMetricsJvmHeapMemory                                                                        metricDatabricksSparkExecutorMetricsJvmHeapMemory
	metricDatabricksSparkExecutorMetricsJvmOffHeapMemory                                                                     metricDatabricksSparkExecutorMetricsJvmOffHeapMemory
	metricDatabricksSparkExecutorMetricsMajorGcCount                                                                         metricDatabricksSparkExecutorMetricsMajorGcCount
	metricDatabricksSparkExecutorMetricsMajorGcTime                                                                          metricDatabricksSparkExecutorMetricsMajorGcTime
	metricDatabricksSparkLiveListenerBusQueueExecutormanagementSize                                                          metricDatabricksSparkLiveListenerBusQueueExecutormanagementSize
	metricDatabricksJobsRunDuration                                                                                          metricDatabricksJobsRunDuration
	metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCount                                    metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCount
	metricDatabricksSparkExecutorMetricsOffHeapExecutionMemory                                                               metricDatabricksSparkExecutorMetricsOffHeapExecutionMemory
	metricDatabricksSparkExecutorMetricsOffHeapStorageMemory                                                                 metricDatabricksSparkExecutorMetricsOffHeapStorageMemory
	metricDatabricksSparkExecutorMetricsOffHeapUnifiedMemory                                                                 metricDatabricksSparkExecutorMetricsOffHeapUnifiedMemory
	metricDatabricksSparkExecutorMetricsOnHeapExecutionMemory                                                                metricDatabricksSparkExecutorMetricsOnHeapExecutionMemory
	metricDatabricksSparkExecutorMetricsOnHeapStorageMemory                                                                  metricDatabricksSparkExecutorMetricsOnHeapStorageMemory
	metricDatabricksSparkExecutorMetricsOnHeapUnifiedMemory                                                                  metricDatabricksSparkExecutorMetricsOnHeapUnifiedMemory
	metricDatabricksSparkExecutorMetricsProcessTreeJvmRssMemory                                                              metricDatabricksSparkExecutorMetricsProcessTreeJvmRssMemory
	metricDatabricksSparkExecutorMetricsProcessTreeJvmVMemory                                                                metricDatabricksSparkExecutorMetricsProcessTreeJvmVMemory
	metricDatabricksSparkExecutorMetricsProcessTreeOtherRssMemory                                                            metricDatabricksSparkExecutorMetricsProcessTreeOtherRssMemory
	metricDatabricksSparkExecutorMetricsProcessTreeOtherVMemory                                                              metricDatabricksSparkExecutorMetricsProcessTreeOtherVMemory
	metricDatabricksSparkExecutorMetricsProcessTreePythonRssMemory                                                           metricDatabricksSparkExecutorMetricsProcessTreePythonRssMemory
	metricDatabricksSparkExecutorMetricsProcessTreePythonVMemory                                                             metricDatabricksSparkExecutorMetricsProcessTreePythonVMemory
	metricDatabricksSparkHiveExternalCatalogFileCacheHits                                                                    metricDatabricksSparkHiveExternalCatalogFileCacheHits
	metricDatabricksSparkHiveExternalCatalogFilesDiscovered                                                                  metricDatabricksSparkHiveExternalCatalogFilesDiscovered
	metricDatabricksSparkHiveExternalCatalogHiveClientCalls                                                                  metricDatabricksSparkHiveExternalCatalogHiveClientCalls
	metricDatabricksSparkHiveExternalCatalogParallelListingJobsCount                                                         metricDatabricksSparkHiveExternalCatalogParallelListingJobsCount
	metricDatabricksSparkHiveExternalCatalogPartitionsFetched                                                                metricDatabricksSparkHiveExternalCatalogPartitionsFetched
	metricDatabricksSparkJobNumActiveStages                                                                                  metricDatabricksSparkJobNumActiveStages
	metricDatabricksSparkJobNumActiveTasks                                                                                   metricDatabricksSparkJobNumActiveTasks
	metricDatabricksSparkJobNumCompletedStages                                                                               metricDatabricksSparkJobNumCompletedStages
	metricDatabricksSparkJobNumCompletedTasks                                                                                metricDatabricksSparkJobNumCompletedTasks
	metricDatabricksSparkJobNumFailedStages                                                                                  metricDatabricksSparkJobNumFailedStages
	metricDatabricksSparkJobNumFailedTasks                                                                                   metricDatabricksSparkJobNumFailedTasks
	metricDatabricksSparkJobNumSkippedStages                                                                                 metricDatabricksSparkJobNumSkippedStages
	metricDatabricksSparkJobNumSkippedTasks                                                                                  metricDatabricksSparkJobNumSkippedTasks
	metricDatabricksSparkJobNumTasks                                                                                         metricDatabricksSparkJobNumTasks
	metricDatabricksSparkJvmCPUTime                                                                                          metricDatabricksSparkJvmCPUTime
	metricDatabricksSparkLiveListenerBusEventsPostedCount                                                                    metricDatabricksSparkLiveListenerBusEventsPostedCount
	metricDatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCount                                                     metricDatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCount
	metricDatabricksSparkLiveListenerBusQueueAppstatusSize                                                                   metricDatabricksSparkLiveListenerBusQueueAppstatusSize
	metricDatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCount                                            metricDatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCount
	metricDatabricksJobsActiveTotal                                                                                          metricDatabricksJobsActiveTotal
	metricDatabricksSparkLiveListenerBusQueueSharedDroppedEventsCount                                                        metricDatabricksSparkLiveListenerBusQueueSharedDroppedEventsCount
	metricDatabricksSparkLiveListenerBusQueueSharedSize                                                                      metricDatabricksSparkLiveListenerBusQueueSharedSize
	metricDatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCount                                                       metricDatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCount
	metricDatabricksSparkLiveListenerBusQueueStreamsSize                                                                     metricDatabricksSparkLiveListenerBusQueueStreamsSize
	metricDatabricksSparkSparkSQLOperationManagerHiveOperationsCount                                                         metricDatabricksSparkSparkSQLOperationManagerHiveOperationsCount
	metricDatabricksSparkStageDiskBytesSpilled                                                                               metricDatabricksSparkStageDiskBytesSpilled
	metricDatabricksSparkStageExecutorRunTime                                                                                metricDatabricksSparkStageExecutorRunTime
	metricDatabricksSparkStageInputBytes                                                                                     metricDatabricksSparkStageInputBytes
	metricDatabricksSparkStageInputRecords                                                                                   metricDatabricksSparkStageInputRecords
	metricDatabricksSparkStageMemoryBytesSpilled                                                                             metricDatabricksSparkStageMemoryBytesSpilled
	metricDatabricksSparkStageOutputBytes                                                                                    metricDatabricksSparkStageOutputBytes
	metricDatabricksSparkStageOutputRecords                                                                                  metricDatabricksSparkStageOutputRecords
	metricDatabricksSparkTimerDagSchedulerMessageProcessingTime                                                              metricDatabricksSparkTimerDagSchedulerMessageProcessingTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTime          metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTime                                   metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTime             metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTime metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTime                                metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTime                    metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTime                        metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTime                                metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTime       metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTime      metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTime                     metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTime            metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTime                   metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTime                        metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTime                metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTime                   metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTime
	metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTime              metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTime
	metricDatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTime                                            metricDatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTime
	metricDatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTime                                   metricDatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTime
	metricDatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTime                                               metricDatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTime
	metricDatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTime                                              metricDatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTime
	metricDatabricksTasksRunDuration                                                                                         metricDatabricksTasksRunDuration
	startTime                                                                                                                pcommon.Timestamp
	metricsCapacity                                                                                                          int
	resourceCapacity                                                                                                         int
	resourceAttributesConfig                                                                                                 ResourceAttributesConfig
}

// metricBuilderOption applies changes to default metrics builder.
type metricBuilderOption func(*MetricsBuilder)

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) metricBuilderOption {
	return func(mb *MetricsBuilder) {
		mb.startTime = startTime
	}
}

func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.CreateSettings, options ...metricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		startTime:                          pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:                      pmetric.NewMetrics(),
		buildInfo:                          settings.BuildInfo,
		resourceAttributesConfig:           mbc.ResourceAttributes,
		metricDatabricksJobsActiveTotal:    newMetricDatabricksJobsActiveTotal(mbc.Metrics.DatabricksJobsActiveTotal),
		metricDatabricksJobsRunDuration:    newMetricDatabricksJobsRunDuration(mbc.Metrics.DatabricksJobsRunDuration),
		metricDatabricksJobsScheduleStatus: newMetricDatabricksJobsScheduleStatus(mbc.Metrics.DatabricksJobsScheduleStatus),
		metricDatabricksJobsTotal:          newMetricDatabricksJobsTotal(mbc.Metrics.DatabricksJobsTotal),
		metricDatabricksSparkBlockManagerMemoryDiskSpaceUsed:                                                                     newMetricDatabricksSparkBlockManagerMemoryDiskSpaceUsed(mbc.Metrics.DatabricksSparkBlockManagerMemoryDiskSpaceUsed),
		metricDatabricksSparkBlockManagerMemoryMax:                                                                               newMetricDatabricksSparkBlockManagerMemoryMax(mbc.Metrics.DatabricksSparkBlockManagerMemoryMax),
		metricDatabricksSparkBlockManagerMemoryOffHeapMax:                                                                        newMetricDatabricksSparkBlockManagerMemoryOffHeapMax(mbc.Metrics.DatabricksSparkBlockManagerMemoryOffHeapMax),
		metricDatabricksSparkBlockManagerMemoryOffHeapUsed:                                                                       newMetricDatabricksSparkBlockManagerMemoryOffHeapUsed(mbc.Metrics.DatabricksSparkBlockManagerMemoryOffHeapUsed),
		metricDatabricksSparkBlockManagerMemoryOnHeapMax:                                                                         newMetricDatabricksSparkBlockManagerMemoryOnHeapMax(mbc.Metrics.DatabricksSparkBlockManagerMemoryOnHeapMax),
		metricDatabricksSparkBlockManagerMemoryOnHeapUsed:                                                                        newMetricDatabricksSparkBlockManagerMemoryOnHeapUsed(mbc.Metrics.DatabricksSparkBlockManagerMemoryOnHeapUsed),
		metricDatabricksSparkBlockManagerMemoryRemaining:                                                                         newMetricDatabricksSparkBlockManagerMemoryRemaining(mbc.Metrics.DatabricksSparkBlockManagerMemoryRemaining),
		metricDatabricksSparkBlockManagerMemoryRemainingOffHeap:                                                                  newMetricDatabricksSparkBlockManagerMemoryRemainingOffHeap(mbc.Metrics.DatabricksSparkBlockManagerMemoryRemainingOffHeap),
		metricDatabricksSparkBlockManagerMemoryRemainingOnHeap:                                                                   newMetricDatabricksSparkBlockManagerMemoryRemainingOnHeap(mbc.Metrics.DatabricksSparkBlockManagerMemoryRemainingOnHeap),
		metricDatabricksSparkBlockManagerMemoryUsed:                                                                              newMetricDatabricksSparkBlockManagerMemoryUsed(mbc.Metrics.DatabricksSparkBlockManagerMemoryUsed),
		metricDatabricksSparkCodeGeneratorCompilationTime:                                                                        newMetricDatabricksSparkCodeGeneratorCompilationTime(mbc.Metrics.DatabricksSparkCodeGeneratorCompilationTime),
		metricDatabricksSparkCodeGeneratorGeneratedClassSize:                                                                     newMetricDatabricksSparkCodeGeneratorGeneratedClassSize(mbc.Metrics.DatabricksSparkCodeGeneratorGeneratedClassSize),
		metricDatabricksSparkCodeGeneratorGeneratedMethodSize:                                                                    newMetricDatabricksSparkCodeGeneratorGeneratedMethodSize(mbc.Metrics.DatabricksSparkCodeGeneratorGeneratedMethodSize),
		metricDatabricksSparkCodeGeneratorSourcecodeSize:                                                                         newMetricDatabricksSparkCodeGeneratorSourcecodeSize(mbc.Metrics.DatabricksSparkCodeGeneratorSourcecodeSize),
		metricDatabricksSparkDagSchedulerJobsActive:                                                                              newMetricDatabricksSparkDagSchedulerJobsActive(mbc.Metrics.DatabricksSparkDagSchedulerJobsActive),
		metricDatabricksSparkDagSchedulerJobsAll:                                                                                 newMetricDatabricksSparkDagSchedulerJobsAll(mbc.Metrics.DatabricksSparkDagSchedulerJobsAll),
		metricDatabricksSparkDagSchedulerStagesFailed:                                                                            newMetricDatabricksSparkDagSchedulerStagesFailed(mbc.Metrics.DatabricksSparkDagSchedulerStagesFailed),
		metricDatabricksSparkDagSchedulerStagesRunning:                                                                           newMetricDatabricksSparkDagSchedulerStagesRunning(mbc.Metrics.DatabricksSparkDagSchedulerStagesRunning),
		metricDatabricksSparkDagSchedulerStagesWaiting:                                                                           newMetricDatabricksSparkDagSchedulerStagesWaiting(mbc.Metrics.DatabricksSparkDagSchedulerStagesWaiting),
		metricDatabricksSparkDatabricksDirectoryCommitAutoVacuumCount:                                                            newMetricDatabricksSparkDatabricksDirectoryCommitAutoVacuumCount(mbc.Metrics.DatabricksSparkDatabricksDirectoryCommitAutoVacuumCount),
		metricDatabricksSparkDatabricksDirectoryCommitDeletedFilesFiltered:                                                       newMetricDatabricksSparkDatabricksDirectoryCommitDeletedFilesFiltered(mbc.Metrics.DatabricksSparkDatabricksDirectoryCommitDeletedFilesFiltered),
		metricDatabricksSparkDatabricksDirectoryCommitFilterListingCount:                                                         newMetricDatabricksSparkDatabricksDirectoryCommitFilterListingCount(mbc.Metrics.DatabricksSparkDatabricksDirectoryCommitFilterListingCount),
		metricDatabricksSparkDatabricksDirectoryCommitJobCommitCompleted:                                                         newMetricDatabricksSparkDatabricksDirectoryCommitJobCommitCompleted(mbc.Metrics.DatabricksSparkDatabricksDirectoryCommitJobCommitCompleted),
		metricDatabricksSparkDatabricksDirectoryCommitMarkerReadErrors:                                                           newMetricDatabricksSparkDatabricksDirectoryCommitMarkerReadErrors(mbc.Metrics.DatabricksSparkDatabricksDirectoryCommitMarkerReadErrors),
		metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshCount:                                                         newMetricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshCount(mbc.Metrics.DatabricksSparkDatabricksDirectoryCommitMarkerRefreshCount),
		metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrors:                                                        newMetricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrors(mbc.Metrics.DatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrors),
		metricDatabricksSparkDatabricksDirectoryCommitMarkersRead:                                                                newMetricDatabricksSparkDatabricksDirectoryCommitMarkersRead(mbc.Metrics.DatabricksSparkDatabricksDirectoryCommitMarkersRead),
		metricDatabricksSparkDatabricksDirectoryCommitRepeatedListCount:                                                          newMetricDatabricksSparkDatabricksDirectoryCommitRepeatedListCount(mbc.Metrics.DatabricksSparkDatabricksDirectoryCommitRepeatedListCount),
		metricDatabricksSparkDatabricksDirectoryCommitUncommittedFilesFiltered:                                                   newMetricDatabricksSparkDatabricksDirectoryCommitUncommittedFilesFiltered(mbc.Metrics.DatabricksSparkDatabricksDirectoryCommitUncommittedFilesFiltered),
		metricDatabricksSparkDatabricksDirectoryCommitUntrackedFilesFound:                                                        newMetricDatabricksSparkDatabricksDirectoryCommitUntrackedFilesFound(mbc.Metrics.DatabricksSparkDatabricksDirectoryCommitUntrackedFilesFound),
		metricDatabricksSparkDatabricksDirectoryCommitVacuumCount:                                                                newMetricDatabricksSparkDatabricksDirectoryCommitVacuumCount(mbc.Metrics.DatabricksSparkDatabricksDirectoryCommitVacuumCount),
		metricDatabricksSparkDatabricksDirectoryCommitVacuumErrors:                                                               newMetricDatabricksSparkDatabricksDirectoryCommitVacuumErrors(mbc.Metrics.DatabricksSparkDatabricksDirectoryCommitVacuumErrors),
		metricDatabricksSparkDatabricksPreemptionChecksCount:                                                                     newMetricDatabricksSparkDatabricksPreemptionChecksCount(mbc.Metrics.DatabricksSparkDatabricksPreemptionChecksCount),
		metricDatabricksSparkDatabricksPreemptionPoolsAutoexpiredCount:                                                           newMetricDatabricksSparkDatabricksPreemptionPoolsAutoexpiredCount(mbc.Metrics.DatabricksSparkDatabricksPreemptionPoolsAutoexpiredCount),
		metricDatabricksSparkDatabricksPreemptionPoolstarvationTime:                                                              newMetricDatabricksSparkDatabricksPreemptionPoolstarvationTime(mbc.Metrics.DatabricksSparkDatabricksPreemptionPoolstarvationTime),
		metricDatabricksSparkDatabricksPreemptionSchedulerOverheadTime:                                                           newMetricDatabricksSparkDatabricksPreemptionSchedulerOverheadTime(mbc.Metrics.DatabricksSparkDatabricksPreemptionSchedulerOverheadTime),
		metricDatabricksSparkDatabricksPreemptionTaskWastedTime:                                                                  newMetricDatabricksSparkDatabricksPreemptionTaskWastedTime(mbc.Metrics.DatabricksSparkDatabricksPreemptionTaskWastedTime),
		metricDatabricksSparkDatabricksPreemptionTasksPreemptedCount:                                                             newMetricDatabricksSparkDatabricksPreemptionTasksPreemptedCount(mbc.Metrics.DatabricksSparkDatabricksPreemptionTasksPreemptedCount),
		metricDatabricksSparkDatabricksTaskSchedulingLanesActivePools:                                                            newMetricDatabricksSparkDatabricksTaskSchedulingLanesActivePools(mbc.Metrics.DatabricksSparkDatabricksTaskSchedulingLanesActivePools),
		metricDatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePools:                                                  newMetricDatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePools(mbc.Metrics.DatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePools),
		metricDatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePools:                                                    newMetricDatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePools(mbc.Metrics.DatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePools),
		metricDatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTime:                                           newMetricDatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTime(mbc.Metrics.DatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTime),
		metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPools:                                                 newMetricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPools(mbc.Metrics.DatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPools),
		metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleaned:                                        newMetricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleaned(mbc.Metrics.DatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleaned),
		metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleaned:                                          newMetricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleaned(mbc.Metrics.DatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleaned),
		metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCount:              newMetricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCount(mbc.Metrics.DatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCount),
		metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCount:                              newMetricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCount(mbc.Metrics.DatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCount),
		metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTime:                                   newMetricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTime(mbc.Metrics.DatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTime),
		metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCount:                                    newMetricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCount(mbc.Metrics.DatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCount),
		metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCount:                                          newMetricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCount(mbc.Metrics.DatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCount),
		metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCount:                                          newMetricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCount(mbc.Metrics.DatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCount),
		metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReserved:                                           newMetricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReserved(mbc.Metrics.DatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReserved),
		metricDatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePools:                                                    newMetricDatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePools(mbc.Metrics.DatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePools),
		metricDatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinished:                                               newMetricDatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinished(mbc.Metrics.DatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinished),
		metricDatabricksSparkExecutorDiskUsed:                                                                                    newMetricDatabricksSparkExecutorDiskUsed(mbc.Metrics.DatabricksSparkExecutorDiskUsed),
		metricDatabricksSparkExecutorMaxMemory:                                                                                   newMetricDatabricksSparkExecutorMaxMemory(mbc.Metrics.DatabricksSparkExecutorMaxMemory),
		metricDatabricksSparkExecutorMemoryUsed:                                                                                  newMetricDatabricksSparkExecutorMemoryUsed(mbc.Metrics.DatabricksSparkExecutorMemoryUsed),
		metricDatabricksSparkExecutorTotalInputBytes:                                                                             newMetricDatabricksSparkExecutorTotalInputBytes(mbc.Metrics.DatabricksSparkExecutorTotalInputBytes),
		metricDatabricksSparkExecutorTotalShuffleRead:                                                                            newMetricDatabricksSparkExecutorTotalShuffleRead(mbc.Metrics.DatabricksSparkExecutorTotalShuffleRead),
		metricDatabricksSparkExecutorTotalShuffleWrite:                                                                           newMetricDatabricksSparkExecutorTotalShuffleWrite(mbc.Metrics.DatabricksSparkExecutorTotalShuffleWrite),
		metricDatabricksSparkExecutorMetricsDirectPoolMemory:                                                                     newMetricDatabricksSparkExecutorMetricsDirectPoolMemory(mbc.Metrics.DatabricksSparkExecutorMetricsDirectPoolMemory),
		metricDatabricksSparkExecutorMetricsJvmHeapMemory:                                                                        newMetricDatabricksSparkExecutorMetricsJvmHeapMemory(mbc.Metrics.DatabricksSparkExecutorMetricsJvmHeapMemory),
		metricDatabricksSparkExecutorMetricsJvmOffHeapMemory:                                                                     newMetricDatabricksSparkExecutorMetricsJvmOffHeapMemory(mbc.Metrics.DatabricksSparkExecutorMetricsJvmOffHeapMemory),
		metricDatabricksSparkExecutorMetricsMajorGcCount:                                                                         newMetricDatabricksSparkExecutorMetricsMajorGcCount(mbc.Metrics.DatabricksSparkExecutorMetricsMajorGcCount),
		metricDatabricksSparkExecutorMetricsMajorGcTime:                                                                          newMetricDatabricksSparkExecutorMetricsMajorGcTime(mbc.Metrics.DatabricksSparkExecutorMetricsMajorGcTime),
		metricDatabricksSparkExecutorMetricsMappedPoolMemory:                                                                     newMetricDatabricksSparkExecutorMetricsMappedPoolMemory(mbc.Metrics.DatabricksSparkExecutorMetricsMappedPoolMemory),
		metricDatabricksSparkExecutorMetricsMinorGcCount:                                                                         newMetricDatabricksSparkExecutorMetricsMinorGcCount(mbc.Metrics.DatabricksSparkExecutorMetricsMinorGcCount),
		metricDatabricksSparkExecutorMetricsMinorGcTime:                                                                          newMetricDatabricksSparkExecutorMetricsMinorGcTime(mbc.Metrics.DatabricksSparkExecutorMetricsMinorGcTime),
		metricDatabricksSparkExecutorMetricsOffHeapExecutionMemory:                                                               newMetricDatabricksSparkExecutorMetricsOffHeapExecutionMemory(mbc.Metrics.DatabricksSparkExecutorMetricsOffHeapExecutionMemory),
		metricDatabricksSparkExecutorMetricsOffHeapStorageMemory:                                                                 newMetricDatabricksSparkExecutorMetricsOffHeapStorageMemory(mbc.Metrics.DatabricksSparkExecutorMetricsOffHeapStorageMemory),
		metricDatabricksSparkExecutorMetricsOffHeapUnifiedMemory:                                                                 newMetricDatabricksSparkExecutorMetricsOffHeapUnifiedMemory(mbc.Metrics.DatabricksSparkExecutorMetricsOffHeapUnifiedMemory),
		metricDatabricksSparkExecutorMetricsOnHeapExecutionMemory:                                                                newMetricDatabricksSparkExecutorMetricsOnHeapExecutionMemory(mbc.Metrics.DatabricksSparkExecutorMetricsOnHeapExecutionMemory),
		metricDatabricksSparkExecutorMetricsOnHeapStorageMemory:                                                                  newMetricDatabricksSparkExecutorMetricsOnHeapStorageMemory(mbc.Metrics.DatabricksSparkExecutorMetricsOnHeapStorageMemory),
		metricDatabricksSparkExecutorMetricsOnHeapUnifiedMemory:                                                                  newMetricDatabricksSparkExecutorMetricsOnHeapUnifiedMemory(mbc.Metrics.DatabricksSparkExecutorMetricsOnHeapUnifiedMemory),
		metricDatabricksSparkExecutorMetricsProcessTreeJvmRssMemory:                                                              newMetricDatabricksSparkExecutorMetricsProcessTreeJvmRssMemory(mbc.Metrics.DatabricksSparkExecutorMetricsProcessTreeJvmRssMemory),
		metricDatabricksSparkExecutorMetricsProcessTreeJvmVMemory:                                                                newMetricDatabricksSparkExecutorMetricsProcessTreeJvmVMemory(mbc.Metrics.DatabricksSparkExecutorMetricsProcessTreeJvmVMemory),
		metricDatabricksSparkExecutorMetricsProcessTreeOtherRssMemory:                                                            newMetricDatabricksSparkExecutorMetricsProcessTreeOtherRssMemory(mbc.Metrics.DatabricksSparkExecutorMetricsProcessTreeOtherRssMemory),
		metricDatabricksSparkExecutorMetricsProcessTreeOtherVMemory:                                                              newMetricDatabricksSparkExecutorMetricsProcessTreeOtherVMemory(mbc.Metrics.DatabricksSparkExecutorMetricsProcessTreeOtherVMemory),
		metricDatabricksSparkExecutorMetricsProcessTreePythonRssMemory:                                                           newMetricDatabricksSparkExecutorMetricsProcessTreePythonRssMemory(mbc.Metrics.DatabricksSparkExecutorMetricsProcessTreePythonRssMemory),
		metricDatabricksSparkExecutorMetricsProcessTreePythonVMemory:                                                             newMetricDatabricksSparkExecutorMetricsProcessTreePythonVMemory(mbc.Metrics.DatabricksSparkExecutorMetricsProcessTreePythonVMemory),
		metricDatabricksSparkHiveExternalCatalogFileCacheHits:                                                                    newMetricDatabricksSparkHiveExternalCatalogFileCacheHits(mbc.Metrics.DatabricksSparkHiveExternalCatalogFileCacheHits),
		metricDatabricksSparkHiveExternalCatalogFilesDiscovered:                                                                  newMetricDatabricksSparkHiveExternalCatalogFilesDiscovered(mbc.Metrics.DatabricksSparkHiveExternalCatalogFilesDiscovered),
		metricDatabricksSparkHiveExternalCatalogHiveClientCalls:                                                                  newMetricDatabricksSparkHiveExternalCatalogHiveClientCalls(mbc.Metrics.DatabricksSparkHiveExternalCatalogHiveClientCalls),
		metricDatabricksSparkHiveExternalCatalogParallelListingJobsCount:                                                         newMetricDatabricksSparkHiveExternalCatalogParallelListingJobsCount(mbc.Metrics.DatabricksSparkHiveExternalCatalogParallelListingJobsCount),
		metricDatabricksSparkHiveExternalCatalogPartitionsFetched:                                                                newMetricDatabricksSparkHiveExternalCatalogPartitionsFetched(mbc.Metrics.DatabricksSparkHiveExternalCatalogPartitionsFetched),
		metricDatabricksSparkJobNumActiveStages:                                                                                  newMetricDatabricksSparkJobNumActiveStages(mbc.Metrics.DatabricksSparkJobNumActiveStages),
		metricDatabricksSparkJobNumActiveTasks:                                                                                   newMetricDatabricksSparkJobNumActiveTasks(mbc.Metrics.DatabricksSparkJobNumActiveTasks),
		metricDatabricksSparkJobNumCompletedStages:                                                                               newMetricDatabricksSparkJobNumCompletedStages(mbc.Metrics.DatabricksSparkJobNumCompletedStages),
		metricDatabricksSparkJobNumCompletedTasks:                                                                                newMetricDatabricksSparkJobNumCompletedTasks(mbc.Metrics.DatabricksSparkJobNumCompletedTasks),
		metricDatabricksSparkJobNumFailedStages:                                                                                  newMetricDatabricksSparkJobNumFailedStages(mbc.Metrics.DatabricksSparkJobNumFailedStages),
		metricDatabricksSparkJobNumFailedTasks:                                                                                   newMetricDatabricksSparkJobNumFailedTasks(mbc.Metrics.DatabricksSparkJobNumFailedTasks),
		metricDatabricksSparkJobNumSkippedStages:                                                                                 newMetricDatabricksSparkJobNumSkippedStages(mbc.Metrics.DatabricksSparkJobNumSkippedStages),
		metricDatabricksSparkJobNumSkippedTasks:                                                                                  newMetricDatabricksSparkJobNumSkippedTasks(mbc.Metrics.DatabricksSparkJobNumSkippedTasks),
		metricDatabricksSparkJobNumTasks:                                                                                         newMetricDatabricksSparkJobNumTasks(mbc.Metrics.DatabricksSparkJobNumTasks),
		metricDatabricksSparkJvmCPUTime:                                                                                          newMetricDatabricksSparkJvmCPUTime(mbc.Metrics.DatabricksSparkJvmCPUTime),
		metricDatabricksSparkLiveListenerBusEventsPostedCount:                                                                    newMetricDatabricksSparkLiveListenerBusEventsPostedCount(mbc.Metrics.DatabricksSparkLiveListenerBusEventsPostedCount),
		metricDatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCount:                                                     newMetricDatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCount(mbc.Metrics.DatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCount),
		metricDatabricksSparkLiveListenerBusQueueAppstatusSize:                                                                   newMetricDatabricksSparkLiveListenerBusQueueAppstatusSize(mbc.Metrics.DatabricksSparkLiveListenerBusQueueAppstatusSize),
		metricDatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCount:                                            newMetricDatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCount(mbc.Metrics.DatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCount),
		metricDatabricksSparkLiveListenerBusQueueExecutormanagementSize:                                                          newMetricDatabricksSparkLiveListenerBusQueueExecutormanagementSize(mbc.Metrics.DatabricksSparkLiveListenerBusQueueExecutormanagementSize),
		metricDatabricksSparkLiveListenerBusQueueSharedDroppedEventsCount:                                                        newMetricDatabricksSparkLiveListenerBusQueueSharedDroppedEventsCount(mbc.Metrics.DatabricksSparkLiveListenerBusQueueSharedDroppedEventsCount),
		metricDatabricksSparkLiveListenerBusQueueSharedSize:                                                                      newMetricDatabricksSparkLiveListenerBusQueueSharedSize(mbc.Metrics.DatabricksSparkLiveListenerBusQueueSharedSize),
		metricDatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCount:                                                       newMetricDatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCount(mbc.Metrics.DatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCount),
		metricDatabricksSparkLiveListenerBusQueueStreamsSize:                                                                     newMetricDatabricksSparkLiveListenerBusQueueStreamsSize(mbc.Metrics.DatabricksSparkLiveListenerBusQueueStreamsSize),
		metricDatabricksSparkSparkSQLOperationManagerHiveOperationsCount:                                                         newMetricDatabricksSparkSparkSQLOperationManagerHiveOperationsCount(mbc.Metrics.DatabricksSparkSparkSQLOperationManagerHiveOperationsCount),
		metricDatabricksSparkStageDiskBytesSpilled:                                                                               newMetricDatabricksSparkStageDiskBytesSpilled(mbc.Metrics.DatabricksSparkStageDiskBytesSpilled),
		metricDatabricksSparkStageExecutorRunTime:                                                                                newMetricDatabricksSparkStageExecutorRunTime(mbc.Metrics.DatabricksSparkStageExecutorRunTime),
		metricDatabricksSparkStageInputBytes:                                                                                     newMetricDatabricksSparkStageInputBytes(mbc.Metrics.DatabricksSparkStageInputBytes),
		metricDatabricksSparkStageInputRecords:                                                                                   newMetricDatabricksSparkStageInputRecords(mbc.Metrics.DatabricksSparkStageInputRecords),
		metricDatabricksSparkStageMemoryBytesSpilled:                                                                             newMetricDatabricksSparkStageMemoryBytesSpilled(mbc.Metrics.DatabricksSparkStageMemoryBytesSpilled),
		metricDatabricksSparkStageOutputBytes:                                                                                    newMetricDatabricksSparkStageOutputBytes(mbc.Metrics.DatabricksSparkStageOutputBytes),
		metricDatabricksSparkStageOutputRecords:                                                                                  newMetricDatabricksSparkStageOutputRecords(mbc.Metrics.DatabricksSparkStageOutputRecords),
		metricDatabricksSparkTimerDagSchedulerMessageProcessingTime:                                                              newMetricDatabricksSparkTimerDagSchedulerMessageProcessingTime(mbc.Metrics.DatabricksSparkTimerDagSchedulerMessageProcessingTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTime:          newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTime:                                   newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTime:             newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTime: newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTime:                                newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTime:                    newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTime:                        newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTime:                                newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTime:       newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTime:      newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTime:                     newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTime:            newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTime:                   newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTime:                        newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTime:                newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTime:                   newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTime),
		metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTime:              newMetricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTime),
		metricDatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTime:                                            newMetricDatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTime),
		metricDatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTime:                                   newMetricDatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTime),
		metricDatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTime:                                               newMetricDatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTime),
		metricDatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTime:                                              newMetricDatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTime(mbc.Metrics.DatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTime),
		metricDatabricksTasksRunDuration:                                                                                         newMetricDatabricksTasksRunDuration(mbc.Metrics.DatabricksTasksRunDuration),
		metricDatabricksTasksScheduleStatus:                                                                                      newMetricDatabricksTasksScheduleStatus(mbc.Metrics.DatabricksTasksScheduleStatus),
	}
	for _, op := range options {
		op(mb)
	}
	return mb
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
	if mb.resourceCapacity < rm.Resource().Attributes().Len() {
		mb.resourceCapacity = rm.Resource().Attributes().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption func(ResourceAttributesConfig, pmetric.ResourceMetrics)

// WithDatabricksInstanceName sets provided value as "databricks.instance.name" attribute for current resource.
func WithDatabricksInstanceName(val string) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.DatabricksInstanceName.Enabled {
			rm.Resource().Attributes().PutStr("databricks.instance.name", val)
		}
	}
}

// WithSparkAppID sets provided value as "spark.app.id" attribute for current resource.
func WithSparkAppID(val string) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SparkAppID.Enabled {
			rm.Resource().Attributes().PutStr("spark.app.id", val)
		}
	}
}

// WithSparkClusterID sets provided value as "spark.cluster.id" attribute for current resource.
func WithSparkClusterID(val string) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SparkClusterID.Enabled {
			rm.Resource().Attributes().PutStr("spark.cluster.id", val)
		}
	}
}

// WithSparkClusterName sets provided value as "spark.cluster.name" attribute for current resource.
func WithSparkClusterName(val string) ResourceMetricsOption {
	return func(rac ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		if rac.SparkClusterName.Enabled {
			rm.Resource().Attributes().PutStr("spark.cluster.name", val)
		}
	}
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return func(_ ResourceAttributesConfig, rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	}
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(rmo ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	rm.Resource().Attributes().EnsureCapacity(mb.resourceCapacity)
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName("otelcol/databricksreceiver")
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricDatabricksJobsActiveTotal.emit(ils.Metrics())
	mb.metricDatabricksJobsRunDuration.emit(ils.Metrics())
	mb.metricDatabricksJobsScheduleStatus.emit(ils.Metrics())
	mb.metricDatabricksJobsTotal.emit(ils.Metrics())
	mb.metricDatabricksSparkBlockManagerMemoryDiskSpaceUsed.emit(ils.Metrics())
	mb.metricDatabricksSparkBlockManagerMemoryMax.emit(ils.Metrics())
	mb.metricDatabricksSparkBlockManagerMemoryOffHeapMax.emit(ils.Metrics())
	mb.metricDatabricksSparkBlockManagerMemoryOffHeapUsed.emit(ils.Metrics())
	mb.metricDatabricksSparkBlockManagerMemoryOnHeapMax.emit(ils.Metrics())
	mb.metricDatabricksSparkBlockManagerMemoryOnHeapUsed.emit(ils.Metrics())
	mb.metricDatabricksSparkBlockManagerMemoryRemaining.emit(ils.Metrics())
	mb.metricDatabricksSparkBlockManagerMemoryRemainingOffHeap.emit(ils.Metrics())
	mb.metricDatabricksSparkBlockManagerMemoryRemainingOnHeap.emit(ils.Metrics())
	mb.metricDatabricksSparkBlockManagerMemoryUsed.emit(ils.Metrics())
	mb.metricDatabricksSparkCodeGeneratorCompilationTime.emit(ils.Metrics())
	mb.metricDatabricksSparkCodeGeneratorGeneratedClassSize.emit(ils.Metrics())
	mb.metricDatabricksSparkCodeGeneratorGeneratedMethodSize.emit(ils.Metrics())
	mb.metricDatabricksSparkCodeGeneratorSourcecodeSize.emit(ils.Metrics())
	mb.metricDatabricksSparkDagSchedulerJobsActive.emit(ils.Metrics())
	mb.metricDatabricksSparkDagSchedulerJobsAll.emit(ils.Metrics())
	mb.metricDatabricksSparkDagSchedulerStagesFailed.emit(ils.Metrics())
	mb.metricDatabricksSparkDagSchedulerStagesRunning.emit(ils.Metrics())
	mb.metricDatabricksSparkDagSchedulerStagesWaiting.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksDirectoryCommitAutoVacuumCount.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksDirectoryCommitDeletedFilesFiltered.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksDirectoryCommitFilterListingCount.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksDirectoryCommitJobCommitCompleted.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksDirectoryCommitMarkerReadErrors.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshCount.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrors.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksDirectoryCommitMarkersRead.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksDirectoryCommitRepeatedListCount.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksDirectoryCommitUncommittedFilesFiltered.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksDirectoryCommitUntrackedFilesFound.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksDirectoryCommitVacuumCount.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksDirectoryCommitVacuumErrors.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksPreemptionChecksCount.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksPreemptionPoolsAutoexpiredCount.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksPreemptionPoolstarvationTime.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksPreemptionSchedulerOverheadTime.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksPreemptionTaskWastedTime.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksPreemptionTasksPreemptedCount.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesActivePools.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePools.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePools.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTime.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPools.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleaned.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleaned.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCount.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCount.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTime.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCount.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCount.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCount.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReserved.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePools.emit(ils.Metrics())
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinished.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorDiskUsed.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMaxMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMemoryUsed.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorTotalInputBytes.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorTotalShuffleRead.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorTotalShuffleWrite.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsDirectPoolMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsJvmHeapMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsJvmOffHeapMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsMajorGcCount.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsMajorGcTime.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsMappedPoolMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsMinorGcCount.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsMinorGcTime.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsOffHeapExecutionMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsOffHeapStorageMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsOffHeapUnifiedMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsOnHeapExecutionMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsOnHeapStorageMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsOnHeapUnifiedMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsProcessTreeJvmRssMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsProcessTreeJvmVMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsProcessTreeOtherRssMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsProcessTreeOtherVMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsProcessTreePythonRssMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkExecutorMetricsProcessTreePythonVMemory.emit(ils.Metrics())
	mb.metricDatabricksSparkHiveExternalCatalogFileCacheHits.emit(ils.Metrics())
	mb.metricDatabricksSparkHiveExternalCatalogFilesDiscovered.emit(ils.Metrics())
	mb.metricDatabricksSparkHiveExternalCatalogHiveClientCalls.emit(ils.Metrics())
	mb.metricDatabricksSparkHiveExternalCatalogParallelListingJobsCount.emit(ils.Metrics())
	mb.metricDatabricksSparkHiveExternalCatalogPartitionsFetched.emit(ils.Metrics())
	mb.metricDatabricksSparkJobNumActiveStages.emit(ils.Metrics())
	mb.metricDatabricksSparkJobNumActiveTasks.emit(ils.Metrics())
	mb.metricDatabricksSparkJobNumCompletedStages.emit(ils.Metrics())
	mb.metricDatabricksSparkJobNumCompletedTasks.emit(ils.Metrics())
	mb.metricDatabricksSparkJobNumFailedStages.emit(ils.Metrics())
	mb.metricDatabricksSparkJobNumFailedTasks.emit(ils.Metrics())
	mb.metricDatabricksSparkJobNumSkippedStages.emit(ils.Metrics())
	mb.metricDatabricksSparkJobNumSkippedTasks.emit(ils.Metrics())
	mb.metricDatabricksSparkJobNumTasks.emit(ils.Metrics())
	mb.metricDatabricksSparkJvmCPUTime.emit(ils.Metrics())
	mb.metricDatabricksSparkLiveListenerBusEventsPostedCount.emit(ils.Metrics())
	mb.metricDatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCount.emit(ils.Metrics())
	mb.metricDatabricksSparkLiveListenerBusQueueAppstatusSize.emit(ils.Metrics())
	mb.metricDatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCount.emit(ils.Metrics())
	mb.metricDatabricksSparkLiveListenerBusQueueExecutormanagementSize.emit(ils.Metrics())
	mb.metricDatabricksSparkLiveListenerBusQueueSharedDroppedEventsCount.emit(ils.Metrics())
	mb.metricDatabricksSparkLiveListenerBusQueueSharedSize.emit(ils.Metrics())
	mb.metricDatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCount.emit(ils.Metrics())
	mb.metricDatabricksSparkLiveListenerBusQueueStreamsSize.emit(ils.Metrics())
	mb.metricDatabricksSparkSparkSQLOperationManagerHiveOperationsCount.emit(ils.Metrics())
	mb.metricDatabricksSparkStageDiskBytesSpilled.emit(ils.Metrics())
	mb.metricDatabricksSparkStageExecutorRunTime.emit(ils.Metrics())
	mb.metricDatabricksSparkStageInputBytes.emit(ils.Metrics())
	mb.metricDatabricksSparkStageInputRecords.emit(ils.Metrics())
	mb.metricDatabricksSparkStageMemoryBytesSpilled.emit(ils.Metrics())
	mb.metricDatabricksSparkStageOutputBytes.emit(ils.Metrics())
	mb.metricDatabricksSparkStageOutputRecords.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerDagSchedulerMessageProcessingTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTime.emit(ils.Metrics())
	mb.metricDatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTime.emit(ils.Metrics())
	mb.metricDatabricksTasksRunDuration.emit(ils.Metrics())
	mb.metricDatabricksTasksScheduleStatus.emit(ils.Metrics())

	for _, op := range rmo {
		op(mb.resourceAttributesConfig, rm)
	}
	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(rmo ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(rmo...)
	metrics := mb.metricsBuffer
	mb.metricsBuffer = pmetric.NewMetrics()
	return metrics
}

// RecordDatabricksJobsActiveTotalDataPoint adds a data point to databricks.jobs.active.total metric.
func (mb *MetricsBuilder) RecordDatabricksJobsActiveTotalDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricDatabricksJobsActiveTotal.recordDataPoint(mb.startTime, ts, val)
}

// RecordDatabricksJobsRunDurationDataPoint adds a data point to databricks.jobs.run.duration metric.
func (mb *MetricsBuilder) RecordDatabricksJobsRunDurationDataPoint(ts pcommon.Timestamp, val int64, jobIDAttributeValue int64) {
	mb.metricDatabricksJobsRunDuration.recordDataPoint(mb.startTime, ts, val, jobIDAttributeValue)
}

// RecordDatabricksJobsScheduleStatusDataPoint adds a data point to databricks.jobs.schedule.status metric.
func (mb *MetricsBuilder) RecordDatabricksJobsScheduleStatusDataPoint(ts pcommon.Timestamp, val int64, jobIDAttributeValue int64) {
	mb.metricDatabricksJobsScheduleStatus.recordDataPoint(mb.startTime, ts, val, jobIDAttributeValue)
}

// RecordDatabricksJobsTotalDataPoint adds a data point to databricks.jobs.total metric.
func (mb *MetricsBuilder) RecordDatabricksJobsTotalDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricDatabricksJobsTotal.recordDataPoint(mb.startTime, ts, val)
}

// RecordDatabricksSparkBlockManagerMemoryDiskSpaceUsedDataPoint adds a data point to databricks.spark.block_manager.memory.disk_space.used metric.
func (mb *MetricsBuilder) RecordDatabricksSparkBlockManagerMemoryDiskSpaceUsedDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkBlockManagerMemoryDiskSpaceUsed.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkBlockManagerMemoryMaxDataPoint adds a data point to databricks.spark.block_manager.memory.max metric.
func (mb *MetricsBuilder) RecordDatabricksSparkBlockManagerMemoryMaxDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkBlockManagerMemoryMax.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkBlockManagerMemoryOffHeapMaxDataPoint adds a data point to databricks.spark.block_manager.memory.off_heap.max metric.
func (mb *MetricsBuilder) RecordDatabricksSparkBlockManagerMemoryOffHeapMaxDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkBlockManagerMemoryOffHeapMax.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkBlockManagerMemoryOffHeapUsedDataPoint adds a data point to databricks.spark.block_manager.memory.off_heap.used metric.
func (mb *MetricsBuilder) RecordDatabricksSparkBlockManagerMemoryOffHeapUsedDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkBlockManagerMemoryOffHeapUsed.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkBlockManagerMemoryOnHeapMaxDataPoint adds a data point to databricks.spark.block_manager.memory.on_heap.max metric.
func (mb *MetricsBuilder) RecordDatabricksSparkBlockManagerMemoryOnHeapMaxDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkBlockManagerMemoryOnHeapMax.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkBlockManagerMemoryOnHeapUsedDataPoint adds a data point to databricks.spark.block_manager.memory.on_heap.used metric.
func (mb *MetricsBuilder) RecordDatabricksSparkBlockManagerMemoryOnHeapUsedDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkBlockManagerMemoryOnHeapUsed.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkBlockManagerMemoryRemainingDataPoint adds a data point to databricks.spark.block_manager.memory.remaining metric.
func (mb *MetricsBuilder) RecordDatabricksSparkBlockManagerMemoryRemainingDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkBlockManagerMemoryRemaining.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkBlockManagerMemoryRemainingOffHeapDataPoint adds a data point to databricks.spark.block_manager.memory.remaining.off_heap metric.
func (mb *MetricsBuilder) RecordDatabricksSparkBlockManagerMemoryRemainingOffHeapDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkBlockManagerMemoryRemainingOffHeap.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkBlockManagerMemoryRemainingOnHeapDataPoint adds a data point to databricks.spark.block_manager.memory.remaining.on_heap metric.
func (mb *MetricsBuilder) RecordDatabricksSparkBlockManagerMemoryRemainingOnHeapDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkBlockManagerMemoryRemainingOnHeap.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkBlockManagerMemoryUsedDataPoint adds a data point to databricks.spark.block_manager.memory.used metric.
func (mb *MetricsBuilder) RecordDatabricksSparkBlockManagerMemoryUsedDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkBlockManagerMemoryUsed.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkCodeGeneratorCompilationTimeDataPoint adds a data point to databricks.spark.code_generator.compilation.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkCodeGeneratorCompilationTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkCodeGeneratorCompilationTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkCodeGeneratorGeneratedClassSizeDataPoint adds a data point to databricks.spark.code_generator.generated_class_size metric.
func (mb *MetricsBuilder) RecordDatabricksSparkCodeGeneratorGeneratedClassSizeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkCodeGeneratorGeneratedClassSize.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkCodeGeneratorGeneratedMethodSizeDataPoint adds a data point to databricks.spark.code_generator.generated_method_size metric.
func (mb *MetricsBuilder) RecordDatabricksSparkCodeGeneratorGeneratedMethodSizeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkCodeGeneratorGeneratedMethodSize.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkCodeGeneratorSourcecodeSizeDataPoint adds a data point to databricks.spark.code_generator.sourcecode_size metric.
func (mb *MetricsBuilder) RecordDatabricksSparkCodeGeneratorSourcecodeSizeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkCodeGeneratorSourcecodeSize.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDagSchedulerJobsActiveDataPoint adds a data point to databricks.spark.dag_scheduler.jobs.active metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDagSchedulerJobsActiveDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDagSchedulerJobsActive.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDagSchedulerJobsAllDataPoint adds a data point to databricks.spark.dag_scheduler.jobs.all metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDagSchedulerJobsAllDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDagSchedulerJobsAll.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDagSchedulerStagesFailedDataPoint adds a data point to databricks.spark.dag_scheduler.stages.failed metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDagSchedulerStagesFailedDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDagSchedulerStagesFailed.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDagSchedulerStagesRunningDataPoint adds a data point to databricks.spark.dag_scheduler.stages.running metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDagSchedulerStagesRunningDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDagSchedulerStagesRunning.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDagSchedulerStagesWaitingDataPoint adds a data point to databricks.spark.dag_scheduler.stages.waiting metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDagSchedulerStagesWaitingDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDagSchedulerStagesWaiting.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksDirectoryCommitAutoVacuumCountDataPoint adds a data point to databricks.spark.databricks.directory_commit.auto_vacuum.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksDirectoryCommitAutoVacuumCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksDirectoryCommitAutoVacuumCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksDirectoryCommitDeletedFilesFilteredDataPoint adds a data point to databricks.spark.databricks.directory_commit.deleted_files_filtered metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksDirectoryCommitDeletedFilesFilteredDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksDirectoryCommitDeletedFilesFiltered.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksDirectoryCommitFilterListingCountDataPoint adds a data point to databricks.spark.databricks.directory_commit.filter_listing.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksDirectoryCommitFilterListingCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksDirectoryCommitFilterListingCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksDirectoryCommitJobCommitCompletedDataPoint adds a data point to databricks.spark.databricks.directory_commit.job_commit_completed metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksDirectoryCommitJobCommitCompletedDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksDirectoryCommitJobCommitCompleted.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksDirectoryCommitMarkerReadErrorsDataPoint adds a data point to databricks.spark.databricks.directory_commit.marker_read.errors metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksDirectoryCommitMarkerReadErrorsDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksDirectoryCommitMarkerReadErrors.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksDirectoryCommitMarkerRefreshCountDataPoint adds a data point to databricks.spark.databricks.directory_commit.marker_refresh.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksDirectoryCommitMarkerRefreshCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrorsDataPoint adds a data point to databricks.spark.databricks.directory_commit.marker_refresh.errors metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrorsDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksDirectoryCommitMarkerRefreshErrors.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksDirectoryCommitMarkersReadDataPoint adds a data point to databricks.spark.databricks.directory_commit.markers.read metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksDirectoryCommitMarkersReadDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksDirectoryCommitMarkersRead.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksDirectoryCommitRepeatedListCountDataPoint adds a data point to databricks.spark.databricks.directory_commit.repeated_list.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksDirectoryCommitRepeatedListCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksDirectoryCommitRepeatedListCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksDirectoryCommitUncommittedFilesFilteredDataPoint adds a data point to databricks.spark.databricks.directory_commit.uncommitted_files.filtered metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksDirectoryCommitUncommittedFilesFilteredDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksDirectoryCommitUncommittedFilesFiltered.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksDirectoryCommitUntrackedFilesFoundDataPoint adds a data point to databricks.spark.databricks.directory_commit.untracked_files.found metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksDirectoryCommitUntrackedFilesFoundDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksDirectoryCommitUntrackedFilesFound.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksDirectoryCommitVacuumCountDataPoint adds a data point to databricks.spark.databricks.directory_commit.vacuum.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksDirectoryCommitVacuumCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksDirectoryCommitVacuumCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksDirectoryCommitVacuumErrorsDataPoint adds a data point to databricks.spark.databricks.directory_commit.vacuum.errors metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksDirectoryCommitVacuumErrorsDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksDirectoryCommitVacuumErrors.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksPreemptionChecksCountDataPoint adds a data point to databricks.spark.databricks.preemption.checks.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksPreemptionChecksCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksPreemptionChecksCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksPreemptionPoolsAutoexpiredCountDataPoint adds a data point to databricks.spark.databricks.preemption.pools_autoexpired.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksPreemptionPoolsAutoexpiredCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksPreemptionPoolsAutoexpiredCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksPreemptionPoolstarvationTimeDataPoint adds a data point to databricks.spark.databricks.preemption.poolstarvation.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksPreemptionPoolstarvationTimeDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksPreemptionPoolstarvationTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksPreemptionSchedulerOverheadTimeDataPoint adds a data point to databricks.spark.databricks.preemption.scheduler_overhead.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksPreemptionSchedulerOverheadTimeDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksPreemptionSchedulerOverheadTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksPreemptionTaskWastedTimeDataPoint adds a data point to databricks.spark.databricks.preemption.task_wasted.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksPreemptionTaskWastedTimeDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksPreemptionTaskWastedTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksPreemptionTasksPreemptedCountDataPoint adds a data point to databricks.spark.databricks.preemption.tasks_preempted.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksPreemptionTasksPreemptedCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksPreemptionTasksPreemptedCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksTaskSchedulingLanesActivePoolsDataPoint adds a data point to databricks.spark.databricks.task_scheduling_lanes.active_pools metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksTaskSchedulingLanesActivePoolsDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesActivePools.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePoolsDataPoint adds a data point to databricks.spark.databricks.task_scheduling_lanes.bypass_lane_active_pools metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePoolsDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesBypassLaneActivePools.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePoolsDataPoint adds a data point to databricks.spark.databricks.task_scheduling_lanes.fast_lane_active_pools metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePoolsDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesFastLaneActivePools.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTimeDataPoint adds a data point to databricks.spark.databricks.task_scheduling_lanes.finished_queries_total_task.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTimeDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesFinishedQueriesTotalTaskTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPoolsDataPoint adds a data point to databricks.spark.databricks.task_scheduling_lanes.lane_cleanup.marked_pools metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPoolsDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupMarkedPools.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleanedDataPoint adds a data point to databricks.spark.databricks.task_scheduling_lanes.lane_cleanup.two_phase_pools_cleaned metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleanedDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupTwoPhasePoolsCleaned.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleanedDataPoint adds a data point to databricks.spark.databricks.task_scheduling_lanes.lane_cleanup.zombie_pools_cleaned metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleanedDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesLaneCleanupZombiePoolsCleaned.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCountDataPoint adds a data point to databricks.spark.databricks.task_scheduling_lanes.preemption.slot_transfer_successful_preemption_iterations.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferSuccessfulPreemptionIterationsCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCountDataPoint adds a data point to databricks.spark.databricks.task_scheduling_lanes.preemption.slot_transfer_tasks_preempted.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferTasksPreemptedCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTimeDataPoint adds a data point to databricks.spark.databricks.task_scheduling_lanes.preemption.slot_transfer_wasted_task.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTimeDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesPreemptionSlotTransferWastedTaskTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCountDataPoint adds a data point to databricks.spark.databricks.task_scheduling_lanes.slot_reservation.gradual_decrease.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationGradualDecreaseCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCountDataPoint adds a data point to databricks.spark.databricks.task_scheduling_lanes.slot_reservation.quick_drop.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickDropCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCountDataPoint adds a data point to databricks.spark.databricks.task_scheduling_lanes.slot_reservation.quick_jump.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationQuickJumpCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReservedDataPoint adds a data point to databricks.spark.databricks.task_scheduling_lanes.slot_reservation.slots_reserved metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReservedDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesSlotReservationSlotsReserved.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePoolsDataPoint adds a data point to databricks.spark.databricks.task_scheduling_lanes.slow_lane_active_pools metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePoolsDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesSlowLaneActivePools.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinishedDataPoint adds a data point to databricks.spark.databricks.task_scheduling_lanes.totalquerygroupsfinished metric.
func (mb *MetricsBuilder) RecordDatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinishedDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkDatabricksTaskSchedulingLanesTotalquerygroupsfinished.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorDiskUsedDataPoint adds a data point to databricks.spark.executor.disk_used metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorDiskUsedDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkExecutorIDAttributeValue string) {
	mb.metricDatabricksSparkExecutorDiskUsed.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkExecutorIDAttributeValue)
}

// RecordDatabricksSparkExecutorMaxMemoryDataPoint adds a data point to databricks.spark.executor.max_memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMaxMemoryDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkExecutorIDAttributeValue string) {
	mb.metricDatabricksSparkExecutorMaxMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkExecutorIDAttributeValue)
}

// RecordDatabricksSparkExecutorMemoryUsedDataPoint adds a data point to databricks.spark.executor.memory_used metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMemoryUsedDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkExecutorIDAttributeValue string) {
	mb.metricDatabricksSparkExecutorMemoryUsed.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkExecutorIDAttributeValue)
}

// RecordDatabricksSparkExecutorTotalInputBytesDataPoint adds a data point to databricks.spark.executor.total_input_bytes metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorTotalInputBytesDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkExecutorIDAttributeValue string) {
	mb.metricDatabricksSparkExecutorTotalInputBytes.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkExecutorIDAttributeValue)
}

// RecordDatabricksSparkExecutorTotalShuffleReadDataPoint adds a data point to databricks.spark.executor.total_shuffle_read metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorTotalShuffleReadDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkExecutorIDAttributeValue string) {
	mb.metricDatabricksSparkExecutorTotalShuffleRead.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkExecutorIDAttributeValue)
}

// RecordDatabricksSparkExecutorTotalShuffleWriteDataPoint adds a data point to databricks.spark.executor.total_shuffle_write metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorTotalShuffleWriteDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkExecutorIDAttributeValue string) {
	mb.metricDatabricksSparkExecutorTotalShuffleWrite.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkExecutorIDAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsDirectPoolMemoryDataPoint adds a data point to databricks.spark.executor_metrics.direct_pool.memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsDirectPoolMemoryDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsDirectPoolMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsJvmHeapMemoryDataPoint adds a data point to databricks.spark.executor_metrics.jvm.heap.memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsJvmHeapMemoryDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsJvmHeapMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsJvmOffHeapMemoryDataPoint adds a data point to databricks.spark.executor_metrics.jvm.off_heap.memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsJvmOffHeapMemoryDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsJvmOffHeapMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsMajorGcCountDataPoint adds a data point to databricks.spark.executor_metrics.major_gc.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsMajorGcCountDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsMajorGcCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsMajorGcTimeDataPoint adds a data point to databricks.spark.executor_metrics.major_gc.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsMajorGcTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsMajorGcTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsMappedPoolMemoryDataPoint adds a data point to databricks.spark.executor_metrics.mapped_pool.memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsMappedPoolMemoryDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsMappedPoolMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsMinorGcCountDataPoint adds a data point to databricks.spark.executor_metrics.minor_gc.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsMinorGcCountDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsMinorGcCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsMinorGcTimeDataPoint adds a data point to databricks.spark.executor_metrics.minor_gc.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsMinorGcTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsMinorGcTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsOffHeapExecutionMemoryDataPoint adds a data point to databricks.spark.executor_metrics.off_heap.execution.memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsOffHeapExecutionMemoryDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsOffHeapExecutionMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsOffHeapStorageMemoryDataPoint adds a data point to databricks.spark.executor_metrics.off_heap.storage.memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsOffHeapStorageMemoryDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsOffHeapStorageMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsOffHeapUnifiedMemoryDataPoint adds a data point to databricks.spark.executor_metrics.off_heap.unified.memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsOffHeapUnifiedMemoryDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsOffHeapUnifiedMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsOnHeapExecutionMemoryDataPoint adds a data point to databricks.spark.executor_metrics.on_heap.execution.memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsOnHeapExecutionMemoryDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsOnHeapExecutionMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsOnHeapStorageMemoryDataPoint adds a data point to databricks.spark.executor_metrics.on_heap.storage.memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsOnHeapStorageMemoryDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsOnHeapStorageMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsOnHeapUnifiedMemoryDataPoint adds a data point to databricks.spark.executor_metrics.on_heap.unified.memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsOnHeapUnifiedMemoryDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsOnHeapUnifiedMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsProcessTreeJvmRssMemoryDataPoint adds a data point to databricks.spark.executor_metrics.process_tree.jvm_rss.memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsProcessTreeJvmRssMemoryDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsProcessTreeJvmRssMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsProcessTreeJvmVMemoryDataPoint adds a data point to databricks.spark.executor_metrics.process_tree.jvm_v.memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsProcessTreeJvmVMemoryDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsProcessTreeJvmVMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsProcessTreeOtherRssMemoryDataPoint adds a data point to databricks.spark.executor_metrics.process_tree.other_rss.memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsProcessTreeOtherRssMemoryDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsProcessTreeOtherRssMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsProcessTreeOtherVMemoryDataPoint adds a data point to databricks.spark.executor_metrics.process_tree.other_v.memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsProcessTreeOtherVMemoryDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsProcessTreeOtherVMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsProcessTreePythonRssMemoryDataPoint adds a data point to databricks.spark.executor_metrics.process_tree.python_rss.memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsProcessTreePythonRssMemoryDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsProcessTreePythonRssMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkExecutorMetricsProcessTreePythonVMemoryDataPoint adds a data point to databricks.spark.executor_metrics.process_tree.python_v.memory metric.
func (mb *MetricsBuilder) RecordDatabricksSparkExecutorMetricsProcessTreePythonVMemoryDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkExecutorMetricsProcessTreePythonVMemory.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkHiveExternalCatalogFileCacheHitsDataPoint adds a data point to databricks.spark.hive_external_catalog.file_cache.hits metric.
func (mb *MetricsBuilder) RecordDatabricksSparkHiveExternalCatalogFileCacheHitsDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkHiveExternalCatalogFileCacheHits.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkHiveExternalCatalogFilesDiscoveredDataPoint adds a data point to databricks.spark.hive_external_catalog.files_discovered metric.
func (mb *MetricsBuilder) RecordDatabricksSparkHiveExternalCatalogFilesDiscoveredDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkHiveExternalCatalogFilesDiscovered.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkHiveExternalCatalogHiveClientCallsDataPoint adds a data point to databricks.spark.hive_external_catalog.hive_client_calls metric.
func (mb *MetricsBuilder) RecordDatabricksSparkHiveExternalCatalogHiveClientCallsDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkHiveExternalCatalogHiveClientCalls.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkHiveExternalCatalogParallelListingJobsCountDataPoint adds a data point to databricks.spark.hive_external_catalog.parallel_listing_jobs.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkHiveExternalCatalogParallelListingJobsCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkHiveExternalCatalogParallelListingJobsCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkHiveExternalCatalogPartitionsFetchedDataPoint adds a data point to databricks.spark.hive_external_catalog.partitions_fetched metric.
func (mb *MetricsBuilder) RecordDatabricksSparkHiveExternalCatalogPartitionsFetchedDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkHiveExternalCatalogPartitionsFetched.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkJobNumActiveStagesDataPoint adds a data point to databricks.spark.job.num_active_stages metric.
func (mb *MetricsBuilder) RecordDatabricksSparkJobNumActiveStagesDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	mb.metricDatabricksSparkJobNumActiveStages.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkJobIDAttributeValue)
}

// RecordDatabricksSparkJobNumActiveTasksDataPoint adds a data point to databricks.spark.job.num_active_tasks metric.
func (mb *MetricsBuilder) RecordDatabricksSparkJobNumActiveTasksDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	mb.metricDatabricksSparkJobNumActiveTasks.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkJobIDAttributeValue)
}

// RecordDatabricksSparkJobNumCompletedStagesDataPoint adds a data point to databricks.spark.job.num_completed_stages metric.
func (mb *MetricsBuilder) RecordDatabricksSparkJobNumCompletedStagesDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	mb.metricDatabricksSparkJobNumCompletedStages.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkJobIDAttributeValue)
}

// RecordDatabricksSparkJobNumCompletedTasksDataPoint adds a data point to databricks.spark.job.num_completed_tasks metric.
func (mb *MetricsBuilder) RecordDatabricksSparkJobNumCompletedTasksDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	mb.metricDatabricksSparkJobNumCompletedTasks.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkJobIDAttributeValue)
}

// RecordDatabricksSparkJobNumFailedStagesDataPoint adds a data point to databricks.spark.job.num_failed_stages metric.
func (mb *MetricsBuilder) RecordDatabricksSparkJobNumFailedStagesDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	mb.metricDatabricksSparkJobNumFailedStages.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkJobIDAttributeValue)
}

// RecordDatabricksSparkJobNumFailedTasksDataPoint adds a data point to databricks.spark.job.num_failed_tasks metric.
func (mb *MetricsBuilder) RecordDatabricksSparkJobNumFailedTasksDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	mb.metricDatabricksSparkJobNumFailedTasks.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkJobIDAttributeValue)
}

// RecordDatabricksSparkJobNumSkippedStagesDataPoint adds a data point to databricks.spark.job.num_skipped_stages metric.
func (mb *MetricsBuilder) RecordDatabricksSparkJobNumSkippedStagesDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	mb.metricDatabricksSparkJobNumSkippedStages.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkJobIDAttributeValue)
}

// RecordDatabricksSparkJobNumSkippedTasksDataPoint adds a data point to databricks.spark.job.num_skipped_tasks metric.
func (mb *MetricsBuilder) RecordDatabricksSparkJobNumSkippedTasksDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	mb.metricDatabricksSparkJobNumSkippedTasks.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkJobIDAttributeValue)
}

// RecordDatabricksSparkJobNumTasksDataPoint adds a data point to databricks.spark.job.num_tasks metric.
func (mb *MetricsBuilder) RecordDatabricksSparkJobNumTasksDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	mb.metricDatabricksSparkJobNumTasks.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkJobIDAttributeValue)
}

// RecordDatabricksSparkJvmCPUTimeDataPoint adds a data point to databricks.spark.jvm.cpu.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkJvmCPUTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkJvmCPUTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkLiveListenerBusEventsPostedCountDataPoint adds a data point to databricks.spark.live_listener_bus.events_posted.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkLiveListenerBusEventsPostedCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkLiveListenerBusEventsPostedCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCountDataPoint adds a data point to databricks.spark.live_listener_bus.queue.app_status.dropped_events.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkLiveListenerBusQueueAppStatusDroppedEventsCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkLiveListenerBusQueueAppstatusSizeDataPoint adds a data point to databricks.spark.live_listener_bus.queue.appstatus.size metric.
func (mb *MetricsBuilder) RecordDatabricksSparkLiveListenerBusQueueAppstatusSizeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkLiveListenerBusQueueAppstatusSize.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCountDataPoint adds a data point to databricks.spark.live_listener_bus.queue.executor_management.dropped_events.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkLiveListenerBusQueueExecutorManagementDroppedEventsCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkLiveListenerBusQueueExecutormanagementSizeDataPoint adds a data point to databricks.spark.live_listener_bus.queue.executormanagement.size metric.
func (mb *MetricsBuilder) RecordDatabricksSparkLiveListenerBusQueueExecutormanagementSizeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkLiveListenerBusQueueExecutormanagementSize.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkLiveListenerBusQueueSharedDroppedEventsCountDataPoint adds a data point to databricks.spark.live_listener_bus.queue.shared.dropped_events.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkLiveListenerBusQueueSharedDroppedEventsCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkLiveListenerBusQueueSharedDroppedEventsCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkLiveListenerBusQueueSharedSizeDataPoint adds a data point to databricks.spark.live_listener_bus.queue.shared.size metric.
func (mb *MetricsBuilder) RecordDatabricksSparkLiveListenerBusQueueSharedSizeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkLiveListenerBusQueueSharedSize.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCountDataPoint adds a data point to databricks.spark.live_listener_bus.queue.streams.dropped_events.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCountDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkLiveListenerBusQueueStreamsDroppedEventsCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkLiveListenerBusQueueStreamsSizeDataPoint adds a data point to databricks.spark.live_listener_bus.queue.streams.size metric.
func (mb *MetricsBuilder) RecordDatabricksSparkLiveListenerBusQueueStreamsSizeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkLiveListenerBusQueueStreamsSize.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkSparkSQLOperationManagerHiveOperationsCountDataPoint adds a data point to databricks.spark.spark_sql_operation_manager.hive_operations.count metric.
func (mb *MetricsBuilder) RecordDatabricksSparkSparkSQLOperationManagerHiveOperationsCountDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, pipelineIDAttributeValue string, pipelineNameAttributeValue string) {
	mb.metricDatabricksSparkSparkSQLOperationManagerHiveOperationsCount.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, pipelineIDAttributeValue, pipelineNameAttributeValue)
}

// RecordDatabricksSparkStageDiskBytesSpilledDataPoint adds a data point to databricks.spark.stage.disk_bytes_spilled metric.
func (mb *MetricsBuilder) RecordDatabricksSparkStageDiskBytesSpilledDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	mb.metricDatabricksSparkStageDiskBytesSpilled.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkJobIDAttributeValue)
}

// RecordDatabricksSparkStageExecutorRunTimeDataPoint adds a data point to databricks.spark.stage.executor_run_time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkStageExecutorRunTimeDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	mb.metricDatabricksSparkStageExecutorRunTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkJobIDAttributeValue)
}

// RecordDatabricksSparkStageInputBytesDataPoint adds a data point to databricks.spark.stage.input_bytes metric.
func (mb *MetricsBuilder) RecordDatabricksSparkStageInputBytesDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	mb.metricDatabricksSparkStageInputBytes.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkJobIDAttributeValue)
}

// RecordDatabricksSparkStageInputRecordsDataPoint adds a data point to databricks.spark.stage.input_records metric.
func (mb *MetricsBuilder) RecordDatabricksSparkStageInputRecordsDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	mb.metricDatabricksSparkStageInputRecords.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkJobIDAttributeValue)
}

// RecordDatabricksSparkStageMemoryBytesSpilledDataPoint adds a data point to databricks.spark.stage.memory_bytes_spilled metric.
func (mb *MetricsBuilder) RecordDatabricksSparkStageMemoryBytesSpilledDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	mb.metricDatabricksSparkStageMemoryBytesSpilled.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkJobIDAttributeValue)
}

// RecordDatabricksSparkStageOutputBytesDataPoint adds a data point to databricks.spark.stage.output_bytes metric.
func (mb *MetricsBuilder) RecordDatabricksSparkStageOutputBytesDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	mb.metricDatabricksSparkStageOutputBytes.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkJobIDAttributeValue)
}

// RecordDatabricksSparkStageOutputRecordsDataPoint adds a data point to databricks.spark.stage.output_records metric.
func (mb *MetricsBuilder) RecordDatabricksSparkStageOutputRecordsDataPoint(ts pcommon.Timestamp, val int64, clusterIDAttributeValue string, sparkAppIDAttributeValue string, sparkJobIDAttributeValue int64) {
	mb.metricDatabricksSparkStageOutputRecords.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue, sparkJobIDAttributeValue)
}

// RecordDatabricksSparkTimerDagSchedulerMessageProcessingTimeDataPoint adds a data point to databricks.spark.timer.dag_scheduler.message_processing.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerDagSchedulerMessageProcessingTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerDagSchedulerMessageProcessingTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.execution.streaming.query_listener_bus.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionStreamingQueryListenerBusTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.execution.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.execution.ui.sql_app_status_listener.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLExecutionUISQLAppStatusListenerTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.hive.thriftserver.ui.hive_thrift_server2listener.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLHiveThriftserverUIHiveThriftServer2listenerTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.spark_session.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLSparkSessionTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.sql.util.execution_listener_bus.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkSQLUtilExecutionListenerBusTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.status.app_status_listener.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkStatusAppStatusListenerTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.apache.spark.util.profiler_env.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingApacheSparkUtilProfilerEnvTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.databricks.backend.daemon.driver.data_plane_event_listener.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDataPlaneEventListenerTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.databricks.backend.daemon.driver.dbc_event_logging_listener.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksBackendDaemonDriverDbcEventLoggingListenerTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.databricks.photon.photon_cleanup_listener.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksPhotonPhotonCleanupListenerTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.databricks.spark.util.executor_time_logging_listener.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilExecutorTimeLoggingListenerTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.databricks.spark.util.usage_logging_listener.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSparkUtilUsageLoggingListenerTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.databricks.sql.advice.advisor_listener.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLAdviceAdvisorListenerTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.databricks.sql.debugger.query_watchdog_listener.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLDebuggerQueryWatchdogListenerTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.databricks.sql.execution.ui.io_cache_listener.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLExecutionUIIoCacheListenerTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.listener_processing.databricks.sql.io.caching.repeated_reads_estimator.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusListenerProcessingDatabricksSQLIoCachingRepeatedReadsEstimatorTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.queue.app_status.listener_processing.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusQueueAppStatusListenerProcessingTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.queue.executor_management.listener_processing.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusQueueExecutorManagementListenerProcessingTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.queue.shared.listener_processing.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusQueueSharedListenerProcessingTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTimeDataPoint adds a data point to databricks.spark.timer.live_listener_bus.queue.streams.listener_processing.time metric.
func (mb *MetricsBuilder) RecordDatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTimeDataPoint(ts pcommon.Timestamp, val float64, clusterIDAttributeValue string, sparkAppIDAttributeValue string) {
	mb.metricDatabricksSparkTimerLiveListenerBusQueueStreamsListenerProcessingTime.recordDataPoint(mb.startTime, ts, val, clusterIDAttributeValue, sparkAppIDAttributeValue)
}

// RecordDatabricksTasksRunDurationDataPoint adds a data point to databricks.tasks.run.duration metric.
func (mb *MetricsBuilder) RecordDatabricksTasksRunDurationDataPoint(ts pcommon.Timestamp, val int64, jobIDAttributeValue int64, taskIDAttributeValue string) {
	mb.metricDatabricksTasksRunDuration.recordDataPoint(mb.startTime, ts, val, jobIDAttributeValue, taskIDAttributeValue)
}

// RecordDatabricksTasksScheduleStatusDataPoint adds a data point to databricks.tasks.schedule.status metric.
func (mb *MetricsBuilder) RecordDatabricksTasksScheduleStatusDataPoint(ts pcommon.Timestamp, val int64, jobIDAttributeValue int64, taskIDAttributeValue string, taskTypeAttributeValue AttributeTaskType) {
	mb.metricDatabricksTasksScheduleStatus.recordDataPoint(mb.startTime, ts, val, jobIDAttributeValue, taskIDAttributeValue, taskTypeAttributeValue.String())
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...metricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op(mb)
	}
}
