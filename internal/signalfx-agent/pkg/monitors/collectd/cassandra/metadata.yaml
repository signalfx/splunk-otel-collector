monitors:
- dimensions:
  doc: |
    Monitors Cassandra using the Collectd GenericJMX plugin.  This is
    essentially a wrapper around the
    [collectd-genericjmx](./collectd-genericjmx.md)[](sfx_link:java) monitor that comes with a
    set of predefined MBean definitions that a standard Cassandra deployment
    will expose.

    Use this integration to monitor the following types of information from Cassandra nodes:

     - read/write/range-slice requests
     - read/write/range-slice errors (timeouts and unavailable)
     - read/write/range-slice latency (median, 99th percentile, maximum)
     - compaction activity
     - hint activity

    Supports Cassandra 2.0.10+.
  metrics:
    # Taken from genericjmx monitor. If you want to change them update genericjmx and update
    # all other monitors that use genericjmx with this same notice.
    ### BEGIN JVM METRICS ###
    gauge.jvm.threads.count:
      description: Number of JVM threads
      group: jvm
      default: true
      type: gauge
    gauge.loaded_classes:
      description: Number of classes loaded in the JVM
      group: jvm
      default: true
      type: gauge
    invocations:
      description: Total number of garbage collection events
      group: jvm
      default: true
      type: cumulative
    jmx_memory.committed:
      description: Amount of memory guaranteed to be available in bytes
      group: jvm
      default: true
      type: gauge
    jmx_memory.max:
      description: Maximum amount of memory that can be used in bytes
      group: jvm
      default: true
      type: gauge
    jmx_memory.used:
      description: Current memory usage in bytes
      group: jvm
      default: true
      type: gauge
    total_time_in_ms.collection_time:
      description: Amount of time spent garbage collecting in milliseconds
      group: jvm
      default: true
      type: cumulative
    jmx_memory.init:
      description: Amount of initial memory at startup in bytes
      group: jvm
      default: true
      type: gauge
    ### END JVM METRICS ###

    counter.cassandra.ClientRequest.RangeSlice.Latency.Count:
      description: |
        Count of range slice operations since server start. This typically indicates a server overload condition.

        If this value is increasing across the cluster then the cluster is too small for the application range slice load.

        If this value is increasing for a single server in a cluster, then one of the following conditions may be true:

        - one or more clients are directing more load to this server than the others
        - the server is experiencing hardware or software issues and may require maintenance.
      default: true
      type: cumulative
    counter.cassandra.ClientRequest.RangeSlice.TotalLatency.Count:
      description: The total number of microseconds elapsed in servicing range slice requests.
      default: false
      type: cumulative
    counter.cassandra.ClientRequest.RangeSlice.Timeouts.Count:
      description: |
        Count of range slice timeouts since server start. This typically indicates a server overload condition.

        If this value is increasing across the cluster then the cluster is too small for the application range slice load.

        If this value is increasing for a single server in a cluster, then one of the following conditions may be true:
        - one or more clients are directing more load to this server than the others
        - the server is experiencing hardware or software issues and may require maintenance.
      default: true
      type: cumulative
    counter.cassandra.ClientRequest.RangeSlice.Unavailables.Count:
      description: |
        Count of range slice unavailables since server start. A non-zero value
        means that insufficient replicas were available to fulfil a range slice
        request at the requested consistency level.

        This typically means that one or more nodes are down. To fix this condition,
        any down nodes must be restarted, or removed from the cluster.
      default: true
      type: cumulative
    counter.cassandra.ClientRequest.Read.Latency.Count:
      description: Count of read operations since server start.
      default: true
      type: cumulative
    counter.cassandra.ClientRequest.Read.TotalLatency.Count:
      description: |
        The total number of microseconds elapsed in servicing client read requests.

        It can be devided by `counter.cassandra.ClientRequest.Read.Latency.Count`
        to find the real time read latency.
      default: false
      type: cumulative
    counter.cassandra.ClientRequest.CASRead.Latency.Count:
      description: Count of transactional read operations since server start.
      default: false
      type: cumulative
    counter.cassandra.ClientRequest.CASRead.TotalLatency.Count:
      description: |
        The total number of microseconds elapsed in servicing client transactional read requests.

        It can be devided by `counter.cassandra.ClientRequest.CASRead.Latency.Count`
        to find the real time transactional read latency.
      default: false
      type: cumulative
    counter.cassandra.ClientRequest.Read.Timeouts.Count:
      description: |
        Count of read timeouts since server start. This typically indicates a server overload condition.

        If this value is increasing across the cluster then the cluster is too small for the application read load.

        If this value is increasing for a single server in a cluster, then one of the following conditions may be true:
        - one or more clients are directing more load to this server than the others
        - the server is experiencing hardware or software issues and may require maintenance.
      default: true
      type: cumulative
    counter.cassandra.ClientRequest.Read.Unavailables.Count:
      description: |
        Count of read unavailables since server start. A non-zero value means
        that insufficient replicas were available to fulfil a read request at
        the requested consistency level. This typically means that one or more
        nodes are down. To fix this condition, any down nodes must be
        restarted, or removed from the cluster.
      default: true
      type: cumulative
    counter.cassandra.ClientRequest.Write.Latency.Count:
      description: Count of write operations since server start.
      default: true
      type: cumulative
    counter.cassandra.ClientRequest.Write.TotalLatency.Count:
      description: |
        The total number of microseconds elapsed in servicing client write requests.

        It can be devided by `counter.cassandra.ClientRequest.Write.Latency.Count`
        to find the real time write latency.
      default: false
      type: cumulative
    counter.cassandra.ClientRequest.CASWrite.Latency.Count:
      description: Count of transactional write operations since server start.
      default: false
      type: cumulative
    counter.cassandra.ClientRequest.CASWrite.TotalLatency.Count:
      description: |
        The total number of microseconds elapsed in servicing client transactional write requests.

        It can be devided by `counter.cassandra.ClientRequest.CASWrite.Latency.Count`
        to find the real time transactional write latency.
      default: false
      type: cumulative
    counter.cassandra.ClientRequest.Write.Timeouts.Count:
      description: |
        Count of write timeouts since server start. This typically indicates a server overload condition.

        If this value is increasing across the cluster then the cluster is too small for the application write load.

        If this value is increasing for a single server in a cluster, then one of the following conditions may be true:
        - one or more clients are directing more load to this server than the others
        - the server is experiencing hardware or software issues and may require maintenance.
      default: true
      type: cumulative
    counter.cassandra.ClientRequest.Write.Unavailables.Count:
      description: |
        Count of write unavailables since server start. A non-zero value means
        that insufficient replicas were available to fulfil a write request at
        the requested consistency level.

        This typically means that one or more nodes are down. To fix this
        condition, any down nodes must be restarted, or removed from the
        cluster.
      default: true
      type: cumulative
    counter.cassandra.Compaction.TotalCompactionsCompleted.Count:
      description: |
        Number of compaction operations since node start. If this value does
        not increase steadily over time then the node may be experiencing
        problems completing compaction operations.
      default: false
      type: cumulative
    gauge.cassandra.ClientRequest.RangeSlice.Latency.50thPercentile:
      description: |
        50th percentile (median) of Cassandra range slice latency. This value
        should be similar across all nodes in the cluster. If some nodes have higher
        values than the rest of the cluster then they may have more connected clients
        or may be experiencing heavier than usual compaction load.
      default: false
      type: gauge
    gauge.cassandra.ClientRequest.RangeSlice.Latency.99thPercentile:
      description: |
        99th percentile of Cassandra range slice latency. This value should be
        similar across all nodes in the cluster. If some nodes have higher values than
        the rest of the cluster then they may have more connected clients or may be
        experiencing heavier than usual compaction load.
      default: true
      type: gauge
    gauge.cassandra.ClientRequest.RangeSlice.Latency.Max:
      description: Maximum Cassandra range slice latency.
      default: false
      type: gauge
    gauge.cassandra.ClientRequest.Read.Latency.50thPercentile:
      description: |
        50th percentile (median) of Cassandra read latency. This value should
        be similar across all nodes in the cluster. If some nodes have higher
        values than the rest of the cluster then they may have more connected
        clients or may be experiencing heavier than usual compaction load.
      default: true
      type: gauge
    gauge.cassandra.ClientRequest.Read.Latency.99thPercentile:
      description: |
        99th percentile of Cassandra read latency. This value should be similar
        across all nodes in the cluster. If some nodes have higher values than
        the rest of the cluster then they may have more connected clients or
        may be experiencing heavier than usual compaction load.
      default: true
      type: gauge
    gauge.cassandra.ClientRequest.Read.Latency.Max:
      description: Maximum Cassandra read latency.
      default: true
      type: gauge
    gauge.cassandra.ClientRequest.CASRead.Latency.50thPercentile:
      description: |
        50th percentile (median) of Cassandra transactional read latency.
      default: false
      type: gauge
    gauge.cassandra.ClientRequest.CASRead.Latency.99thPercentile:
      description: |
        99th percentile of Cassandra transactional read latency.
      default: false
      type: gauge
    gauge.cassandra.ClientRequest.CASRead.Latency.Max:
      description: Maximum Cassandra transactional read latency.
      default: false
      type: gauge
    gauge.cassandra.ClientRequest.Write.Latency.50thPercentile:
      description: |
        50th percentile (median) of Cassandra write latency. This value should
        be similar across all nodes in the cluster. If some nodes have higher
        values than the rest of the cluster then they may have more connected
        clients or may be experiencing heavier than usual compaction load.
      default: true
      type: gauge
    gauge.cassandra.ClientRequest.Write.Latency.99thPercentile:
      description: |
        99th percentile of Cassandra write latency. This value should be
        similar across all nodes in the cluster. If some nodes have higher
        values than the rest of the cluster then they may have more connected
        clients or may be experiencing heavier than usual compaction load.
      default: true
      type: gauge
    gauge.cassandra.ClientRequest.Write.Latency.Max:
      description: Maximum Cassandra write latency
      default: true
      type: gauge
    gauge.cassandra.ClientRequest.CASWrite.Latency.50thPercentile:
      description: |
        50th percentile (median) of Cassandra transactional write latency.
      default: false
      type: gauge
    gauge.cassandra.ClientRequest.CASWrite.Latency.99thPercentile:
      description: |
        99th percentile of Cassandra transactional write latency.
      default: false
      type: gauge
    gauge.cassandra.ClientRequest.CASWrite.Latency.Max:
      description: Maximum Cassandra transactional write latency.
      default: false
      type: gauge
    gauge.cassandra.Compaction.PendingTasks.Value:
      description: |
        Number of compaction operations waiting to run. If this value is
        continually increasing then the node may be experiencing problems
        completing compaction operations.
      default: true
      type: gauge
    counter.cassandra.Storage.Exceptions.Count:
      description: |
        Number of internal exceptions caught. Under normal exceptions this should be zero.
      default: false
      type: cumulative
    counter.cassandra.Storage.Load.Count:
      description: |
        Storage used for Cassandra data in bytes. Use this metric to see how much storage is being used for data by a Cassandra node.

        The value of this metric is influenced by:
        - Total data stored into the database
        - compaction behavior
      default: true
      type: cumulative
    counter.cassandra.Storage.TotalHints.Count:
      description: |
        Total hints since node start. Indicates that write operations cannot be
        delivered to a node, usually because a node is down. If this value is
        increasing and all nodes are up then there may be some connectivity
        issue between nodes in the cluster.
      default: false
      type: cumulative
    counter.cassandra.Storage.TotalHintsInProgress.Count:
      description: |
        Total pending hints. Indicates that write operations cannot be
        delivered to a node, usually because a node is down. If this value is
        increasing and all nodes are up then there may be some connectivity
        issue between nodes in the cluster.
      default: true
      type: cumulative
  monitorType: collectd/cassandra
  sendUnknown: true
  properties:
