// Code generated by monitor-code-gen. DO NOT EDIT.

package spark

import (
	"github.com/signalfx/golib/v3/datapoint"
	"github.com/signalfx/signalfx-agent/pkg/monitors"
)

const monitorType = "collectd/spark"

var groupSet = map[string]bool{}

const (
	counterHiveExternalCatalogFileCacheHits           = "counter.HiveExternalCatalog.fileCacheHits"
	counterHiveExternalCatalogFilesDiscovered         = "counter.HiveExternalCatalog.filesDiscovered"
	counterHiveExternalCatalogHiveClientCalls         = "counter.HiveExternalCatalog.hiveClientCalls"
	counterHiveExternalCatalogParallelListingJobCount = "counter.HiveExternalCatalog.parallelListingJobCount"
	counterHiveExternalCatalogPartitionsFetched       = "counter.HiveExternalCatalog.partitionsFetched"
	counterSparkDriverCompletedTasks                  = "counter.spark.driver.completed_tasks"
	counterSparkDriverDiskUsed                        = "counter.spark.driver.disk_used"
	counterSparkDriverFailedTasks                     = "counter.spark.driver.failed_tasks"
	counterSparkDriverMemoryUsed                      = "counter.spark.driver.memory_used"
	counterSparkDriverTotalDuration                   = "counter.spark.driver.total_duration"
	counterSparkDriverTotalInputBytes                 = "counter.spark.driver.total_input_bytes"
	counterSparkDriverTotalShuffleRead                = "counter.spark.driver.total_shuffle_read"
	counterSparkDriverTotalShuffleWrite               = "counter.spark.driver.total_shuffle_write"
	counterSparkDriverTotalTasks                      = "counter.spark.driver.total_tasks"
	counterSparkExecutorCompletedTasks                = "counter.spark.executor.completed_tasks"
	counterSparkExecutorDiskUsed                      = "counter.spark.executor.disk_used"
	counterSparkExecutorFailedTasks                   = "counter.spark.executor.failed_tasks"
	counterSparkExecutorMemoryUsed                    = "counter.spark.executor.memory_used"
	counterSparkExecutorTotalDuration                 = "counter.spark.executor.total_duration"
	counterSparkExecutorTotalInputBytes               = "counter.spark.executor.total_input_bytes"
	counterSparkExecutorTotalShuffleRead              = "counter.spark.executor.total_shuffle_read"
	counterSparkExecutorTotalShuffleWrite             = "counter.spark.executor.total_shuffle_write"
	counterSparkExecutorTotalTasks                    = "counter.spark.executor.total_tasks"
	counterSparkStreamingNumProcessedRecords          = "counter.spark.streaming.num_processed_records"
	counterSparkStreamingNumReceivedRecords           = "counter.spark.streaming.num_received_records"
	counterSparkStreamingNumTotalCompletedBatches     = "counter.spark.streaming.num_total_completed_batches"
	gaugeJvmMarkSweepCompactCount                     = "gauge.jvm.MarkSweepCompact.count"
	gaugeJvmMarkSweepCompactTime                      = "gauge.jvm.MarkSweepCompact.time"
	gaugeJvmHeapCommitted                             = "gauge.jvm.heap.committed"
	gaugeJvmHeapUsed                                  = "gauge.jvm.heap.used"
	gaugeJvmNonHeapCommitted                          = "gauge.jvm.non-heap.committed"
	gaugeJvmNonHeapUsed                               = "gauge.jvm.non-heap.used"
	gaugeJvmPoolsCodeCacheCommitted                   = "gauge.jvm.pools.Code-Cache.committed"
	gaugeJvmPoolsCodeCacheUsed                        = "gauge.jvm.pools.Code-Cache.used"
	gaugeJvmPoolsCompressedClassSpaceCommitted        = "gauge.jvm.pools.Compressed-Class-Space.committed"
	gaugeJvmPoolsCompressedClassSpaceUsed             = "gauge.jvm.pools.Compressed-Class-Space.used"
	gaugeJvmPoolsEdenSpaceCommitted                   = "gauge.jvm.pools.Eden-Space.committed"
	gaugeJvmPoolsEdenSpaceUsed                        = "gauge.jvm.pools.Eden-Space.used"
	gaugeJvmPoolsMetaspaceCommitted                   = "gauge.jvm.pools.Metaspace.committed"
	gaugeJvmPoolsMetaspaceUsed                        = "gauge.jvm.pools.Metaspace.used"
	gaugeJvmPoolsSurvivorSpaceCommitted               = "gauge.jvm.pools.Survivor-Space.committed"
	gaugeJvmPoolsSurvivorSpaceUsed                    = "gauge.jvm.pools.Survivor-Space.used"
	gaugeJvmPoolsTenuredGenCommitted                  = "gauge.jvm.pools.Tenured-Gen.committed"
	gaugeJvmPoolsTenuredGenUsed                       = "gauge.jvm.pools.Tenured-Gen.used"
	gaugeJvmTotalCommitted                            = "gauge.jvm.total.committed"
	gaugeJvmTotalUsed                                 = "gauge.jvm.total.used"
	gaugeMasterAliveWorkers                           = "gauge.master.aliveWorkers"
	gaugeMasterApps                                   = "gauge.master.apps"
	gaugeMasterWaitingApps                            = "gauge.master.waitingApps"
	gaugeMasterWorkers                                = "gauge.master.workers"
	gaugeSparkDriverActiveTasks                       = "gauge.spark.driver.active_tasks"
	gaugeSparkDriverMaxMemory                         = "gauge.spark.driver.max_memory"
	gaugeSparkDriverRddBlocks                         = "gauge.spark.driver.rdd_blocks"
	gaugeSparkExecutorActiveTasks                     = "gauge.spark.executor.active_tasks"
	gaugeSparkExecutorCount                           = "gauge.spark.executor.count"
	gaugeSparkExecutorMaxMemory                       = "gauge.spark.executor.max_memory"
	gaugeSparkExecutorRddBlocks                       = "gauge.spark.executor.rdd_blocks"
	gaugeSparkJobNumActiveStages                      = "gauge.spark.job.num_active_stages"
	gaugeSparkJobNumActiveTasks                       = "gauge.spark.job.num_active_tasks"
	gaugeSparkJobNumCompletedStages                   = "gauge.spark.job.num_completed_stages"
	gaugeSparkJobNumCompletedTasks                    = "gauge.spark.job.num_completed_tasks"
	gaugeSparkJobNumFailedStages                      = "gauge.spark.job.num_failed_stages"
	gaugeSparkJobNumFailedTasks                       = "gauge.spark.job.num_failed_tasks"
	gaugeSparkJobNumSkippedStages                     = "gauge.spark.job.num_skipped_stages"
	gaugeSparkJobNumSkippedTasks                      = "gauge.spark.job.num_skipped_tasks"
	gaugeSparkJobNumTasks                             = "gauge.spark.job.num_tasks"
	gaugeSparkNumActiveStages                         = "gauge.spark.num_active_stages"
	gaugeSparkNumRunningJobs                          = "gauge.spark.num_running_jobs"
	gaugeSparkStageDiskBytesSpilled                   = "gauge.spark.stage.disk_bytes_spilled"
	gaugeSparkStageExecutorRunTime                    = "gauge.spark.stage.executor_run_time"
	gaugeSparkStageInputBytes                         = "gauge.spark.stage.input_bytes"
	gaugeSparkStageInputRecords                       = "gauge.spark.stage.input_records"
	gaugeSparkStageMemoryBytesSpilled                 = "gauge.spark.stage.memory_bytes_spilled"
	gaugeSparkStageOutputBytes                        = "gauge.spark.stage.output_bytes"
	gaugeSparkStageOutputRecords                      = "gauge.spark.stage.output_records"
	gaugeSparkStageShuffleReadBytes                   = "gauge.spark.stage.shuffle_read_bytes"
	gaugeSparkStageShuffleReadRecords                 = "gauge.spark.stage.shuffle_read_records"
	gaugeSparkStageShuffleWriteBytes                  = "gauge.spark.stage.shuffle_write_bytes"
	gaugeSparkStageShuffleWriteRecords                = "gauge.spark.stage.shuffle_write_records"
	gaugeSparkStreamingAvgInputRate                   = "gauge.spark.streaming.avg_input_rate"
	gaugeSparkStreamingAvgProcessingTime              = "gauge.spark.streaming.avg_processing_time"
	gaugeSparkStreamingAvgSchedulingDelay             = "gauge.spark.streaming.avg_scheduling_delay"
	gaugeSparkStreamingAvgTotalDelay                  = "gauge.spark.streaming.avg_total_delay"
	gaugeSparkStreamingNumActiveBatches               = "gauge.spark.streaming.num_active_batches"
	gaugeSparkStreamingNumInactiveReceivers           = "gauge.spark.streaming.num_inactive_receivers"
	gaugeWorkerCoresFree                              = "gauge.worker.coresFree"
	gaugeWorkerCoresUsed                              = "gauge.worker.coresUsed"
	gaugeWorkerExecutors                              = "gauge.worker.executors"
	gaugeWorkerMemFreeMB                              = "gauge.worker.memFree_MB"
	gaugeWorkerMemUsedMB                              = "gauge.worker.memUsed_MB"
)

var metricSet = map[string]monitors.MetricInfo{
	counterHiveExternalCatalogFileCacheHits:           {Type: datapoint.Count},
	counterHiveExternalCatalogFilesDiscovered:         {Type: datapoint.Count},
	counterHiveExternalCatalogHiveClientCalls:         {Type: datapoint.Count},
	counterHiveExternalCatalogParallelListingJobCount: {Type: datapoint.Count},
	counterHiveExternalCatalogPartitionsFetched:       {Type: datapoint.Count},
	counterSparkDriverCompletedTasks:                  {Type: datapoint.Count},
	counterSparkDriverDiskUsed:                        {Type: datapoint.Count},
	counterSparkDriverFailedTasks:                     {Type: datapoint.Count},
	counterSparkDriverMemoryUsed:                      {Type: datapoint.Count},
	counterSparkDriverTotalDuration:                   {Type: datapoint.Count},
	counterSparkDriverTotalInputBytes:                 {Type: datapoint.Count},
	counterSparkDriverTotalShuffleRead:                {Type: datapoint.Count},
	counterSparkDriverTotalShuffleWrite:               {Type: datapoint.Count},
	counterSparkDriverTotalTasks:                      {Type: datapoint.Count},
	counterSparkExecutorCompletedTasks:                {Type: datapoint.Count},
	counterSparkExecutorDiskUsed:                      {Type: datapoint.Count},
	counterSparkExecutorFailedTasks:                   {Type: datapoint.Count},
	counterSparkExecutorMemoryUsed:                    {Type: datapoint.Count},
	counterSparkExecutorTotalDuration:                 {Type: datapoint.Count},
	counterSparkExecutorTotalInputBytes:               {Type: datapoint.Count},
	counterSparkExecutorTotalShuffleRead:              {Type: datapoint.Count},
	counterSparkExecutorTotalShuffleWrite:             {Type: datapoint.Count},
	counterSparkExecutorTotalTasks:                    {Type: datapoint.Count},
	counterSparkStreamingNumProcessedRecords:          {Type: datapoint.Count},
	counterSparkStreamingNumReceivedRecords:           {Type: datapoint.Count},
	counterSparkStreamingNumTotalCompletedBatches:     {Type: datapoint.Count},
	gaugeJvmMarkSweepCompactCount:                     {Type: datapoint.Gauge},
	gaugeJvmMarkSweepCompactTime:                      {Type: datapoint.Gauge},
	gaugeJvmHeapCommitted:                             {Type: datapoint.Gauge},
	gaugeJvmHeapUsed:                                  {Type: datapoint.Gauge},
	gaugeJvmNonHeapCommitted:                          {Type: datapoint.Gauge},
	gaugeJvmNonHeapUsed:                               {Type: datapoint.Gauge},
	gaugeJvmPoolsCodeCacheCommitted:                   {Type: datapoint.Gauge},
	gaugeJvmPoolsCodeCacheUsed:                        {Type: datapoint.Gauge},
	gaugeJvmPoolsCompressedClassSpaceCommitted:        {Type: datapoint.Gauge},
	gaugeJvmPoolsCompressedClassSpaceUsed:             {Type: datapoint.Gauge},
	gaugeJvmPoolsEdenSpaceCommitted:                   {Type: datapoint.Gauge},
	gaugeJvmPoolsEdenSpaceUsed:                        {Type: datapoint.Gauge},
	gaugeJvmPoolsMetaspaceCommitted:                   {Type: datapoint.Gauge},
	gaugeJvmPoolsMetaspaceUsed:                        {Type: datapoint.Gauge},
	gaugeJvmPoolsSurvivorSpaceCommitted:               {Type: datapoint.Gauge},
	gaugeJvmPoolsSurvivorSpaceUsed:                    {Type: datapoint.Gauge},
	gaugeJvmPoolsTenuredGenCommitted:                  {Type: datapoint.Gauge},
	gaugeJvmPoolsTenuredGenUsed:                       {Type: datapoint.Gauge},
	gaugeJvmTotalCommitted:                            {Type: datapoint.Gauge},
	gaugeJvmTotalUsed:                                 {Type: datapoint.Gauge},
	gaugeMasterAliveWorkers:                           {Type: datapoint.Gauge},
	gaugeMasterApps:                                   {Type: datapoint.Gauge},
	gaugeMasterWaitingApps:                            {Type: datapoint.Gauge},
	gaugeMasterWorkers:                                {Type: datapoint.Gauge},
	gaugeSparkDriverActiveTasks:                       {Type: datapoint.Gauge},
	gaugeSparkDriverMaxMemory:                         {Type: datapoint.Gauge},
	gaugeSparkDriverRddBlocks:                         {Type: datapoint.Gauge},
	gaugeSparkExecutorActiveTasks:                     {Type: datapoint.Gauge},
	gaugeSparkExecutorCount:                           {Type: datapoint.Gauge},
	gaugeSparkExecutorMaxMemory:                       {Type: datapoint.Gauge},
	gaugeSparkExecutorRddBlocks:                       {Type: datapoint.Gauge},
	gaugeSparkJobNumActiveStages:                      {Type: datapoint.Gauge},
	gaugeSparkJobNumActiveTasks:                       {Type: datapoint.Gauge},
	gaugeSparkJobNumCompletedStages:                   {Type: datapoint.Gauge},
	gaugeSparkJobNumCompletedTasks:                    {Type: datapoint.Gauge},
	gaugeSparkJobNumFailedStages:                      {Type: datapoint.Gauge},
	gaugeSparkJobNumFailedTasks:                       {Type: datapoint.Gauge},
	gaugeSparkJobNumSkippedStages:                     {Type: datapoint.Gauge},
	gaugeSparkJobNumSkippedTasks:                      {Type: datapoint.Gauge},
	gaugeSparkJobNumTasks:                             {Type: datapoint.Gauge},
	gaugeSparkNumActiveStages:                         {Type: datapoint.Gauge},
	gaugeSparkNumRunningJobs:                          {Type: datapoint.Gauge},
	gaugeSparkStageDiskBytesSpilled:                   {Type: datapoint.Gauge},
	gaugeSparkStageExecutorRunTime:                    {Type: datapoint.Gauge},
	gaugeSparkStageInputBytes:                         {Type: datapoint.Gauge},
	gaugeSparkStageInputRecords:                       {Type: datapoint.Gauge},
	gaugeSparkStageMemoryBytesSpilled:                 {Type: datapoint.Gauge},
	gaugeSparkStageOutputBytes:                        {Type: datapoint.Gauge},
	gaugeSparkStageOutputRecords:                      {Type: datapoint.Gauge},
	gaugeSparkStageShuffleReadBytes:                   {Type: datapoint.Gauge},
	gaugeSparkStageShuffleReadRecords:                 {Type: datapoint.Gauge},
	gaugeSparkStageShuffleWriteBytes:                  {Type: datapoint.Gauge},
	gaugeSparkStageShuffleWriteRecords:                {Type: datapoint.Gauge},
	gaugeSparkStreamingAvgInputRate:                   {Type: datapoint.Gauge},
	gaugeSparkStreamingAvgProcessingTime:              {Type: datapoint.Gauge},
	gaugeSparkStreamingAvgSchedulingDelay:             {Type: datapoint.Gauge},
	gaugeSparkStreamingAvgTotalDelay:                  {Type: datapoint.Gauge},
	gaugeSparkStreamingNumActiveBatches:               {Type: datapoint.Gauge},
	gaugeSparkStreamingNumInactiveReceivers:           {Type: datapoint.Gauge},
	gaugeWorkerCoresFree:                              {Type: datapoint.Gauge},
	gaugeWorkerCoresUsed:                              {Type: datapoint.Gauge},
	gaugeWorkerExecutors:                              {Type: datapoint.Gauge},
	gaugeWorkerMemFreeMB:                              {Type: datapoint.Gauge},
	gaugeWorkerMemUsedMB:                              {Type: datapoint.Gauge},
}

var defaultMetrics = map[string]bool{
	counterSparkDriverDiskUsed:                    true,
	counterSparkDriverMemoryUsed:                  true,
	counterSparkDriverTotalInputBytes:             true,
	counterSparkDriverTotalShuffleRead:            true,
	counterSparkDriverTotalShuffleWrite:           true,
	counterSparkDriverTotalTasks:                  true,
	counterSparkExecutorDiskUsed:                  true,
	counterSparkExecutorMemoryUsed:                true,
	counterSparkExecutorTotalInputBytes:           true,
	counterSparkExecutorTotalShuffleRead:          true,
	counterSparkExecutorTotalShuffleWrite:         true,
	counterSparkStreamingNumProcessedRecords:      true,
	counterSparkStreamingNumReceivedRecords:       true,
	counterSparkStreamingNumTotalCompletedBatches: true,
	gaugeJvmHeapCommitted:                         true,
	gaugeJvmHeapUsed:                              true,
	gaugeJvmNonHeapCommitted:                      true,
	gaugeJvmNonHeapUsed:                           true,
	gaugeJvmTotalCommitted:                        true,
	gaugeJvmTotalUsed:                             true,
	gaugeMasterAliveWorkers:                       true,
	gaugeMasterApps:                               true,
	gaugeMasterWaitingApps:                        true,
	gaugeMasterWorkers:                            true,
	gaugeSparkDriverMaxMemory:                     true,
	gaugeSparkExecutorCount:                       true,
	gaugeSparkExecutorMaxMemory:                   true,
	gaugeSparkJobNumActiveStages:                  true,
	gaugeSparkJobNumActiveTasks:                   true,
	gaugeSparkJobNumCompletedStages:               true,
	gaugeSparkJobNumCompletedTasks:                true,
	gaugeSparkJobNumFailedStages:                  true,
	gaugeSparkJobNumFailedTasks:                   true,
	gaugeSparkJobNumSkippedStages:                 true,
	gaugeSparkJobNumSkippedTasks:                  true,
	gaugeSparkJobNumTasks:                         true,
	gaugeSparkNumActiveStages:                     true,
	gaugeSparkNumRunningJobs:                      true,
	gaugeSparkStageDiskBytesSpilled:               true,
	gaugeSparkStageExecutorRunTime:                true,
	gaugeSparkStageInputBytes:                     true,
	gaugeSparkStageInputRecords:                   true,
	gaugeSparkStageMemoryBytesSpilled:             true,
	gaugeSparkStageOutputBytes:                    true,
	gaugeSparkStageOutputRecords:                  true,
	gaugeSparkStreamingAvgInputRate:               true,
	gaugeSparkStreamingAvgProcessingTime:          true,
	gaugeSparkStreamingAvgSchedulingDelay:         true,
	gaugeSparkStreamingAvgTotalDelay:              true,
	gaugeSparkStreamingNumActiveBatches:           true,
	gaugeSparkStreamingNumInactiveReceivers:       true,
	gaugeWorkerCoresFree:                          true,
	gaugeWorkerCoresUsed:                          true,
	gaugeWorkerExecutors:                          true,
	gaugeWorkerMemFreeMB:                          true,
	gaugeWorkerMemUsedMB:                          true,
}

var groupMetricsMap = map[string][]string{}

var monitorMetadata = monitors.Metadata{
	MonitorType:     "collectd/spark",
	DefaultMetrics:  defaultMetrics,
	Metrics:         metricSet,
	SendUnknown:     false,
	Groups:          groupSet,
	GroupMetricsMap: groupMetricsMap,
	SendAll:         false,
}
