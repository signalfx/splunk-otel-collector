packageDir: meta
common:
  &common
  dimensions:
    kubernetes_name:
      description: The name of the resource that the metric describes
    kubernetes_namespace:
      description: The namespace of the resource that the metric describes
    kubernetes_node_uid:
      description: The UID of the node, as defined by the `uid` field of the node
        resource.
    kubernetes_pod_uid:
      description: The UID of the pod that the metric describes
    machine_id:
      description: The machine ID from /etc/machine-id.  This should be unique across
        all nodes in your cluster, but some cluster deployment tools don't guarantee
        this.  This will not be sent if the `useNodeName` config option is set to
        true.
    quota_name:
      description: The name of the k8s ResourceQuota object that the quota is part
        of
    resource:
      description: The k8s resource that the quota applies to
  sendUnknown: true
  metrics:
    kubernetes.container_cpu_limit:
      description: Maximum CPU limit set for the container. This value is derived from
        https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#resourcerequirements-v1-core which
        comes from the pod spec and is reported only if a non null value is available.
      default: true
      type: gauge
    kubernetes.container_cpu_request:
      description: CPU requested for the container. This value is derived from
        https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#resourcerequirements-v1-core
        which comes from the pod spec and is reported only if a non null value is available.
      default: false
      type: gauge
    kubernetes.container_ephemeral_storage_limit:
      description: Maximum ephemeral storage set for the container. This value is derived from
        https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#resourcerequirements-v1-core which
        comes from the pod spec and is reported only if a non null value is available.
        See https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#local-ephemeral-storage
        for details.
      default: false
      type: gauge
    kubernetes.container_ephemeral_storage_request:
      description: Ephemeral storage requested for the container. This value is derived from
        https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#resourcerequirements-v1-core
        which comes from the pod spec and is reported only if a non null value is available.
        See https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#local-ephemeral-storage
        for details
      default: false
      type: gauge
    kubernetes.container_memory_limit:
      description: Maximum memory limit set for the container. This value is derived from
        https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#resourcerequirements-v1-core
        which comes from the pod spec and is reported only if a non null value is available.
      default: true
      type: gauge
    kubernetes.container_memory_request:
      description: Memory requested for the container. This value is derived from
        https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#resourcerequirements-v1-core
        which comes from the pod spec and is reported only if a non null value is available.
      default: false
      type: gauge
    kubernetes.container_ready:
      description: Whether a container has passed its readiness probe (0 for no, 1
        for yes)
      default: true
      type: gauge
    kubernetes.container_restart_count:
      description: How many times the container has restarted in the recent past.  This
        value is pulled directly from [the K8s API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#containerstatus-v1-core)
        and the value can go indefinitely high and be reset to 0 at any time depending
        on how your [kubelet is configured to prune dead containers](https://kubernetes.io/docs/concepts/cluster-administration/kubelet-garbage-collection/).
        It is best to not depend too much on the exact value but rather look at it
        as either `== 0`, in which case you can conclude there were no restarts in
        the recent past, or `> 0`, in which case you can conclude there were restarts
        in the recent past, and not try and analyze the value beyond that.
      default: true
      type: gauge
    kubernetes.daemon_set.current_scheduled:
      description: The number of nodes that are running at least 1 daemon pod and
        are supposed to run the daemon pod
      default: true
      type: gauge
    kubernetes.daemon_set.desired_scheduled:
      description: The total number of nodes that should be running the daemon pod
        (including nodes currently running the daemon pod)
      default: true
      type: gauge
    kubernetes.daemon_set.misscheduled:
      description: The number of nodes that are running the daemon pod, but are not
        supposed to run the daemon pod
      default: true
      type: gauge
    kubernetes.daemon_set.ready:
      description: The number of nodes that should be running the daemon pod and have
        one or more of the daemon pod running and ready
      default: true
      type: gauge
    kubernetes.daemon_set.updated:
      description: The total number of nodes that are running updated daemon pod
      default: false
      type: gauge
    kubernetes.deployment.available:
      description: Total number of available pods (ready for at least minReadySeconds)
        targeted by this deployment.
      default: true
      type: gauge
    kubernetes.deployment.desired:
      description: Number of desired pods in this deployment
      default: true
      type: gauge
    kubernetes.deployment.updated:
      description: Total number of non-terminated pods targeted by this deployment that have the desired template spec
      default: false
      type: gauge
    kubernetes.namespace_phase:
      description: The current phase of namespaces (`1` for _active_ and `0` for _terminating_)
      default: true
      type: gauge
    kubernetes.node_ready:
      description: Whether this node is ready (1), not ready (0) or in an unknown
        state (-1)
      default: true
      type: gauge
    kubernetes.node_allocatable_cpu:
      description: How many CPU cores remaining that the node can allocate to pods
      default: false
      type: gauge
    kubernetes.node_allocatable_memory:
      description: How many bytes of RAM memory remaining that the node can allocate to pods
      default: false
      type: gauge
    kubernetes.node_allocatable_storage:
      description: How many bytes of storage remaining that the node can allocate to pods
      default: false
      type: gauge
    kubernetes.node_allocatable_ephemeral_storage:
      description: How many bytes of ephemeral storage remaining that the node can allocate to pods
      default: false
      type: gauge
    kubernetes.pod_phase:
      description: Current phase of the pod (1 - Pending, 2 - Running, 3 - Succeeded,
        4 - Failed, 5 - Unknown)
      default: true
      type: gauge
    kubernetes.replica_set.available:
      description: Total number of available pods (ready for at least minReadySeconds)
        targeted by this replica set
      default: true
      type: gauge
    kubernetes.replica_set.desired:
      description: Number of desired pods in this replica set
      default: true
      type: gauge
    kubernetes.replication_controller.available:
      description: Total number of available pods (ready for at least minReadySeconds)
        targeted by this replication controller.
      default: true
      type: gauge
    kubernetes.replication_controller.desired:
      description: Number of desired pods (the `spec.replicas` field)
      default: true
      type: gauge
    kubernetes.resource_quota_hard:
      description: The upper limit for a particular resource in a specific namespace.  Will
        only be sent if a quota is specified. CPU requests/limits will be sent as
        millicores.
      default: true
      type: gauge
    kubernetes.resource_quota_used:
      description: The usage for a particular resource in a specific namespace.  Will
        only be sent if a quota is specified. CPU requests/limits will be sent as
        millicores.
      default: true
      type: gauge
    kubernetes.stateful_set.desired:
      description: Number of desired pods in the stateful set (the `spec.replicas` field)
      default: false
      type: gauge
    kubernetes.stateful_set.ready:
      description: Number of pods created by the stateful set that have the `Ready` condition
      default: false
      type: gauge
    kubernetes.stateful_set.current:
      description: |
        The number of pods created by the StatefulSet controller from the
        StatefulSet version indicated by `current_revision` property on the
        `kubernetes_uid` dimension for this StatefulSet.
      default: false
      type: gauge
    kubernetes.stateful_set.updated:
      description: |
        The number of pods created by the StatefulSet controller from the
        StatefulSet version indicated by the `update_revision` property on the
        `kubernetes_uid` dimension for this StatefulSet.
      default: false
      type: gauge
    kubernetes.job.completions:
      description: The desired number of successfully finished pods the job should be
        run with.
      default: false
      type: gauge
    kubernetes.job.parallelism:
      description: The max desired number of pods the job should run at any given time.
      default: false
      type: gauge
    kubernetes.job.active:
      description: The number of actively running pods for a job.
      default: false
      type: gauge
    kubernetes.job.succeeded:
      description: The number of pods which reached phase Succeeded for a job.
      default: false
      type: cumulative
    kubernetes.job.failed:
      description: The number of pods which reased phase Failed for a job.
      default: false
      type: cumulative
    kubernetes.cronjob.active:
      description: The number of actively running jobs for a cronjob.
      default: false
      type: gauge
    kubernetes.hpa.spec.max_replicas:
      description: The upper limit for the number of replicas to which the autoscaler can scale up. It cannot be less that minReplicas.
      default: false
      type: gauge
      group: hpa
    kubernetes.hpa.spec.min_replicas:
      description: The lower limit for the number of replicas to which the autoscaler can scale down. It defaults to 1 pod.
      default: false
      type: gauge
      group: hpa
    kubernetes.hpa.status.current_replicas:
      description: The current number of pod replicas managed by this autoscaler.
      default: false
      type: gauge
      group: hpa
    kubernetes.hpa.status.desired_replicas:
      description: The desired number of pod replicas managed by this autoscaler.
      default: false
      type: gauge
      group: hpa
    kubernetes.hpa.status.condition.scaling_active:
      description: 'A status value that indicates the autoscaler status in reference to the ScalingActive condition.
      A value of 1 means that the autoscaler is in the ScalingActive condition, a 0 value means that it is not, and -1
      means that the status of the ScalingActive condition is unknown. ScalingActive indicates that the HPA controller
      is able to scale if necessary.'
      default: false
      type: gauge
      group: hpa
    kubernetes.hpa.status.condition.able_to_scale:
      description: 'A status value that indicates the autoscaler status in reference to the AbleToScale condition.
        A value of 1 means that the autoscaler is in the AbleToScale condition, a 0 value means that it is not, and -1
        means that the status of the AbleToScale condition is unknown. AbleToScale indicates a lack of transient issues
        which prevent scaling from occurring, such as being in a backoff window, or being unable to access/update the
        target scale.'
      default: false
      type: gauge
      group: hpa
    kubernetes.hpa.status.condition.scaling_limited:
      description: 'A status value that indicates the autoscaler status in reference to the ScalingLimited condition.
        A value of 1 means that the autoscaler is in the ScalingLimited condition, a 0 value means that it is not, and -1
        means that the status of the ScalingLimited condition is unknown. ScalingLimited indicates that the calculated
        scale based on metrics would be above or below the range for the HPA, and has thus been capped.'
      default: false
      type: gauge
      group: hpa
  properties:
    <node label>:
      description: All non-blank labels on a given node will be synced as
        properties to the `kubernetes_node_uid` dimension value for that node.
        Any blank values will be synced as tags on that same dimension.
      dimension: kubernetes_node_uid
    <pod label>:
      description: Any labels with non-blank values on the pod will be synced as properties
        to the `kubernetes_pod_uid` dimension. Any blank labels will be synced as
        tags on that same dimension.
      dimension: kubernetes_pod_uid
    container_status:
      description: Status of the container such as `running`, `waiting` or `terminated` are
        synced to the `container_id` dimension.
      dimension: container_id
    container_status_reason:
      description: Reason why a container is in a particular state. This property is synced
        to `container_id` only if the value of `cotnainer_status` is either `waiting` or
        `terminated`.
      dimension: container_id
    cronjob_creation_timestamp:
      description: Timestamp (in RFC3339 format) representing the server time when the cron
        job was created and is in UTC. This property is synced onto `kubernetes_uid`.
      dimension: kubernetes_uid
    daemonset_creation_timestamp:
      description: Timestamp (in RFC3339 format) representing the server time when the daemon
        set was created and is in UTC. This property is synced onto `kubernetes_uid`.
      dimension: kubernetes_uid
    deployment_creation_timestamp:
      description: Timestamp (in RFC3339 format) representing the server time when the
        deployment was created and is in UTC. This property is synced onto `kubernetes_uid`.
      dimension: kubernetes_uid
    job_creation_timestamp:
      description: Timestamp (in RFC3339 format) representing the server time when the job was
        created and is in UTC. This property is synced onto `kubernetes_uid`.
      dimension: kubernetes_uid
    pod_creation_timestamp:
      description: Timestamp (in RFC3339 format) representing the server time when the pod was
        created and is in UTC. This property is synced onto `kubernetes_pod_uid`.
      dimension: kubernetes_pod_uid
    replicaset_creation_timestamp:
      description: Timestamp (in RFC3339 format) representing the server time when the replica
        set was created and is in UTC. This property is synced onto `kubernetes_uid`.
      dimension: kubernetes_uid
    statefulset_creation_timestamp:
      description: Timestamp (in RFC3339 format) representing the server time when the stateful
        set was created and is in UTC. This property is synced onto `kubernetes_uid`.
      dimension: kubernetes_uid
    node_creation_timestamp:
      description: CreationTimestamp is a timestamp representing the server time when the node was
        created and is in UTC. This property is synced onto `kubernetes_node_uid`.
      dimension: kubernetes_node_uid

monitors:
- <<: *common
  doc: |
    *If you are using OpenShift there is an* [openshift-cluster](openshift-cluster.md)
    *monitor to be used instead of this monitor that contains additional OpenShift metrics.*

    Collects cluster-level metrics from the Kubernetes API server.  It uses the
    _watch_ functionality of the K8s API to listen for updates about the cluster
    and maintains a cache of metrics that get sent on a regular interval.

    Since the agent is generally running in multiple places in a K8s cluster and
    since it is generally more convenient to share the same configuration across
    all agent instances, this monitor by default makes use of a leader election
    process to ensure that it is the only agent sending metrics in a cluster.
    All of the agents running in the same namespace that have this monitor
    configured will decide amongst themselves which should send metrics for this
    monitor, and the rest will stand by ready to activate if the leader agent
    dies.  You can override leader election by setting the config option
    `alwaysClusterReporter` to true, which will make the monitor always report
    metrics.

    This monitor is similar to
    [kube-state-metrics](https://github.com/kubernetes/kube-state-metrics), and
    sends many of the same metrics, but in a way that is less verbose and better
    fitted for the SignalFx backend.
  monitorType: kubernetes-cluster
  dimensions:
    metric_source:
      description: This is always set to `kubernetes`

- <<: *common
  doc: |
    This monitor is for use with an OpenShift cluster. It includes all metrics
    from the [kubernetes-cluster](kubernetes-cluster.md) monitor with additional
    OpenShift-specific metrics. You only need to use one monitor or the other.

    Collects cluster-level metrics from the Kubernetes API server.  It uses the
    _watch_ functionality of the K8s API to listen for updates about the cluster
    and maintains a cache of metrics that get sent on a regular interval.

    Since the agent is generally running in multiple places in a K8s cluster and
    since it is generally more convenient to share the same configuration across
    all agent instances, this monitor by default makes use of a leader election
    process to ensure that it is the only agent sending metrics in a cluster.
    All of the agents running in the same namespace that have this monitor
    configured will decide amongst themselves which should send metrics for this
    monitor, and the rest will stand by ready to activate if the leader agent
    dies.  You can override leader election by setting the config option
    `alwaysClusterReporter` to true, which will make the monitor always report
    metrics.

    This monitor is similar to
    [kube-state-metrics](https://github.com/kubernetes/kube-state-metrics), and
    sends many of the same metrics, but in a way that is less verbose and better
    fitted for the SignalFx backend.
  monitorType: openshift-cluster
  dimensions:
    metric_source:
      description: This is always set to `openshift`
  # NOTE: Do not manually update list below. Update gen-metrics.py and rerun.
  metrics:
    openshift.appliedclusterquota.cpu.hard:
      description: Hard limit for number of cpu by namespace
      default: true
      type: gauge
    openshift.appliedclusterquota.cpu.used:
      description: Consumed number of cpu by namespace
      default: true
      type: gauge
    openshift.appliedclusterquota.memory.hard:
      description: Hard limit for amount of memory by namespace
      default: true
      type: gauge
    openshift.appliedclusterquota.memory.used:
      description: Consumed amount of memory by namespace
      default: true
      type: gauge
    openshift.appliedclusterquota.persistentvolumeclaims.hard:
      description: Hard limit for number of persistentvolumeclaims by namespace
      default: true
      type: gauge
    openshift.appliedclusterquota.persistentvolumeclaims.used:
      description: Consumed number of persistentvolumeclaims by namespace
      default: true
      type: gauge
    openshift.appliedclusterquota.pods.hard:
      description: Hard limit for number of pods by namespace
      default: true
      type: gauge
    openshift.appliedclusterquota.pods.used:
      description: Consumed number of pods by namespace
      default: true
      type: gauge
    openshift.appliedclusterquota.services.hard:
      description: Hard limit for number of services by namespace
      default: true
      type: gauge
    openshift.appliedclusterquota.services.loadbalancers.hard:
      description: Hard limit for number of services.loadbalancers by namespace
      default: true
      type: gauge
    openshift.appliedclusterquota.services.loadbalancers.used:
      description: Consumed number of services.loadbalancers by namespace
      default: true
      type: gauge
    openshift.appliedclusterquota.services.nodeports.hard:
      description: Hard limit for number of services.nodeports by namespace
      default: true
      type: gauge
    openshift.appliedclusterquota.services.nodeports.used:
      description: Consumed number of services.nodeports by namespace
      default: true
      type: gauge
    openshift.appliedclusterquota.services.used:
      description: Consumed number of services by namespace
      default: true
      type: gauge
    openshift.clusterquota.cpu.hard:
      description: Hard limit for number of cpu across all namespaces
      default: true
      type: gauge
    openshift.clusterquota.cpu.used:
      description: Consumed number of cpu across all namespaces
      default: true
      type: gauge
    openshift.clusterquota.memory.hard:
      description: Hard limit for amount of memory across all namespaces
      default: true
      type: gauge
    openshift.clusterquota.memory.used:
      description: Consumed amount of memory across all namespaces
      default: true
      type: gauge
    openshift.clusterquota.persistentvolumeclaims.hard:
      description: Hard limit for number of persistentvolumeclaims across all namespaces
      default: true
      type: gauge
    openshift.clusterquota.persistentvolumeclaims.used:
      description: Consumed number of persistentvolumeclaims across all namespaces
      default: true
      type: gauge
    openshift.clusterquota.pods.hard:
      description: Hard limit for number of pods across all namespaces
      default: true
      type: gauge
    openshift.clusterquota.pods.used:
      description: Consumed number of pods across all namespaces
      default: true
      type: gauge
    openshift.clusterquota.services.hard:
      description: Hard limit for number of services across all namespaces
      default: true
      type: gauge
    openshift.clusterquota.services.loadbalancers.hard:
      description: Hard limit for number of services.loadbalancers across all namespaces
      default: true
      type: gauge
    openshift.clusterquota.services.loadbalancers.used:
      description: Consumed number of services.loadbalancers across all namespaces
      default: true
      type: gauge
    openshift.clusterquota.services.nodeports.hard:
      description: Hard limit for number of services.nodeports across all namespaces
      default: true
      type: gauge
    openshift.clusterquota.services.nodeports.used:
      description: Consumed number of services.nodeports across all namespaces
      default: true
      type: gauge
    openshift.clusterquota.services.used:
      description: Consumed number of services across all namespaces
      default: true
      type: gauge
