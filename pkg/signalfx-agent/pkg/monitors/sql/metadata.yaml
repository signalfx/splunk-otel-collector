monitors:
- monitorType: sql
  dimensions:
  metrics:
  sendAll: true
  doc: |
    Run arbitrary SQL queries against a relational database and use the results to generate dataponts.

    For example, if you had a database table `customers` that looked like:

    | id | name       | country | status   |
    |----|------------|---------|----------|
    | 1  | Bill       | USA     | active   |
    | 2  | Mary       | USA     | inactive |
    | 3  | Joe        | USA     | active   |
    | 4  | Elizabeth  | Germany | active   |

    You could use the following monitor config to generate metrics about active users and customer counts by country:

    ```yaml
    monitors:
      - type: sql
        host: localhost
        port: 5432
        dbDriver: postgres
        params:
          user: admin
          password: s3cr3t
        # The `host` and `port` values from above (or provided through auto-discovery) should be interpolated
        # to the connection string as appropriate for your database driver.
        # Also, the values from the `params` config option above can be
        # interpolated.
        connectionString: 'host={{.host}} port={{.port}} dbname=main user={{.user}} password={{.password}} sslmode=disable'
        queries:
          - query: 'SELECT COUNT(*) as count, country, status FROM customers GROUP BY country, status;'
            metrics:
              - metricName: "customers"
                valueColumn: "count"
                dimensionColumns: ["country", "status"]
    ```

    This would generate a series of timeseries, all with the metric name
    `customers` that includes a `county` and `status` dimension.  The value
    is the number of customers that belong to that combination of `country`
    and `status`.  You could also specify multiple `metrics` items to
    generate more than one metric from a single query.

    ## Metric Expressions

    **Metric Expressions are a beta feature and may break in subsequent
    non-major releases.  The example documented will be maintained for backwards
    compatibility, however.**

    If you need to do more complex logic than simply mapping columns to metric
    values and dimensions, you can use the `datapointExpressions` option to the
    individual metric configurations.  This allows you to use the
    [expr](https://github.com/antonmedv/expr/blob/master/docs/Language-Definition.md)
    expression language to derive datapoints from individual rows using more
    sophisticated logic.  These expressions should evaluate to datapoints
    created by the `GAUGE` or `CUMULATIVE` helper functions available in the
    expression's context.  You can also have the expression evaluate to `nil`
    if no datapoint should be generated for a particular row.

    The signature for both the `GAUGE` and `CUMULATIVE` functions is
    `(metricName, dimensions, value)`, where `metricName` should be a string
    value, `dimensions` should be a map of string keys and values, and `value`
    should be any numeric value.

    Each of the columns in the row is mapped to a variable in the context of
    the expression with the same name.  So if there was a column called `name`
    in your SQL query result, there will be a variable called `name` that you
    can use in the expression.  Note that literal string values used in your
    expressions must be surrounded by `"`.

    For example, the MySQL `SHOW REPLICATE STATUS` query
    does not let you pre-process columns using SQL but let us say
    you wanted to convert the `Slave_IO_Running` column, which is a
    string `Yes`/`No` value, to a gauge datapoint that has a value
    of 0 or 1.  You can do that with the following configuration:

    ```yaml
       - type: sql
         # Example discovery rule, your environment will probably be different
         discoveryRule: container_labels["mysql.slave"] == "true" && port == 3306
         dbDriver: mysql
         params:
           user: root
           password: password
         connectionString: '{{.user}}:{{.password}}@tcp({{.host}})/mysql'
         queries:
          - query: 'SHOW SLAVE STATUS'
            datapointExpressions:
              - 'GAUGE("mysql.slave_sql_running", {master_uuid: Master_UUID, channel: Channel_name}, Slave_SQL_Running == "Yes" ? 1 : 0)'
    ```

    This would generate a single gauge datapoint for each row in the slave
    status output, with two dimension, `master_uuid` and `channel` and with a
    value of 0 or 1 depending on if the slave's SQL thread is running.


    ## Supported Drivers

    The `dbDriver` config option must specify the database driver to use.
    These are equivalent to the name of the Golang SQL driver used in the
    agent.  The `connectionString` option will be formatted according to the
    driver that is going to receive it.  Here is a list of the drivers we
    currently support and documentation on the connection string:

      - `postgres`: https://godoc.org/github.com/lib/pq#hdr-Connection_String_Parameters
      - `mysql`: https://github.com/go-sql-driver/mysql#dsn-data-source-name
      - `sqlserver`: https://github.com/denisenkom/go-mssqldb#connection-parameters-and-dsn
      - `snowflake`: https://pkg.go.dev/github.com/snowflakedb/gosnowflake#hdr-Connection_Parameters

    ## Parameterized Connection String

    The `connectionString` config option acts as a template with a context
    consisting of the variables: `host`, `port`, and all the values from
    the `params` config option map.  You interpolate variables into it
    with the Go template syntax `{{.varname}}` (see example config
    above).

    ## Snowflake Performance and Usage Metrics

    To configure the agent to collect Snowflake performance and usage metrics:
    - Copy pkg/sql/snowflake-metrics.yaml from this repo into the same location as your agent.yaml file (for example, /etc/signalfx).
    - Configure the sql monitor as follows:
    ```
    monitors:
      - type: sql
        intervalSeconds: 3600
        dbDriver: snowflake
        params:
          account: "account.region"
          database: "SNOWFLAKE"
          schema: "ACCOUNT_USAGE"
          role: "ACCOUNTADMIN"
          user: "user"
          password: "password"
        connectionString: "{{.user}}:{{.password}}@{{.account}}/{{.database}}/{{.schema}}?role={{.role}}"
        queries: 
          {"#from": "/etc/signalfx/snowflake-metrics.yaml"}
    ```

    You can also cut/paste the contents of snowflake-metrics.yaml into agent.yaml under "queries" if needed or preferred.  And you can edit snowflake-metrics.yaml to only include metrics you care about.
